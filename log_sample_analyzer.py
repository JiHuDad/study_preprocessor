#!/usr/bin/env python3
"""
ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ë° ë¶„ì„ ë„êµ¬
- ì´ìƒíƒì§€ ê²°ê³¼ì—ì„œ ì‹¤ì œ ë¬¸ì œê°€ ë˜ëŠ” ë¡œê·¸ë“¤ì„ ì¶”ì¶œ
- ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë¡œê·¸ ìƒ˜í”Œê³¼ ë¶„ì„ ì œê³µ
- ì „í›„ ë§¥ë½ê³¼ í•¨ê»˜ ì´ìƒ íŒ¨í„´ ì„¤ëª…
"""
import pandas as pd
import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Optional
import argparse
from datetime import datetime

class LogSampleAnalyzer:
    def __init__(self):
        self.max_samples_per_type = 5  # íƒ€ì…ë³„ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜
        self.context_lines = 3  # ì „í›„ ë§¥ë½ ë¼ì¸ ìˆ˜
        
    def extract_baseline_anomaly_samples(self, parsed_file: str, baseline_scores_file: str) -> Dict:
        """ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” ë¡œê·¸ ìƒ˜í”Œë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        
        # ë°ì´í„° ë¡œë“œ
        df_parsed = pd.read_parquet(parsed_file)
        df_scores = pd.read_parquet(baseline_scores_file)
        
        # ì´ìƒ ìœˆë„ìš°ë§Œ í•„í„°ë§
        anomaly_windows = df_scores[df_scores['is_anomaly'] == True].copy()
        if len(anomaly_windows) == 0:
            return {'type': 'baseline', 'anomaly_count': 0, 'samples': []}
        
        # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        anomaly_windows = anomaly_windows.sort_values('score', ascending=False)
        
        samples = []
        for _, window_row in anomaly_windows.head(self.max_samples_per_type).iterrows():
            window_start = int(window_row['window_start_line'])
            window_size = 50  # ê¸°ë³¸ ìœˆë„ìš° í¬ê¸°
            
            # ìœˆë„ìš° ë‚´ì˜ ë¡œê·¸ë“¤ ì¶”ì¶œ
            window_logs = df_parsed[
                (df_parsed['line_no'] >= window_start) & 
                (df_parsed['line_no'] < window_start + window_size)
            ].copy()
            
            if len(window_logs) == 0:
                continue
            
            # ì „í›„ ë§¥ë½ ë¡œê·¸ ì¶”ì¶œ
            context_before = df_parsed[
                (df_parsed['line_no'] >= max(0, window_start - self.context_lines)) & 
                (df_parsed['line_no'] < window_start)
            ].copy()
            
            context_after = df_parsed[
                (df_parsed['line_no'] >= window_start + window_size) & 
                (df_parsed['line_no'] < window_start + window_size + self.context_lines)
            ].copy()
            
            # ìœˆë„ìš° ë‚´ ì´ìƒ íŒ¨í„´ ë¶„ì„
            analysis = self._analyze_window_patterns(window_logs, window_row)
            
            # ëŒ€í‘œ ë¡œê·¸ë“¤ ì„ ë³„
            representative_logs = self._select_representative_logs(window_logs, analysis)
            
            sample = {
                'window_id': f"window_{window_start}",
                'window_start_line': window_start,
                'anomaly_score': float(window_row['score']),
                'unseen_rate': float(window_row['unseen_rate']),
                'freq_z_score': float(window_row.get('freq_z', 0)),
                'time_range': {
                    'start': str(window_logs['timestamp'].min()) if 'timestamp' in window_logs.columns else None,
                    'end': str(window_logs['timestamp'].max()) if 'timestamp' in window_logs.columns else None,
                },
                'analysis': analysis,
                'representative_logs': representative_logs,
                'context_before': self._format_log_entries(context_before),
                'context_after': self._format_log_entries(context_after),
                'total_logs_in_window': len(window_logs)
            }
            
            samples.append(sample)
        
        return {
            'type': 'baseline',
            'method': 'Window-based frequency and novelty detection',
            'anomaly_count': len(anomaly_windows),
            'analyzed_count': len(samples),
            'samples': samples
        }
    
    def extract_deeplog_anomaly_samples(self, parsed_file: str, deeplog_infer_file: str, 
                                      vocab_file: str, seq_len: int = 50) -> Dict:
        """DeepLog ì´ìƒíƒì§€ì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” ë¡œê·¸ ìƒ˜í”Œë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        
        # ë°ì´í„° ë¡œë“œ
        df_parsed = pd.read_parquet(parsed_file)
        df_infer = pd.read_parquet(deeplog_infer_file)
        
            with open(vocab_file, 'r', encoding='utf-8') as f:
            vocab = json.load(f)
        # ì—­ë°©í–¥ ë§¤í•‘ ìƒì„±
        idx_to_template = {v: k for k, v in vocab.items()}
        
        # ì˜ˆì¸¡ ì‹¤íŒ¨í•œ ê²½ìš°ë“¤ í•„í„°ë§
        anomalies = df_infer[df_infer['in_topk'] == False].copy()
        if len(anomalies) == 0:
            return {'type': 'deeplog', 'anomaly_count': 0, 'samples': []}
        
        samples = []
        for _, anomaly_row in anomalies.head(self.max_samples_per_type).iterrows():
            seq_idx = int(anomaly_row['idx'])
            predicted_template = idx_to_template.get(int(anomaly_row['target']), 'UNKNOWN')
            
            # ì‹œí€€ìŠ¤ ìœ„ì¹˜ë¥¼ ë¼ì¸ ë²ˆí˜¸ë¡œ ë³€í™˜
            approx_line_no = seq_idx + seq_len
            
            # í•´ë‹¹ ë¼ì¸ ì£¼ë³€ì˜ ë¡œê·¸ë“¤ ì°¾ê¸°
            target_logs = df_parsed[
                (df_parsed['line_no'] >= approx_line_no - 5) & 
                (df_parsed['line_no'] <= approx_line_no + 5)
            ].copy()
            
            if len(target_logs) == 0:
                continue
            
            # ê°€ì¥ ê°€ê¹Œìš´ ë¡œê·¸ ì°¾ê¸°
            target_log = target_logs.iloc[len(target_logs)//2] if len(target_logs) > 0 else None
            if target_log is None:
                continue
            
            # ì‹œí€€ìŠ¤ ë§¥ë½ (ì´ì „ seq_lenê°œ ë¡œê·¸ë“¤)
            sequence_context = df_parsed[
                (df_parsed['line_no'] >= max(0, approx_line_no - seq_len)) & 
                (df_parsed['line_no'] < approx_line_no)
            ].copy()
            
            # ì‹œí€€ìŠ¤ ë¶„ì„
            sequence_analysis = self._analyze_sequence_patterns(sequence_context, target_log, predicted_template)
            
            sample = {
                'sequence_id': f"seq_{seq_idx}",
                'sequence_index': seq_idx,
                'predicted_template_id': predicted_template,
                'actual_line_no': int(target_log['line_no']),
                'actual_template_id': str(target_log['template_id']),
                'timestamp': str(target_log['timestamp']) if target_log['timestamp'] else None,
                'analysis': sequence_analysis,
                'target_log': {
                    'line_no': int(target_log['line_no']),
                    'raw_message': str(target_log['raw']),
                    'masked_message': str(target_log['masked']),
                    'template': str(target_log['template']),
                    'template_id': str(target_log['template_id'])
                },
                'sequence_context': self._format_log_entries(sequence_context),
                'sequence_length': len(sequence_context)
            }
            
            samples.append(sample)
        
        return {
            'type': 'deeplog',
            'method': 'LSTM sequence prediction (top-k violation)',
            'anomaly_count': len(anomalies),
            'analyzed_count': len(samples),
            'samples': samples
        }
    
    def extract_comparative_anomaly_samples(self, comparative_anomalies_file: str, 
                                          parsed_file: str) -> Dict:
        """ë¹„êµ ë¶„ì„ì—ì„œ ë°œê²¬ëœ ì´ìƒ ë¡œê·¸ ìƒ˜í”Œë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        
        # ë¹„êµ ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        with open(comparative_anomalies_file, 'r', encoding='utf-8') as f:
            anomalies = json.load(f)
        
        if not anomalies:
            return {'type': 'comparative', 'anomaly_count': 0, 'samples': []}
        
        # parsed íŒŒì¼ ë¡œë“œ
        df_parsed = pd.read_parquet(parsed_file)
        
        samples = []
        for anomaly in anomalies[:self.max_samples_per_type]:
            analysis_type = anomaly.get('type', 'unknown')
            
            if 'template' in analysis_type.lower():
                # í…œí”Œë¦¿ ê´€ë ¨ ì´ìƒ
                sample = self._extract_template_anomaly_sample(anomaly, df_parsed)
            elif 'metric' in analysis_type.lower():
                # ë©”íŠ¸ë¦­ ê´€ë ¨ ì´ìƒ
                sample = self._extract_metric_anomaly_sample(anomaly, df_parsed)
            else:
                # ê¸°íƒ€ ì´ìƒ
                sample = self._extract_general_anomaly_sample(anomaly, df_parsed)
            
            if sample:
                samples.append(sample)
        
        return {
            'type': 'comparative',
            'method': 'Cross-file pattern comparison',
            'anomaly_count': len(anomalies),
            'analyzed_count': len(samples),
            'samples': samples
        }
    
    def _analyze_window_patterns(self, window_logs: pd.DataFrame, window_row: pd.Series) -> Dict:
        """ìœˆë„ìš° ë‚´ ì´ìƒ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        
        # í…œí”Œë¦¿ ë¶„í¬ ë¶„ì„
        template_counts = window_logs['template_id'].value_counts()
        
        # ìƒˆë¡œìš´ í…œí”Œë¦¿ ì‹ë³„
        unseen_rate = float(window_row['unseen_rate'])
        freq_z = float(window_row.get('freq_z', 0))
        
        # ì—ëŸ¬/ê²½ê³  í‚¤ì›Œë“œ ë¶„ì„
        error_keywords = ['error', 'ERROR', 'fail', 'FAIL', 'exception', 'Exception', 'panic', 'fatal', 'crash']
        warning_keywords = ['warn', 'WARN', 'warning', 'WARNING', 'deprecated']
        
        error_logs = window_logs[window_logs['raw'].str.contains('|'.join(error_keywords), case=False, na=False)]
        warning_logs = window_logs[window_logs['raw'].str.contains('|'.join(warning_keywords), case=False, na=False)]
        
        # ì‹œê°„ ë°€ë„ ë¶„ì„
        time_density = self._analyze_time_density(window_logs)
        
        analysis = {
            'dominant_templates': [
                {'template_id': str(tid), 'count': int(count), 'percentage': count/len(window_logs)*100}
                for tid, count in template_counts.head(3).items()
            ],
            'unseen_templates_ratio': unseen_rate,
            'frequency_spike_score': freq_z,
            'error_log_count': len(error_logs),
            'warning_log_count': len(warning_logs),
            'error_percentage': len(error_logs) / len(window_logs) * 100,
            'time_density': time_density,
            'anomaly_indicators': self._identify_anomaly_indicators(window_logs, unseen_rate, freq_z, error_logs, warning_logs)
        }
        
        return analysis
    
    def _analyze_sequence_patterns(self, sequence_context: pd.DataFrame, target_log: pd.Series, 
                                 predicted_template: str) -> Dict:
        """ì‹œí€€ìŠ¤ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        
        # ì‹œí€€ìŠ¤ ë‚´ í…œí”Œë¦¿ ì „í™˜ íŒ¨í„´
        template_sequence = sequence_context['template_id'].tolist() + [target_log['template_id']]
        template_transitions = []
        
        for i in range(len(template_sequence)-1):
            template_transitions.append(f"{template_sequence[i]} â†’ {template_sequence[i+1]}")
        
        # ì˜ˆì¸¡ ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
        prediction_analysis = self._analyze_prediction_failure(
            sequence_context, target_log, predicted_template
        )
        
        # ì»¨í…ìŠ¤íŠ¸ ë‚´ ì´ìƒ íŒ¨í„´
        context_anomalies = self._detect_context_anomalies(sequence_context, target_log)
        
        return {
            'predicted_template': predicted_template,
            'actual_template': str(target_log['template_id']),
            'template_sequence': template_sequence,
            'recent_transitions': template_transitions[-3:] if len(template_transitions) >= 3 else template_transitions,
            'prediction_failure_reason': prediction_analysis,
            'context_anomalies': context_anomalies,
            'sequence_uniqueness': len(set(template_sequence)) / len(template_sequence) if template_sequence else 0
        }
    
    def _extract_template_anomaly_sample(self, anomaly: Dict, df_parsed: pd.DataFrame) -> Optional[Dict]:
        """í…œí”Œë¦¿ ê´€ë ¨ ì´ìƒì—ì„œ ë¡œê·¸ ìƒ˜í”Œì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        
        # unique_templates ì •ë³´ë¥¼ í™œìš©
        unique_templates = anomaly.get('unique_templates', [])
        if not unique_templates:
            return None
        
        # ê³ ìœ  í…œí”Œë¦¿ë“¤ì˜ ë¡œê·¸ ìƒ˜í”Œ ì°¾ê¸°
        sample_logs = []
        for template_id in unique_templates[:3]:  # ìµœëŒ€ 3ê°œ
            template_logs = df_parsed[df_parsed['template_id'] == template_id]
            if len(template_logs) > 0:
                # ì²« ë²ˆì§¸ì™€ ë§ˆì§€ë§‰ ë¡œê·¸ (ì‹œê°„ ë²”ìœ„ íŒŒì•…ìš©)
                first_log = template_logs.iloc[0]
                last_log = template_logs.iloc[-1] if len(template_logs) > 1 else first_log
                
                sample_logs.append({
                    'template_id': str(template_id),
                    'count': len(template_logs),
                    'first_occurrence': {
                        'line_no': int(first_log['line_no']),
                        'timestamp': str(first_log['timestamp']) if first_log['timestamp'] else None,
                        'raw_message': str(first_log['raw']),
                        'template': str(first_log['template'])
                    },
                    'last_occurrence': {
                        'line_no': int(last_log['line_no']),
                        'timestamp': str(last_log['timestamp']) if last_log['timestamp'] else None,
                        'raw_message': str(last_log['raw'])
                    } if len(template_logs) > 1 else None
                })
        
        return {
            'anomaly_type': anomaly.get('type', 'template_anomaly'),
            'severity': anomaly.get('severity', 'unknown'),
            'description': anomaly.get('description', 'Template distribution anomaly'),
            'unique_template_samples': sample_logs,
            'analysis': {
                'total_unique_templates': len(unique_templates),
                'kl_divergence': anomaly.get('kl_divergence'),
                'anomaly_explanation': self._explain_template_anomaly(anomaly)
            }
        }
    
    def _extract_metric_anomaly_sample(self, anomaly: Dict, df_parsed: pd.DataFrame) -> Optional[Dict]:
        """ë©”íŠ¸ë¦­ ê´€ë ¨ ì´ìƒì—ì„œ ë¡œê·¸ ìƒ˜í”Œì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        
        target_value = anomaly.get('target_value')
        baseline_mean = anomaly.get('baseline_mean')
        z_score = anomaly.get('z_score')
        
        # ì „ì²´ íŒŒì¼ì—ì„œ ëŒ€í‘œì ì¸ ë¡œê·¸ ìƒ˜í”Œë“¤ ì¶”ì¶œ
        total_logs = len(df_parsed)
        sample_indices = np.linspace(0, total_logs-1, min(5, total_logs)).astype(int)
        sample_logs = []
        
        for idx in sample_indices:
            log_entry = df_parsed.iloc[idx]
            sample_logs.append({
                'line_no': int(log_entry['line_no']),
                'timestamp': str(log_entry['timestamp']) if log_entry['timestamp'] else None,
                'raw_message': str(log_entry['raw']),
                'template': str(log_entry['template']),
                'template_id': str(log_entry['template_id'])
            })
        
        return {
            'anomaly_type': anomaly.get('type', 'metric_anomaly'),
            'severity': anomaly.get('severity', 'unknown'),
            'description': anomaly.get('description', 'Metric anomaly'),
            'metric_comparison': {
                'target_value': target_value,
                'baseline_mean': baseline_mean,
                'z_score': z_score,
                'deviation_percentage': abs(target_value - baseline_mean) / max(baseline_mean, 1e-6) * 100 if target_value and baseline_mean else None
            },
            'representative_logs': sample_logs,
            'analysis': {
                'anomaly_explanation': self._explain_metric_anomaly(anomaly)
            }
        }
    
    def _extract_general_anomaly_sample(self, anomaly: Dict, df_parsed: pd.DataFrame) -> Optional[Dict]:
        """ì¼ë°˜ì ì¸ ì´ìƒì—ì„œ ë¡œê·¸ ìƒ˜í”Œì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        
        # ë¬´ì‘ìœ„ë¡œ ëª‡ ê°œ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ
        sample_size = min(3, len(df_parsed))
        sample_logs = df_parsed.sample(n=sample_size)
        
        return {
            'anomaly_type': anomaly.get('type', 'general_anomaly'),
            'severity': anomaly.get('severity', 'unknown'),
            'description': anomaly.get('description', 'General anomaly detected'),
            'sample_logs': self._format_log_entries(sample_logs),
            'analysis': {
                'anomaly_explanation': f"ì¼ë°˜ì ì¸ ì´ìƒ íŒ¨í„´: {anomaly.get('description', 'Unknown anomaly')}"
            }
        }
    
    def _format_log_entries(self, logs_df: pd.DataFrame) -> List[Dict]:
        """ë¡œê·¸ ì—”íŠ¸ë¦¬ë“¤ì„ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ í¬ë§·í•©ë‹ˆë‹¤."""
        
        formatted_logs = []
        for _, log in logs_df.iterrows():
            formatted_logs.append({
                'line_no': int(log['line_no']),
                'timestamp': str(log['timestamp']) if log['timestamp'] else None,
                'host': str(log['host']) if 'host' in log and log['host'] else None,
                'process': str(log['process']) if 'process' in log and log['process'] else None,
                'raw_message': str(log['raw']),
                'masked_message': str(log['masked']) if 'masked' in log else None,
                'template': str(log['template']) if 'template' in log else None,
                'template_id': str(log['template_id']) if 'template_id' in log else None
            })
        
        return formatted_logs
    
    def _select_representative_logs(self, window_logs: pd.DataFrame, analysis: Dict) -> List[Dict]:
        """ìœˆë„ìš°ì—ì„œ ëŒ€í‘œì ì¸ ë¡œê·¸ë“¤ì„ ì„ ë³„í•©ë‹ˆë‹¤."""
        
        representatives = []
        
        # 1. ê°€ì¥ ë§ì´ ë‚˜ì˜¨ í…œí”Œë¦¿ì˜ ì²« ë²ˆì§¸ ë¡œê·¸
        dominant_templates = analysis.get('dominant_templates', [])
        if dominant_templates:
            top_template_id = dominant_templates[0]['template_id']
            top_template_logs = window_logs[window_logs['template_id'] == top_template_id]
            if len(top_template_logs) > 0:
                representatives.append({
                    'type': 'dominant_template',
                    'log': self._format_log_entries(top_template_logs.head(1))[0],
                    'reason': f"ê°€ì¥ ë¹ˆë²ˆí•œ í…œí”Œë¦¿ (ì „ì²´ì˜ {dominant_templates[0]['percentage']:.1f}%)"
                })
        
        # 2. ì—ëŸ¬ ë¡œê·¸ê°€ ìˆë‹¤ë©´ ì²« ë²ˆì§¸ ì—ëŸ¬
        error_keywords = ['error', 'ERROR', 'fail', 'FAIL', 'exception', 'Exception']
        error_logs = window_logs[window_logs['raw'].str.contains('|'.join(error_keywords), case=False, na=False)]
        if len(error_logs) > 0:
            representatives.append({
                'type': 'error_log',
                'log': self._format_log_entries(error_logs.head(1))[0],
                'reason': "ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨"
            })
        
        # 3. í¬ê·€ í…œí”Œë¦¿ (1ë²ˆë§Œ ë‚˜ì˜¨ ê²ƒ)
        template_counts = window_logs['template_id'].value_counts()
        rare_templates = template_counts[template_counts == 1]
        if len(rare_templates) > 0:
            rare_template_id = rare_templates.index[0]
            rare_log = window_logs[window_logs['template_id'] == rare_template_id].iloc[0]
            representatives.append({
                'type': 'rare_template',
                'log': self._format_log_entries(pd.DataFrame([rare_log]))[0],
                'reason': "ìƒˆë¡œìš´/í¬ê·€ í…œí”Œë¦¿"
            })
        
        return representatives[:3]  # ìµœëŒ€ 3ê°œ
    
    def _analyze_time_density(self, logs_df: pd.DataFrame) -> Dict:
        """ì‹œê°„ ë°€ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        
        if 'timestamp' not in logs_df.columns or len(logs_df) < 2:
            return {'analysis': 'insufficient_data'}
        
        try:
            logs_df = logs_df.copy()
            logs_df['timestamp'] = pd.to_datetime(logs_df['timestamp'], errors='coerce')
            valid_logs = logs_df.dropna(subset=['timestamp']).sort_values('timestamp')
            
            if len(valid_logs) < 2:
                return {'analysis': 'insufficient_valid_timestamps'}
            
            time_diffs = valid_logs['timestamp'].diff().dt.total_seconds().dropna()
            
            return {
                'total_duration_seconds': (valid_logs['timestamp'].max() - valid_logs['timestamp'].min()).total_seconds(),
                'average_interval_seconds': float(time_diffs.mean()),
                'logs_per_second': len(valid_logs) / max((valid_logs['timestamp'].max() - valid_logs['timestamp'].min()).total_seconds(), 1),
                'time_distribution': 'concentrated' if time_diffs.std() < time_diffs.mean() * 0.5 else 'spread'
            }
        except (ValueError, TypeError, pd.errors.ParserError):
            return {'analysis': 'time_analysis_failed'}
    
    def _identify_anomaly_indicators(self, window_logs: pd.DataFrame, unseen_rate: float, 
                                   freq_z: float, error_logs: pd.DataFrame, warning_logs: pd.DataFrame) -> List[str]:
        """ì´ìƒ ì§€í‘œë“¤ì„ ì‹ë³„í•©ë‹ˆë‹¤."""
        
        indicators = []
        
        if unseen_rate > 0.2:
            indicators.append(f"ìƒˆë¡œìš´ í…œí”Œë¦¿ ë¹„ìœ¨ì´ ë†’ìŒ ({unseen_rate:.1%})")
        
        if freq_z > 2.0:
            indicators.append(f"í…œí”Œë¦¿ ë¹ˆë„ ê¸‰ì¦ (Z-score: {freq_z:.2f})")
        
        if len(error_logs) > 0:
            indicators.append(f"ì—ëŸ¬ ë¡œê·¸ {len(error_logs)}ê°œ ë°œê²¬")
        
        if len(warning_logs) > len(window_logs) * 0.1:
            indicators.append(f"ê²½ê³  ë¡œê·¸ê°€ ì „ì²´ì˜ {len(warning_logs)/len(window_logs)*100:.1f}%")
        
        # í…œí”Œë¦¿ ë‹¤ì–‘ì„± ì²´í¬
        unique_templates = len(window_logs['template_id'].unique())
        if unique_templates > len(window_logs) * 0.8:
            indicators.append("í…œí”Œë¦¿ ë‹¤ì–‘ì„±ì´ ë§¤ìš° ë†’ìŒ (ê±°ì˜ ëª¨ë“  ë¡œê·¸ê°€ ë‹¤ë¥¸ íŒ¨í„´)")
        
        return indicators
    
    def _analyze_prediction_failure(self, sequence_context: pd.DataFrame, target_log: pd.Series, 
                                  predicted_template: str) -> str:
        """ì˜ˆì¸¡ ì‹¤íŒ¨ ì›ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        
        actual_template = str(target_log['template_id'])
        
        # ì»¨í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ í…œí”Œë¦¿ì´ ë‚˜ì˜¨ ì ì´ ìˆëŠ”ì§€ í™•ì¸
        if actual_template in sequence_context['template_id'].values:
            recent_occurrence = sequence_context[sequence_context['template_id'] == actual_template].iloc[-1]
            position = len(sequence_context) - list(sequence_context['template_id']).index(actual_template)
            return f"ì˜ˆì¸¡í•˜ì§€ ëª»í•œ í…œí”Œë¦¿ ì¬ë“±ì¥ ({position}ë²ˆì§¸ ì „ì— ë§ˆì§€ë§‰ ì¶œí˜„)"
        else:
            return f"ì»¨í…ìŠ¤íŠ¸ì— ì—†ë˜ ì™„ì „íˆ ìƒˆë¡œìš´ í…œí”Œë¦¿ ë“±ì¥"
    
    def _detect_context_anomalies(self, sequence_context: pd.DataFrame, target_log: pd.Series) -> List[str]:
        """ì»¨í…ìŠ¤íŠ¸ ë‚´ ì´ìƒ íŒ¨í„´ì„ íƒì§€í•©ë‹ˆë‹¤."""
        
        anomalies = []
        
        if len(sequence_context) == 0:
            return ["ì»¨í…ìŠ¤íŠ¸ ë¶€ì¡±"]
        
        # 1. ë°˜ë³µ íŒ¨í„´ ì²´í¬
        templates = sequence_context['template_id'].tolist()
        if len(templates) > 3:
            last_3 = templates[-3:]
            if len(set(last_3)) == 1:
                anomalies.append("ì§ì „ 3ê°œ ë¡œê·¸ê°€ ëª¨ë‘ ë™ì¼í•œ í…œí”Œë¦¿")
        
        # 2. ì—ëŸ¬ íŒ¨í„´ ì²´í¬
        error_keywords = ['error', 'ERROR', 'fail', 'FAIL']
        error_count = sum(1 for _, log in sequence_context.iterrows() 
                         if any(keyword in str(log['raw']) for keyword in error_keywords))
        
        if error_count > len(sequence_context) * 0.3:
            anomalies.append(f"ì»¨í…ìŠ¤íŠ¸ ë‚´ ì—ëŸ¬ ë¡œê·¸ ë¹„ìœ¨ì´ ë†’ìŒ ({error_count}/{len(sequence_context)})")
        
        # 3. ì‹œê°„ ê°„ê²© ì²´í¬ (ë§Œì•½ timestampê°€ ìˆë‹¤ë©´)
        if 'timestamp' in sequence_context.columns:
            try:
                sequence_context = sequence_context.copy()
                sequence_context['timestamp'] = pd.to_datetime(sequence_context['timestamp'], errors='coerce')
                valid_times = sequence_context.dropna(subset=['timestamp'])
                
                if len(valid_times) > 1:
                    time_diffs = valid_times['timestamp'].diff().dt.total_seconds().dropna()
                    if time_diffs.max() > 3600:  # 1ì‹œê°„ ì´ìƒ ê°­
                        anomalies.append("ì»¨í…ìŠ¤íŠ¸ ë‚´ í° ì‹œê°„ ê°„ê²© ì¡´ì¬")
            except (ValueError, TypeError, pd.errors.ParserError):
                pass
        
        return anomalies if anomalies else ["íŠ¹ë³„í•œ ì»¨í…ìŠ¤íŠ¸ ì´ìƒ ì—†ìŒ"]
    
    def _explain_template_anomaly(self, anomaly: Dict) -> str:
        """í…œí”Œë¦¿ ì´ìƒì— ëŒ€í•œ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        
        kl_div = anomaly.get('kl_divergence', 0)
        unique_count = anomaly.get('unique_templates', 0)
        
        explanation = f"ì´ íŒŒì¼ì€ ë‹¤ë¥¸ baseline íŒŒì¼ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ "
        
        if kl_div > 2.0:
            explanation += "í…œí”Œë¦¿ ë¶„í¬ê°€ ë§¤ìš° ë‹¤ë¦…ë‹ˆë‹¤. "
        elif kl_div > 1.0:
            explanation += "í…œí”Œë¦¿ ë¶„í¬ê°€ ìƒë‹¹íˆ ë‹¤ë¦…ë‹ˆë‹¤. "
        
        if unique_count > 0:
            explanation += f"íŠ¹íˆ {unique_count}ê°œì˜ ê³ ìœ í•œ í…œí”Œë¦¿ì´ ì´ íŒŒì¼ì—ë§Œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤. "
            explanation += "ì´ëŠ” ìƒˆë¡œìš´ ì¢…ë¥˜ì˜ ì´ë²¤íŠ¸ë‚˜ ë¬¸ì œ ìƒí™©ì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return explanation
    
    def _explain_metric_anomaly(self, anomaly: Dict) -> str:
        """ë©”íŠ¸ë¦­ ì´ìƒì— ëŒ€í•œ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        
        metric_type = anomaly.get('type', '')
        target_value = anomaly.get('target_value')
        baseline_mean = anomaly.get('baseline_mean')
        
        if 'error_rate' in metric_type:
            if target_value > baseline_mean:
                return f"ì—ëŸ¬ìœ¨ì´ baseline í‰ê·  {baseline_mean:.2%}ë³´ë‹¤ {target_value:.2%}ë¡œ ë†’ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì— ë¬¸ì œê°€ ìˆì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
            else:
                return f"ì—ëŸ¬ìœ¨ì´ baseline í‰ê· ë³´ë‹¤ ë‚®ìŠµë‹ˆë‹¤. ì´ëŠ” ì–‘í˜¸í•œ ìƒíƒœì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        elif 'template' in metric_type:
            if target_value > baseline_mean:
                return f"í…œí”Œë¦¿ ìˆ˜ê°€ baseline í‰ê·  {baseline_mean:.0f}ê°œë³´ë‹¤ {target_value:.0f}ê°œë¡œ ë§ìŠµë‹ˆë‹¤. ë” ë‹¤ì–‘í•œ ì´ë²¤íŠ¸ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            else:
                return f"í…œí”Œë¦¿ ìˆ˜ê°€ baseline í‰ê· ë³´ë‹¤ ì ìŠµë‹ˆë‹¤. í™œë™ì´ ì œí•œì ì´ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        
        return f"ë©”íŠ¸ë¦­ ê°’ì´ baselineê³¼ í¬ê²Œ ë‹¤ë¦…ë‹ˆë‹¤ (target: {target_value}, baseline: {baseline_mean})."

def analyze_all_anomalies(processed_dir: str, output_dir: str = None):
    """ëª¨ë“  ì´ìƒíƒì§€ ê²°ê³¼ì—ì„œ ë¡œê·¸ ìƒ˜í”Œì„ ì¶”ì¶œí•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤."""
    
    processed_path = Path(processed_dir)
    if output_dir is None:
        output_dir = processed_path / "log_samples_analysis"
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ” ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ì‹œì‘...")
    
    analyzer = LogSampleAnalyzer()
    all_results = {}
    
    # í•„ìˆ˜ íŒŒì¼ë“¤ í™•ì¸
    parsed_file = processed_path / "parsed.parquet"
    if not parsed_file.exists():
        print("âŒ parsed.parquet íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        return
    
    # 1. Baseline ì´ìƒíƒì§€ ê²°ê³¼ ë¶„ì„
    baseline_scores_file = processed_path / "baseline_scores.parquet"
    if baseline_scores_file.exists():
        print("ğŸ“Š Baseline ì´ìƒíƒì§€ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        baseline_results = analyzer.extract_baseline_anomaly_samples(
            str(parsed_file), str(baseline_scores_file)
        )
        all_results['baseline'] = baseline_results
        print(f"   âœ… {baseline_results['anomaly_count']}ê°œ ì´ìƒ ìœˆë„ìš° ì¤‘ {baseline_results['analyzed_count']}ê°œ ë¶„ì„")
    
    # 2. DeepLog ì´ìƒíƒì§€ ê²°ê³¼ ë¶„ì„
    deeplog_infer_file = processed_path / "deeplog_infer.parquet"
    vocab_file = processed_path / "vocab.json"
    if deeplog_infer_file.exists() and vocab_file.exists():
        print("ğŸ§  DeepLog ì´ìƒíƒì§€ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        deeplog_results = analyzer.extract_deeplog_anomaly_samples(
            str(parsed_file), str(deeplog_infer_file), str(vocab_file)
        )
        all_results['deeplog'] = deeplog_results
        print(f"   âœ… {deeplog_results['anomaly_count']}ê°œ ì˜ˆì¸¡ ì‹¤íŒ¨ ì¤‘ {deeplog_results['analyzed_count']}ê°œ ë¶„ì„")
    
    # 3. ë¹„êµ ë¶„ì„ ê²°ê³¼
    comparative_dir = processed_path / "comparative_analysis"
    comparative_anomalies_file = comparative_dir / "comparative_anomalies.json"
    if comparative_anomalies_file.exists():
        print("ğŸ“Š ë¹„êµ ë¶„ì„ ì´ìƒíƒì§€ ê²°ê³¼ ë¶„ì„ ì¤‘...")
        comparative_results = analyzer.extract_comparative_anomaly_samples(
            str(comparative_anomalies_file), str(parsed_file)
        )
        all_results['comparative'] = comparative_results
        print(f"   âœ… {comparative_results['anomaly_count']}ê°œ ë¹„êµ ì´ìƒ ì¤‘ {comparative_results['analyzed_count']}ê°œ ë¶„ì„")
    
    # ê²°ê³¼ ì €ì¥
    with open(output_path / "anomaly_samples.json", 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
    
    # ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë¦¬í¬íŠ¸ ìƒì„±
    print("ğŸ“„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    report = generate_human_readable_report(all_results)
    with open(output_path / "anomaly_analysis_report.md", 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ì™„ë£Œ!")
    print(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_path}")
    print(f"ğŸ“„ ì£¼ìš” íŒŒì¼:")
    print(f"   - anomaly_samples.json: ìƒì„¸ ë¶„ì„ ë°ì´í„°")
    print(f"   - anomaly_analysis_report.md: ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë¦¬í¬íŠ¸")
    
    return all_results

def generate_human_readable_report(all_results: Dict) -> str:
    """ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ì´ìƒ ë¡œê·¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    report = f"""# ğŸ” ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ë¦¬í¬íŠ¸

**ìƒì„± ì‹œê°„**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

ì´ ë¦¬í¬íŠ¸ëŠ” ë‹¤ì–‘í•œ ì´ìƒíƒì§€ ë°©ë²•ìœ¼ë¡œ ë°œê²¬ëœ ë¬¸ì œ ë¡œê·¸ë“¤ì˜ ì‹¤ì œ ìƒ˜í”Œê³¼ ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ“‹ ë¶„ì„ ë°©ë²•ë³„ ìš”ì•½

"""
    
    total_anomalies = 0
    for method, results in all_results.items():
        anomaly_count = results.get('anomaly_count', 0)
        total_anomalies += anomaly_count
        method_description = results.get('method', 'Unknown method')
        
        report += f"""### {method.title()} ë°©ë²•
- **ë°©ë²•ë¡ **: {method_description}
- **ë°œê²¬ëœ ì´ìƒ**: {anomaly_count}ê°œ
- **ë¶„ì„ëœ ìƒ˜í”Œ**: {results.get('analyzed_count', 0)}ê°œ

"""
    
    report += f"**ì „ì²´ ì´ìƒ ê°œìˆ˜**: {total_anomalies}ê°œ\n\n"
    
    # ê° ë°©ë²•ë³„ ìƒì„¸ ë¶„ì„
    for method, results in all_results.items():
        if results.get('analyzed_count', 0) == 0:
            continue
            
        report += f"""## ğŸ”¬ {method.title()} ìƒì„¸ ë¶„ì„

### ë°©ë²• ì„¤ëª…
{results.get('method', 'Unknown method')}

"""
        
        samples = results.get('samples', [])
        for i, sample in enumerate(samples, 1):
            report += generate_sample_analysis(method, sample, i)
    
    report += """

## ğŸ’¡ ê¶Œì¥ì‚¬í•­

### ì¦‰ì‹œ ì¡°ì¹˜ê°€ í•„ìš”í•œ ì‚¬í•­
1. **ì—ëŸ¬ ë¡œê·¸ê°€ í¬í•¨ëœ ìœˆë„ìš°/ì‹œí€€ìŠ¤**: ì¦‰ì‹œ ì›ì¸ ì¡°ì‚¬ í•„ìš”
2. **ìƒˆë¡œìš´ í…œí”Œë¦¿ ëŒ€ëŸ‰ ë°œìƒ**: ì‹œìŠ¤í…œ ë³€ê²½ì‚¬í•­ì´ë‚˜ ìƒˆë¡œìš´ ë¬¸ì œ í™•ì¸
3. **ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥í•œ íŒ¨í„´**: ë¹„ì •ìƒì ì¸ ì‹œìŠ¤í…œ ë™ì‘ ê°€ëŠ¥ì„±

### ì¶”ê°€ ë¶„ì„ ë°©ë²•
1. **ì‹œê°„ëŒ€ë³„ ë¶„ì„**: íŠ¹ì • ì‹œê°„ëŒ€ì— ì§‘ì¤‘ëœ ì´ìƒì´ ìˆëŠ”ì§€ í™•ì¸
2. **í˜¸ìŠ¤íŠ¸ë³„ ë¶„ì„**: íŠ¹ì • ì„œë²„/í˜¸ìŠ¤íŠ¸ì—ì„œë§Œ ë°œìƒí•˜ëŠ” ë¬¸ì œì¸ì§€ í™•ì¸
3. **í”„ë¡œì„¸ìŠ¤ë³„ ë¶„ì„**: íŠ¹ì • í”„ë¡œì„¸ìŠ¤ì™€ ê´€ë ¨ëœ ë¬¸ì œì¸ì§€ í™•ì¸

### ëª¨ë‹ˆí„°ë§ ê°•í™”
- ì´ìƒ íŒ¨í„´ìœ¼ë¡œ ì‹ë³„ëœ í…œí”Œë¦¿ë“¤ì— ëŒ€í•œ ì•Œë¦¼ ì„¤ì •
- ì—ëŸ¬ìœ¨ì´ ê¸‰ì¦í•˜ëŠ” êµ¬ê°„ì— ëŒ€í•œ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ìƒˆë¡œìš´ í…œí”Œë¦¿ ì¶œí˜„ì— ëŒ€í•œ ìë™ ì•Œë¦¼

---

**ì°¸ê³ **: ì´ ë¦¬í¬íŠ¸ëŠ” ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë” ì •í™•í•œ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ì‹œìŠ¤í…œ ê´€ë¦¬ìì˜ ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.
"""
    
    return report

def generate_sample_analysis(method: str, sample: Dict, sample_num: int) -> str:
    """ê°œë³„ ìƒ˜í”Œì— ëŒ€í•œ ë¶„ì„ ì„¹ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    if method == 'baseline':
        return generate_baseline_sample_analysis(sample, sample_num)
    elif method == 'deeplog':
        return generate_deeplog_sample_analysis(sample, sample_num)
    elif method == 'comparative':
        return generate_comparative_sample_analysis(sample, sample_num)
    else:
        return f"### ìƒ˜í”Œ {sample_num}\nì•Œ ìˆ˜ ì—†ëŠ” ë¶„ì„ ë°©ë²•\n\n"

def generate_baseline_sample_analysis(sample: Dict, sample_num: int) -> str:
    """ë² ì´ìŠ¤ë¼ì¸ ìƒ˜í”Œ ë¶„ì„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    window_start = sample['window_start_line']
    score = sample['anomaly_score']
    time_range = sample.get('time_range', {})
    analysis = sample.get('analysis', {})
    
    report = f"""### ğŸš¨ ì´ìƒ ìœˆë„ìš° #{sample_num} (ë¼ì¸ {window_start}~)

**ê¸°ë³¸ ì •ë³´**:
- ì´ìƒ ì ìˆ˜: {score:.3f}
- ìƒˆ í…œí”Œë¦¿ ë¹„ìœ¨: {sample['unseen_rate']:.1%}
- ì‹œê°„ ë²”ìœ„: {time_range.get('start', 'N/A')} ~ {time_range.get('end', 'N/A')}
- ìœˆë„ìš° ë‚´ ë¡œê·¸ ìˆ˜: {sample['total_logs_in_window']}ê°œ

**ì´ìƒ ì§€í‘œ**:
"""
    
    indicators = analysis.get('anomaly_indicators', [])
    if indicators:
        for indicator in indicators:
            report += f"- âš ï¸ {indicator}\n"
    else:
        report += "- íŠ¹ë³„í•œ ì´ìƒ ì§€í‘œ ì—†ìŒ\n"
    
    # ëŒ€í‘œ ë¡œê·¸ë“¤
    representatives = sample.get('representative_logs', [])
    if representatives:
        report += "\n**ëŒ€í‘œì ì¸ ë¬¸ì œ ë¡œê·¸ë“¤**:\n"
        for rep in representatives:
            log_info = rep['log']
            report += f"""
**{rep['type'].upper()}** ({rep['reason']}):
```
[{log_info.get('timestamp', 'N/A')}] {log_info.get('raw_message', 'N/A')}
```
- í…œí”Œë¦¿: `{log_info.get('template', 'N/A')}`
- ë¼ì¸: {log_info.get('line_no', 'N/A')}

"""
    
    # ì „í›„ ë§¥ë½
    context_before = sample.get('context_before', [])
    context_after = sample.get('context_after', [])
    
    if context_before or context_after:
        report += "**ì „í›„ ë§¥ë½**:\n"
        
        if context_before:
            report += "```\n[ì´ì „ ë§¥ë½]\n"
            for log in context_before[-2:]:  # ë§ˆì§€ë§‰ 2ê°œë§Œ
                report += f"{log.get('line_no', '?'):>6}: {log.get('raw_message', 'N/A')}\n"
            report += "```\n"
        
        if context_after:
            report += "```\n[ì´í›„ ë§¥ë½]\n"
            for log in context_after[:2]:  # ì²˜ìŒ 2ê°œë§Œ
                report += f"{log.get('line_no', '?'):>6}: {log.get('raw_message', 'N/A')}\n"
            report += "```\n"
    
    report += "\n---\n\n"
    return report

def generate_deeplog_sample_analysis(sample: Dict, sample_num: int) -> str:
    """DeepLog ìƒ˜í”Œ ë¶„ì„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    target_log = sample.get('target_log', {})
    analysis = sample.get('analysis', {})
    
    report = f"""### ğŸ§  DeepLog ì˜ˆì¸¡ ì‹¤íŒ¨ #{sample_num}

**ê¸°ë³¸ ì •ë³´**:
- ì‹œí€€ìŠ¤ ì¸ë±ìŠ¤: {sample['sequence_index']}
- ì˜ˆì¸¡ëœ í…œí”Œë¦¿: `{sample['predicted_template_id']}`
- ì‹¤ì œ í…œí”Œë¦¿: `{sample['actual_template_id']}`
- ì‹¤ì œ ë¼ì¸ ë²ˆí˜¸: {sample['actual_line_no']}

**ì‹¤ì œ ë°œìƒí•œ ë¡œê·¸**:
```
[{target_log.get('timestamp', 'N/A')}] {target_log.get('raw_message', 'N/A')}
```
- í…œí”Œë¦¿: `{target_log.get('template', 'N/A')}`

**ì˜ˆì¸¡ ì‹¤íŒ¨ ì›ì¸**:
{analysis.get('prediction_failure_reason', 'ì•Œ ìˆ˜ ì—†ìŒ')}

**ìµœê·¼ í…œí”Œë¦¿ ì „í™˜ íŒ¨í„´**:
"""
    
    recent_transitions = analysis.get('recent_transitions', [])
    if recent_transitions:
        for transition in recent_transitions:
            report += f"- `{transition}`\n"
    else:
        report += "- íŒ¨í„´ ì •ë³´ ì—†ìŒ\n"
    
    # ì»¨í…ìŠ¤íŠ¸ ì´ìƒ
    context_anomalies = analysis.get('context_anomalies', [])
    if context_anomalies:
        report += "\n**ì»¨í…ìŠ¤íŠ¸ ë¶„ì„**:\n"
        for anomaly in context_anomalies:
            report += f"- {anomaly}\n"
    
    # ì‹œí€€ìŠ¤ ì»¨í…ìŠ¤íŠ¸
    sequence_context = sample.get('sequence_context', [])
    if sequence_context:
        report += "\n**ì‹œí€€ìŠ¤ ì»¨í…ìŠ¤íŠ¸ (ìµœê·¼ 5ê°œ)**:\n```\n"
        for log in sequence_context[-5:]:
            report += f"{log.get('line_no', '?'):>6}: {log.get('raw_message', 'N/A')}\n"
        report += "```\n"
    
    report += "\n---\n\n"
    return report

def generate_comparative_sample_analysis(sample: Dict, sample_num: int) -> str:
    """ë¹„êµ ë¶„ì„ ìƒ˜í”Œ ë¶„ì„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    
    report = f"""### ğŸ“Š ë¹„êµ ë¶„ì„ ì´ìƒ #{sample_num}

**ì´ìƒ ìœ í˜•**: {sample.get('anomaly_type', 'unknown')}
**ì‹¬ê°ë„**: {sample.get('severity', 'unknown')}
**ì„¤ëª…**: {sample.get('description', 'No description')}

"""
    
    # í…œí”Œë¦¿ ê´€ë ¨ ì´ìƒ
    if 'unique_template_samples' in sample:
        unique_samples = sample['unique_template_samples']
        report += "**ê³ ìœ  í…œí”Œë¦¿ë“¤**:\n"
        
        for template_sample in unique_samples:
            first_occ = template_sample['first_occurrence']
            report += f"""
**í…œí”Œë¦¿ ID**: `{template_sample['template_id']}`
**ì¶œí˜„ íšŸìˆ˜**: {template_sample['count']}íšŒ
**ì²« ë²ˆì§¸ ì¶œí˜„**:
```
[{first_occ.get('timestamp', 'N/A')}] {first_occ.get('raw_message', 'N/A')}
```
"""
    
    # ë©”íŠ¸ë¦­ ê´€ë ¨ ì´ìƒ
    if 'metric_comparison' in sample:
        metric_comp = sample['metric_comparison']
        report += f"""
**ë©”íŠ¸ë¦­ ë¹„êµ**:
- Target ê°’: {metric_comp.get('target_value', 'N/A')}
- Baseline í‰ê· : {metric_comp.get('baseline_mean', 'N/A')}
- Z-Score: {metric_comp.get('z_score', 'N/A')}
- í¸ì°¨: {metric_comp.get('deviation_percentage', 'N/A'):.1f}%
"""
    
    # ëŒ€í‘œ ë¡œê·¸ë“¤
    if 'representative_logs' in sample:
        rep_logs = sample['representative_logs']
        report += "\n**ëŒ€í‘œ ë¡œê·¸ ìƒ˜í”Œë“¤**:\n```\n"
        for log in rep_logs[:3]:
            report += f"{log.get('line_no', '?'):>6}: {log.get('raw_message', 'N/A')}\n"
        report += "```\n"
    
    # ë¶„ì„ ì„¤ëª…
    analysis = sample.get('analysis', {})
    explanation = analysis.get('anomaly_explanation', '')
    if explanation:
        report += f"\n**ë¶„ì„**: {explanation}\n"
    
    report += "\n---\n\n"
    return report

def main():
    parser = argparse.ArgumentParser(description="ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ë° ë¶„ì„")
    parser.add_argument("processed_dir", help="ì „ì²˜ë¦¬ëœ ê²°ê³¼ ë””ë ‰í† ë¦¬")
    parser.add_argument("--output-dir", help="ê²°ê³¼ ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--max-samples", type=int, default=5, help="íƒ€ì…ë³„ ìµœëŒ€ ìƒ˜í”Œ ìˆ˜")
    parser.add_argument("--context-lines", type=int, default=3, help="ì „í›„ ë§¥ë½ ë¼ì¸ ìˆ˜")
    
    args = parser.parse_args()
    
    # ê¸€ë¡œë²Œ ì„¤ì • ì—…ë°ì´íŠ¸
    LogSampleAnalyzer.max_samples_per_type = args.max_samples
    LogSampleAnalyzer.context_lines = args.context_lines
    
    analyze_all_anomalies(args.processed_dir, args.output_dir)

if __name__ == "__main__":
    main()
