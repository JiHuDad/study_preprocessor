#!/bin/bash

# ì ì§„ì  ë¡œê·¸ ì´ìƒíƒì§€ ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸
# ê¸°ì¡´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì ì§„ì  í•™ìŠµì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
# ì‚¬ìš©ë²•: ./train_models_incremental.sh <ê¸°ì¡´ëª¨ë¸ë””ë ‰í† ë¦¬> <ìƒˆë¡œìš´ë¡œê·¸ë””ë ‰í† ë¦¬> [ê²°ê³¼ëª¨ë¸ë””ë ‰í† ë¦¬] [ìµœëŒ€ê¹Šì´] [ìµœëŒ€íŒŒì¼ìˆ˜]

set -e  # ì—ëŸ¬ ë°œìƒì‹œ ì¦‰ì‹œ ì¤‘ë‹¨

# ê¸°ë³¸ê°’ ì„¤ì •
BASE_MODEL_DIR="$1"
NEW_LOG_DIR="$2"
OUTPUT_MODEL_DIR="${3:-models_incremental_$(date +%Y%m%d_%H%M%S)}"
MAX_DEPTH="${4:-3}"
MAX_FILES="${5:-50}"

# ì¸ìˆ˜ í™•ì¸
if [ -z "$BASE_MODEL_DIR" ] || [ -z "$NEW_LOG_DIR" ]; then
    echo "âŒ ì‚¬ìš©ë²•: $0 <ê¸°ì¡´ëª¨ë¸ë””ë ‰í† ë¦¬> <ìƒˆë¡œìš´ë¡œê·¸ë””ë ‰í† ë¦¬> [ê²°ê³¼ëª¨ë¸ë””ë ‰í† ë¦¬] [ìµœëŒ€ê¹Šì´] [ìµœëŒ€íŒŒì¼ìˆ˜]"
    echo ""
    echo "ì˜ˆì‹œ:"
    echo "  $0 models_old /var/log/new_normal/"
    echo "  $0 models_old /var/log/new_normal/ models_updated"  
    echo "  $0 models_old /var/log/new_normal/ models_updated 5 100"
    echo ""
    echo "ğŸ“‹ ì„¤ëª…:"
    echo "  - ê¸°ì¡´ëª¨ë¸ë””ë ‰í† ë¦¬: ê¸°ì¡´ì— í•™ìŠµëœ ëª¨ë¸ë“¤ì´ ìˆëŠ” í´ë”"
    echo "  - ìƒˆë¡œìš´ë¡œê·¸ë””ë ‰í† ë¦¬: ì¶”ê°€ í•™ìŠµí•  ìƒˆë¡œìš´ ì •ìƒ ë¡œê·¸ í´ë”"
    echo "  - ê²°ê³¼ëª¨ë¸ë””ë ‰í† ë¦¬: ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ë“¤ì„ ì €ì¥í•  í´ë” (ìƒëµì‹œ ìë™ ìƒì„±)"
    echo "  - ìµœëŒ€ê¹Šì´: í•˜ìœ„ ë””ë ‰í† ë¦¬ ìŠ¤ìº” ê¹Šì´ (ê¸°ë³¸: 3)"
    echo "  - ìµœëŒ€íŒŒì¼ìˆ˜: ì¶”ê°€ í•™ìŠµì— ì‚¬ìš©í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (ê¸°ë³¸: 50)"
    echo ""
    echo "ğŸ’¡ íŠ¹ì§•:"
    echo "  - ğŸ”„ ê¸°ì¡´ ëª¨ë¸ ìƒíƒœ ë³´ì¡´ ë° í™•ì¥"
    echo "  - ğŸ“ ìƒˆë¡œìš´ ë¡œê·¸ ë°ì´í„° ì ì§„ì  ì¶”ê°€"
    echo "  - ğŸ§  DeepLog ëª¨ë¸ ì ì§„ì  í•™ìŠµ"
    echo "  - ğŸ”¬ MS-CRED ëª¨ë¸ ì ì§„ì  í•™ìŠµ"
    echo "  - ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸"
    echo "  - ğŸ”§ Drain3 í…œí”Œë¦¿ ìƒíƒœ í™•ì¥"
    echo "  - ğŸ“ˆ í•™ìŠµ ì „í›„ ì„±ëŠ¥ ë¹„êµ"
    exit 1
fi

if [ ! -d "$BASE_MODEL_DIR" ]; then
    echo "âŒ ê¸°ì¡´ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $BASE_MODEL_DIR"
    exit 1
fi

if [ ! -d "$NEW_LOG_DIR" ]; then
    echo "âŒ ìƒˆë¡œìš´ ë¡œê·¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $NEW_LOG_DIR"
    exit 1
fi

# í•„ìˆ˜ ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ë“¤ í™•ì¸
required_files=(
    "$BASE_MODEL_DIR/vocab.json"
    "$BASE_MODEL_DIR/drain3_state.json"
    "$BASE_MODEL_DIR/metadata.json"
)

echo "ğŸ” ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ í™•ì¸ ì¤‘..."
missing_required=false
for file in "${required_files[@]}"; do
    if [ ! -f "$file" ]; then
        echo "âŒ í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: $(basename "$file")"
        missing_required=true
    else
        echo "âœ… $(basename "$file")"
    fi
done

if [ "$missing_required" = true ]; then
    echo ""
    echo "âŒ í•„ìˆ˜ ëª¨ë¸ íŒŒì¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì™„ì „í•œ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
    exit 1
fi

# ê°€ìƒí™˜ê²½ ìë™ ê°ì§€ ë° í™œì„±í™”
VENV_ACTIVATED=false

if [ -n "$VIRTUAL_ENV" ]; then
    echo "ğŸ”µ ê¸°ì¡´ ê°€ìƒí™˜ê²½ ê°ì§€ë¨: $VIRTUAL_ENV"
    VENV_ACTIVATED=true
elif [ -f ".venv/bin/activate" ]; then
    echo "ğŸ”µ .venv ê°€ìƒí™˜ê²½ ë°œê²¬, í™œì„±í™” ì¤‘..."
    source .venv/bin/activate
    VENV_ACTIVATED=true
    echo "âœ… ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨: $VIRTUAL_ENV"
elif [ -f "venv/bin/activate" ]; then
    echo "ğŸ”µ venv ê°€ìƒí™˜ê²½ ë°œê²¬, í™œì„±í™” ì¤‘..."
    source venv/bin/activate
    VENV_ACTIVATED=true
    echo "âœ… ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨: $VIRTUAL_ENV"
fi

# Python ëª…ë ¹ì–´ ì„¤ì •
PYTHON_CMD="python"
if [ "$VENV_ACTIVATED" = false ]; then
    PYTHON_CMD="python3"
fi

# í”„ë¡œì íŠ¸ ì„¤ì¹˜ í™•ì¸
if ! $PYTHON_CMD -c "import study_preprocessor" 2>/dev/null; then
    echo "ğŸ”§ study_preprocessor íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
    .venv/bin/pip install -e . || {
        echo "âŒ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨"
        exit 1
    }
    echo "âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"
fi

# ê²°ê³¼ ëª¨ë¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p "$OUTPUT_MODEL_DIR"
WORK_DIR="$OUTPUT_MODEL_DIR/incremental_workspace"
mkdir -p "$WORK_DIR"

echo ""
echo "ğŸš€ ì ì§„ì  ëª¨ë¸ í•™ìŠµ ì‹œì‘"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“‚ ê¸°ì¡´ ëª¨ë¸ ë””ë ‰í† ë¦¬: $BASE_MODEL_DIR"
echo "ğŸ“‚ ìƒˆë¡œìš´ ë¡œê·¸ ë””ë ‰í† ë¦¬: $NEW_LOG_DIR"
echo "ğŸ’¾ ê²°ê³¼ ëª¨ë¸ ë””ë ‰í† ë¦¬: $OUTPUT_MODEL_DIR"
echo "ğŸ“Š ìŠ¤ìº” ê¹Šì´: $MAX_DEPTH, ìµœëŒ€ íŒŒì¼: $MAX_FILESê°œ"
echo "ğŸ Python ì‹¤í–‰: $PYTHON_CMD"
echo ""
echo "ğŸ”„ ìˆ˜í–‰í•  ì ì§„ì  í•™ìŠµ ë‹¨ê³„:"
echo "  1ï¸âƒ£  ê¸°ì¡´ ëª¨ë¸ ìƒíƒœ ë³µì‚¬ ë° ë°±ì—…"
echo "  2ï¸âƒ£  ìƒˆë¡œìš´ ë¡œê·¸ íŒŒì¼ ìŠ¤ìº” ë° ìˆ˜ì§‘"
echo "  3ï¸âƒ£  ê¸°ì¡´ Drain3 ìƒíƒœë¡œ ìƒˆ ë¡œê·¸ ì „ì²˜ë¦¬"
echo "  4ï¸âƒ£  ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì ì§„ì  ì—…ë°ì´íŠ¸"
echo "  5ï¸âƒ£  DeepLog ëª¨ë¸ ì ì§„ì  í•™ìŠµ"
echo "  6ï¸âƒ£  MS-CRED ëª¨ë¸ ì ì§„ì  í•™ìŠµ"
echo "  7ï¸âƒ£  í•™ìŠµ ì „í›„ ì„±ëŠ¥ ë¹„êµ"
echo "  8ï¸âƒ£  ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° ì €ì¥"
echo ""
echo "â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: 5-20ë¶„ (ìƒˆ ë°ì´í„° í¬ê¸°ì— ë”°ë¼)"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# ì‹œì‘ ì‹œê°„ ê¸°ë¡
START_TIME=$(date +%s)

# 1ë‹¨ê³„: ê¸°ì¡´ ëª¨ë¸ ìƒíƒœ ë³µì‚¬
echo "1ï¸âƒ£  ê¸°ì¡´ ëª¨ë¸ ìƒíƒœ ë³µì‚¬ ì¤‘..."

# ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ë“¤ì„ ìƒˆ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
cp -r "$BASE_MODEL_DIR"/* "$OUTPUT_MODEL_DIR/"

# ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
BACKUP_DIR="$OUTPUT_MODEL_DIR/original_backup"
mkdir -p "$BACKUP_DIR"
cp "$BASE_MODEL_DIR"/*.json "$BACKUP_DIR/" 2>/dev/null || true
cp "$BASE_MODEL_DIR"/*.pth "$BACKUP_DIR/" 2>/dev/null || true

echo "âœ… ê¸°ì¡´ ëª¨ë¸ ìƒíƒœ ë³µì‚¬ ì™„ë£Œ"
echo "   ë°±ì—… ìœ„ì¹˜: $BACKUP_DIR"
echo ""

# 2ë‹¨ê³„: ìƒˆë¡œìš´ ë¡œê·¸ íŒŒì¼ ìŠ¤ìº”
echo "2ï¸âƒ£  ìƒˆë¡œìš´ ë¡œê·¸ íŒŒì¼ ìŠ¤ìº” ì¤‘..."
new_log_files=()
log_patterns=("*.log" "*.txt" "*.out" "*.log.*" "*.syslog" "*.messages")

for pattern in "${log_patterns[@]}"; do
    while IFS= read -r -d '' file; do
        if [ -f "$file" ] && [ -s "$file" ]; then
            new_log_files+=("$file")
        fi
    done < <(find "$NEW_LOG_DIR" -maxdepth "$MAX_DEPTH" -name "$pattern" -type f -print0 2>/dev/null)
done

# íŒŒì¼ í¬ê¸°ìˆœ ì •ë ¬ ë° ì œí•œ
if [ ${#new_log_files[@]} -gt 0 ]; then
    # íŒŒì¼ í¬ê¸°ìˆœ ì •ë ¬
    printf '%s\n' "${new_log_files[@]}" | while read -r file; do
        size=$(stat -c%s "$file" 2>/dev/null || echo 0)
        echo "$size $file"
    done | sort -nr | head -"$MAX_FILES" | cut -d' ' -f2- > "$WORK_DIR/new_selected_files.txt"
    
    mapfile -t selected_new_files < "$WORK_DIR/new_selected_files.txt"
    echo "âœ… ë°œê²¬ëœ ìƒˆ ë¡œê·¸ íŒŒì¼: ${#new_log_files[@]}ê°œ, ì„ íƒëœ íŒŒì¼: ${#selected_new_files[@]}ê°œ"
    
    # ì„ íƒëœ íŒŒì¼ë“¤ ì¶œë ¥
    echo "ğŸ“‹ ì ì§„ì  í•™ìŠµì— ì‚¬ìš©í•  ìƒˆ íŒŒì¼ë“¤:"
    for i in "${!selected_new_files[@]}"; do
        file="${selected_new_files[$i]}"
        size=$(stat -c%s "$file" 2>/dev/null | numfmt --to=iec)
        echo "  $((i+1)). $(basename "$file") ($size)"
        if [ $i -ge 9 ]; then
            echo "  ... ë° $((${#selected_new_files[@]} - 10))ê°œ íŒŒì¼ ë”"
            break
        fi
    done
else
    echo "âŒ ìƒˆë¡œìš´ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    exit 1
fi
echo ""

# 3ë‹¨ê³„: ìƒˆ ë¡œê·¸ ì „ì²˜ë¦¬ (ê¸°ì¡´ Drain3 ìƒíƒœ ì‚¬ìš©)
echo "3ï¸âƒ£  ìƒˆ ë¡œê·¸ ì „ì²˜ë¦¬ ì¤‘ (ê¸°ì¡´ Drain3 ìƒíƒœ í™•ì¥)..."
NEW_MERGED_LOG="$WORK_DIR/new_merged.log"
UPDATED_DRAIN_STATE="$OUTPUT_MODEL_DIR/drain3_state.json"

# ìƒˆ ë¡œê·¸ íŒŒì¼ë“¤ ë³‘í•©
> "$NEW_MERGED_LOG"  # íŒŒì¼ ì´ˆê¸°í™”
for file in "${selected_new_files[@]}"; do
    echo "   ì²˜ë¦¬ ì¤‘: $(basename "$file")"
    cat "$file" >> "$NEW_MERGED_LOG"
done

echo "âœ… ìƒˆ ë¡œê·¸ ë³‘í•© ì™„ë£Œ: $(stat -c%s "$NEW_MERGED_LOG" | numfmt --to=iec)"

# ê¸°ì¡´ Drain3 ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆ ë¡œê·¸ ì „ì²˜ë¦¬
echo "   ê¸°ì¡´ Drain3 ìƒíƒœë¡œ ìƒˆ ë¡œê·¸ íŒŒì‹± ì¤‘..."
$PYTHON_CMD -c "
from study_preprocessor.preprocess import LogPreprocessor, PreprocessConfig
from pathlib import Path
import json

try:
    # ì „ì²˜ë¦¬ ì„¤ì • (ê¸°ì¡´ Drain3 ìƒíƒœ ì‚¬ìš©)
    cfg = PreprocessConfig(drain_state_path='$UPDATED_DRAIN_STATE')
    pre = LogPreprocessor(cfg)
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    df = pre.process_file('$NEW_MERGED_LOG')
    print(f'ìƒˆ ë¡œê·¸ ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)} ë ˆì½”ë“œ ìƒì„±')
    
    # ê²°ê³¼ ì €ì¥
    output_dir = Path('$WORK_DIR')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    parquet_path = output_dir / 'parsed.parquet'
    df.to_parquet(parquet_path, index=False)
    
    # ë¯¸ë¦¬ë³´ê¸° ì €ì¥
    preview = df.head(10).to_dict(orient='records')
    (output_dir / 'new_preview.json').write_text(json.dumps(preview, ensure_ascii=False, default=str, indent=2))
    
    print(f'ì €ì¥ ì™„ë£Œ: {parquet_path}')
    
except Exception as e:
    print(f'ìƒˆ ë¡œê·¸ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"

if [ ! -f "$WORK_DIR/parsed.parquet" ]; then
    echo "âŒ ìƒˆ ë¡œê·¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨"
    exit 1
fi

# ì „ì²˜ë¦¬ ê²°ê³¼ í†µê³„
new_log_lines=$(wc -l < "$NEW_MERGED_LOG")
new_parsed_records=$(python3 -c "import pandas as pd; print(len(pd.read_parquet('$WORK_DIR/parsed.parquet')))" 2>/dev/null || echo "N/A")
echo "âœ… ìƒˆ ë¡œê·¸ ì „ì²˜ë¦¬ ì™„ë£Œ: $new_log_lines ë¼ì¸ â†’ $new_parsed_records ë ˆì½”ë“œ"

# ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° í†µí•©
echo "   ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° í†µí•© ì¤‘..."
$PYTHON_CMD -c "
import pandas as pd
import json
import os

# ê¸°ì¡´ í•™ìŠµ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
old_training_data = None
if os.path.exists('$OUTPUT_MODEL_DIR/training_workspace/parsed.parquet'):
    old_training_data = pd.read_parquet('$OUTPUT_MODEL_DIR/training_workspace/parsed.parquet')
    print(f'ê¸°ì¡´ í•™ìŠµ ë°ì´í„°: {len(old_training_data):,} ë ˆì½”ë“œ')

# ìƒˆ ë°ì´í„° ë¡œë“œ
new_data = pd.read_parquet('$WORK_DIR/parsed.parquet')
print(f'ìƒˆ ë°ì´í„°: {len(new_data):,} ë ˆì½”ë“œ')

# ë°ì´í„° í†µí•©
if old_training_data is not None:
    combined_data = pd.concat([old_training_data, new_data], ignore_index=True)
    print(f'í†µí•© ë°ì´í„°: {len(combined_data):,} ë ˆì½”ë“œ')
else:
    combined_data = new_data
    print(f'í†µí•© ë°ì´í„°: {len(combined_data):,} ë ˆì½”ë“œ (ìƒˆ ë°ì´í„°ë§Œ)')

# í†µí•©ëœ ë°ì´í„° ì €ì¥
os.makedirs('$OUTPUT_MODEL_DIR/training_workspace', exist_ok=True)
combined_data.to_parquet('$OUTPUT_MODEL_DIR/training_workspace/parsed.parquet', index=False)
combined_data.to_parquet('$WORK_DIR/combined_parsed.parquet', index=False)

print('âœ… ë°ì´í„° í†µí•© ì™„ë£Œ')
"
echo ""

# 4ë‹¨ê³„: ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì ì§„ì  ì—…ë°ì´íŠ¸
echo "4ï¸âƒ£  ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì ì§„ì  ì—…ë°ì´íŠ¸ ì¤‘..."

# í†µí•©ëœ ë°ì´í„°ë¡œ ë² ì´ìŠ¤ë¼ì¸ ì¬ê³„ì‚°
$PYTHON_CMD -c "
from study_preprocessor.detect import baseline_detect, BaselineParams

try:
    # ë² ì´ìŠ¤ë¼ì¸ íƒì§€ ì„¤ì •
    params = BaselineParams(window_size=50, stride=25, ewm_alpha=0.3, anomaly_quantile=0.95)
    
    print('ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸ ì‹œì‘...')
    
    # ë² ì´ìŠ¤ë¼ì¸ íƒì§€ ì‹¤í–‰
    result_path = baseline_detect(
        parsed_parquet='$WORK_DIR/combined_parsed.parquet',
        out_dir='$WORK_DIR',
        params=params
    )
    
    print(f'ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {result_path}')
    
except Exception as e:
    print(f'ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"

if [ -f "$WORK_DIR/baseline_scores.parquet" ]; then
    # ì—…ë°ì´íŠ¸ëœ ë² ì´ìŠ¤ë¼ì¸ í†µê³„ë¥¼ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
    cp "$WORK_DIR/baseline_scores.parquet" "$OUTPUT_MODEL_DIR/"
    
    # ê¸°ì¡´ í†µê³„ì™€ ë¹„êµí•˜ì—¬ ì—…ë°ì´íŠ¸ëœ ì •ìƒ íŒ¨í„´ í†µê³„ ìƒì„±
    $PYTHON_CMD -c "
import pandas as pd
import json
import numpy as np
import os

# ìƒˆë¡œìš´ ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼ ë¡œë“œ
new_df = pd.read_parquet('$WORK_DIR/baseline_scores.parquet')

# ê¸°ì¡´ í†µê³„ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
old_stats = {}
if os.path.exists('$BACKUP_DIR/baseline_stats.json'):
    with open('$BACKUP_DIR/baseline_stats.json', 'r') as f:
        old_stats = json.load(f)

# ìƒˆë¡œìš´ ì •ìƒ íŒ¨í„´ í†µê³„ ê³„ì‚°
normal_windows = new_df[new_df['is_anomaly'] == False]

# ì •ìƒ ìœˆë„ìš°ê°€ ìˆëŠ”ì§€ í™•ì¸
if len(normal_windows) > 0:
    unseen_stats = {
        'mean_unseen_rate': float(normal_windows['unseen_rate'].mean()),
        'std_unseen_rate': float(normal_windows['unseen_rate'].std()),
    }
    frequency_stats = {
        'mean_freq_z': float(normal_windows['freq_z'].mean()),
        'std_freq_z': float(normal_windows['freq_z'].std()),
        'mean_score': float(normal_windows['score'].mean()),
        'std_score': float(normal_windows['score'].std()),
    }
else:
    # ì •ìƒ ìœˆë„ìš°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©
    unseen_stats = {
        'mean_unseen_rate': 0.0,
        'std_unseen_rate': 0.0,
    }
    frequency_stats = {
        'mean_freq_z': 0.0,
        'std_freq_z': 0.0,
        'mean_score': 0.0,
        'std_score': 0.0,
    }

new_stats = {
    'total_windows': len(new_df),
    'normal_windows': len(normal_windows),
    'anomaly_rate': float((new_df['is_anomaly'] == True).mean()),
    'unseen_stats': unseen_stats,
    'frequency_stats': frequency_stats,
    'incremental_info': {
        'previous_normal_windows': old_stats.get('normal_windows', 0),
        'added_normal_windows': len(normal_windows) - old_stats.get('normal_windows', 0),
        'improvement_ratio': len(normal_windows) / max(old_stats.get('normal_windows', 0), 1)
    }
}

with open('$OUTPUT_MODEL_DIR/baseline_stats.json', 'w') as f:
    json.dump(new_stats, f, indent=2)

print(f'âœ… ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸ ì™„ë£Œ')
print(f'   ê¸°ì¡´ ì •ìƒ ìœˆë„ìš°: {old_stats.get(\"normal_windows\", 0):,}ê°œ')
print(f'   ìƒˆë¡œìš´ ì •ìƒ ìœˆë„ìš°: {new_stats[\"normal_windows\"]:,}ê°œ')
print(f'   ì¶”ê°€ëœ ìœˆë„ìš°: {new_stats[\"incremental_info\"][\"added_normal_windows\"]:,}ê°œ')
"
else
    echo "âš ï¸  ë² ì´ìŠ¤ë¼ì¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨, ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤."
fi
echo ""

# 5ë‹¨ê³„: DeepLog ì ì§„ì  í•™ìŠµ
echo "5ï¸âƒ£  DeepLog ì ì§„ì  í•™ìŠµ ì¤‘..."

# DeepLog ì…ë ¥ ìƒì„± (í†µí•©ëœ ë°ì´í„°ë¡œ)
$PYTHON_CMD -c "
from study_preprocessor.builders.deeplog import build_deeplog_inputs

try:
    print('DeepLog ì…ë ¥ ìƒì„± ì‹œì‘...')
    
    # DeepLog ì…ë ¥ ìƒì„±
    build_deeplog_inputs(
        parsed_parquet='$WORK_DIR/combined_parsed.parquet',
        out_dir='$WORK_DIR'
    )
    
    print('DeepLog ì…ë ¥ ìƒì„± ì™„ë£Œ')
    
except Exception as e:
    print(f'DeepLog ì…ë ¥ ìƒì„± ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"

if [ -f "$WORK_DIR/sequences.parquet" ] && [ -f "$WORK_DIR/vocab.json" ]; then
    # ê¸°ì¡´ DeepLog ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
    if [ -f "$OUTPUT_MODEL_DIR/deeplog.pth" ]; then
        echo "   ê¸°ì¡´ DeepLog ëª¨ë¸ ë°œê²¬, ì ì§„ì  í•™ìŠµ ìˆ˜í–‰..."
        # ì ì§„ì  í•™ìŠµ (ê¸°ì¡´ ëª¨ë¸ì„ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©)
        UPDATED_DEEPLOG_MODEL="$OUTPUT_MODEL_DIR/deeplog.pth"
        $PYTHON_CMD -c "
import torch
import pandas as pd
import json
from study_preprocessor.builders.deeplog import train_deeplog
from pathlib import Path

# ê¸°ì¡´ ëª¨ë¸ì„ ë°±ì—…
import shutil
shutil.copy('$OUTPUT_MODEL_DIR/deeplog.pth', '$BACKUP_DIR/deeplog_original.pth')

# ì ì§„ì  í•™ìŠµ ìˆ˜í–‰ (ì—í¬í¬ ìˆ˜ë¥¼ ì¤„ì—¬ì„œ ê¸°ì¡´ ì§€ì‹ ë³´ì¡´)
print('ê¸°ì¡´ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì ì§„ì  í•™ìŠµ ì‹œì‘...')
updated_model = train_deeplog(
    sequences_parquet='$WORK_DIR/sequences.parquet',
    vocab_json='$WORK_DIR/vocab.json', 
    out_path='$UPDATED_DEEPLOG_MODEL',
    seq_len=50,
    epochs=5,  # ê¸°ì¡´ë³´ë‹¤ ì ì€ ì—í¬í¬ë¡œ ì ì§„ì  í•™ìŠµ
    batch_size=64
)
print(f'âœ… DeepLog ì ì§„ì  í•™ìŠµ ì™„ë£Œ: {updated_model}')
"
    else
        echo "   ê¸°ì¡´ DeepLog ëª¨ë¸ì´ ì—†ìŒ, ìƒˆë¡œ í•™ìŠµ..."
        # ìƒˆë¡œ í•™ìŠµ
        UPDATED_DEEPLOG_MODEL="$OUTPUT_MODEL_DIR/deeplog.pth"
        $PYTHON_CMD -c "
from study_preprocessor.builders.deeplog import train_deeplog

try:
    print('ìƒˆë¡œìš´ DeepLog ëª¨ë¸ í•™ìŠµ ì‹œì‘...')
    
    updated_model = train_deeplog(
        sequences_parquet='$WORK_DIR/sequences.parquet',
        vocab_json='$WORK_DIR/vocab.json',
        out_path='$UPDATED_DEEPLOG_MODEL',
        seq_len=50,
        epochs=10,
        batch_size=64
    )
    
    print(f'DeepLog ëª¨ë¸ í•™ìŠµ ì™„ë£Œ: {updated_model}')
    
except Exception as e:
    print(f'DeepLog ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"
    fi
    
    # ì–´íœ˜ ì‚¬ì „ ì—…ë°ì´íŠ¸
    cp "$WORK_DIR/vocab.json" "$OUTPUT_MODEL_DIR/"
    
    if [ -f "$UPDATED_DEEPLOG_MODEL" ]; then
        echo "âœ… DeepLog ì—…ë°ì´íŠ¸ ì™„ë£Œ: $(stat -c%s "$UPDATED_DEEPLOG_MODEL" | numfmt --to=iec)"
    else
        echo "âŒ DeepLog ì—…ë°ì´íŠ¸ ì‹¤íŒ¨"
    fi
else
    echo "âŒ DeepLog ì…ë ¥ ìƒì„± ì‹¤íŒ¨"
fi
echo ""

# 6ë‹¨ê³„: MS-CRED ì ì§„ì  í•™ìŠµ
echo "6ï¸âƒ£  MS-CRED ì ì§„ì  í•™ìŠµ ì¤‘..."

# MS-CRED ì…ë ¥ ìƒì„± (í†µí•©ëœ ë°ì´í„°ë¡œ)
$PYTHON_CMD -c "
from study_preprocessor.builders.mscred import build_mscred_window_counts

try:
    print('MS-CRED ì…ë ¥ ìƒì„± ì‹œì‘...')
    
    # MS-CRED ì…ë ¥ ìƒì„±
    build_mscred_window_counts(
        parsed_parquet='$WORK_DIR/combined_parsed.parquet',
        out_dir='$WORK_DIR',
        window_size=50,
        stride=25
    )
    
    print('MS-CRED ì…ë ¥ ìƒì„± ì™„ë£Œ')
    
except Exception as e:
    print(f'MS-CRED ì…ë ¥ ìƒì„± ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"

if [ -f "$WORK_DIR/window_counts.parquet" ]; then
    # ê¸°ì¡´ MS-CRED ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
    if [ -f "$OUTPUT_MODEL_DIR/mscred.pth" ]; then
        echo "   ê¸°ì¡´ MS-CRED ëª¨ë¸ ë°œê²¬, ì ì§„ì  í•™ìŠµ ìˆ˜í–‰..."
        # ê¸°ì¡´ ëª¨ë¸ ë°±ì—…
        cp "$OUTPUT_MODEL_DIR/mscred.pth" "$BACKUP_DIR/mscred_original.pth"
        
        # ì ì§„ì  í•™ìŠµ (ì—í¬í¬ ìˆ˜ë¥¼ ì¤„ì—¬ì„œ)
        UPDATED_MSCRED_MODEL="$OUTPUT_MODEL_DIR/mscred.pth"
        $PYTHON_CMD -c "
from study_preprocessor.mscred_model import train_mscred

try:
    print('ê¸°ì¡´ MS-CRED ëª¨ë¸ ì ì§„ì  í•™ìŠµ ì‹œì‘...')
    
    train_mscred(
        window_counts_path='$WORK_DIR/window_counts.parquet',
        model_output_path='$UPDATED_MSCRED_MODEL',
        epochs=25  # ê¸°ì¡´ë³´ë‹¤ ì ì€ ì—í¬í¬
    )
    
    print('MS-CRED ì ì§„ì  í•™ìŠµ ì™„ë£Œ')
    
except Exception as e:
    print(f'MS-CRED ì ì§„ì  í•™ìŠµ ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"
    else
        echo "   ê¸°ì¡´ MS-CRED ëª¨ë¸ì´ ì—†ìŒ, ìƒˆë¡œ í•™ìŠµ..."
        # ìƒˆë¡œ í•™ìŠµ
        UPDATED_MSCRED_MODEL="$OUTPUT_MODEL_DIR/mscred.pth"
        $PYTHON_CMD -c "
from study_preprocessor.mscred_model import train_mscred

try:
    print('ìƒˆë¡œìš´ MS-CRED ëª¨ë¸ í•™ìŠµ ì‹œì‘...')
    
    train_mscred(
        window_counts_path='$WORK_DIR/window_counts.parquet',
        model_output_path='$UPDATED_MSCRED_MODEL',
        epochs=50
    )
    
    print('MS-CRED ëª¨ë¸ í•™ìŠµ ì™„ë£Œ')
    
except Exception as e:
    print(f'MS-CRED ëª¨ë¸ í•™ìŠµ ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"
    fi
    
    if [ -f "$UPDATED_MSCRED_MODEL" ]; then
        echo "âœ… MS-CRED ì—…ë°ì´íŠ¸ ì™„ë£Œ: $(stat -c%s "$UPDATED_MSCRED_MODEL" | numfmt --to=iec)"
    else
        echo "âŒ MS-CRED ì—…ë°ì´íŠ¸ ì‹¤íŒ¨"
    fi
else
    echo "âŒ MS-CRED ì…ë ¥ ìƒì„± ì‹¤íŒ¨"
fi
echo ""

# 7ë‹¨ê³„: í•™ìŠµ ì „í›„ ì„±ëŠ¥ ë¹„êµ
echo "7ï¸âƒ£  í•™ìŠµ ì „í›„ ì„±ëŠ¥ ë¹„êµ ì¤‘..."

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì„±ëŠ¥ ë¹„êµ (í•©ì„± ë°ì´í„° ì‚¬ìš©)
COMPARISON_DIR="$OUTPUT_MODEL_DIR/performance_comparison"
mkdir -p "$COMPARISON_DIR"

# ê°„ë‹¨í•œ í•©ì„± í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
$PYTHON_CMD -c "
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random

# í•©ì„± í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± (ì‘ì€ í¬ê¸°)
np.random.seed(42)
random.seed(42)

templates = [
    'INFO: User <*> logged in',
    'INFO: Processing request <*>',
    'WARNING: High memory usage',
    'ERROR: Connection timeout'
]

logs = []
start_time = datetime.now() - timedelta(hours=1)

for i in range(1000):
    timestamp = start_time + timedelta(seconds=i*3)
    template = random.choice(templates)
    log_line = f'{timestamp.strftime(\"%Y-%m-%d %H:%M:%S\")} {template}'
    logs.append(log_line)

with open('$COMPARISON_DIR/test_data.log', 'w') as f:
    for log in logs:
        f.write(log + '\\n')

print('âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: 1,000 ë¼ì¸')
"

# ê¸°ì¡´ ëª¨ë¸ê³¼ ìƒˆ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ (compare_models.sh ì‚¬ìš©)
if [ -f "compare_models.sh" ]; then
    echo "   ê¸°ì¡´ ëª¨ë¸ vs ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì¤‘..."
    ./compare_models.sh "$BACKUP_DIR" "$OUTPUT_MODEL_DIR" "$COMPARISON_DIR/test_data.log" "$COMPARISON_DIR" > "$COMPARISON_DIR/comparison.log" 2>&1 || true
    
    if [ -f "$COMPARISON_DIR/comparison_report.md" ]; then
        echo "âœ… ì„±ëŠ¥ ë¹„êµ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„±ë¨"
    else
        echo "âš ï¸  ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰ë¨, ìƒì„¸ ë¡œê·¸ í™•ì¸: $COMPARISON_DIR/comparison.log"
    fi
else
    echo "âš ï¸  compare_models.shê°€ ì—†ì–´ ì„±ëŠ¥ ë¹„êµë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
fi
echo ""

# 8ë‹¨ê³„: ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° ì €ì¥
echo "8ï¸âƒ£  ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° ì €ì¥ ì¤‘..."

# ì ì§„ì  í•™ìŠµ ì •ë³´ ë©”íƒ€ë°ì´í„° ìƒì„±
$PYTHON_CMD -c "
import json
import os
from datetime import datetime
from pathlib import Path

# ê¸°ì¡´ ë©”íƒ€ë°ì´í„° ë¡œë“œ
old_metadata = {}
if os.path.exists('$BACKUP_DIR/metadata.json'):
    with open('$BACKUP_DIR/metadata.json', 'r') as f:
        old_metadata = json.load(f)

# ìƒˆë¡œìš´ ë©”íƒ€ë°ì´í„° ìƒì„±
new_metadata = {
    'incremental_training_info': {
        'timestamp': datetime.now().isoformat(),
        'base_model_directory': '$BASE_MODEL_DIR',
        'new_log_directory': '$NEW_LOG_DIR',
        'total_new_files': ${#selected_new_files[@]},
        'max_depth': $MAX_DEPTH,
        'max_files': $MAX_FILES,
        'previous_training': old_metadata.get('training_info', {})
    },
    'models': {
        'deeplog': os.path.exists('$OUTPUT_MODEL_DIR/deeplog.pth'),
        'mscred': os.path.exists('$OUTPUT_MODEL_DIR/mscred.pth'),
        'baseline_stats': os.path.exists('$OUTPUT_MODEL_DIR/baseline_stats.json'),
        'drain3_state': os.path.exists('$OUTPUT_MODEL_DIR/drain3_state.json'),
        'vocab': os.path.exists('$OUTPUT_MODEL_DIR/vocab.json')
    },
    'incremental_files': [],  # íŒŒì¼ ëª©ë¡ì€ ë³„ë„ë¡œ ì²˜ë¦¬
    'backup_location': '$BACKUP_DIR',
    'performance_comparison': '$COMPARISON_DIR'
}

# íŒŒì¼ ëª©ë¡ ì¶”ê°€ (íŒŒì¼ì—ì„œ ì½ê¸°)
try:
    if os.path.exists('$WORK_DIR/new_selected_files.txt'):
        with open('$WORK_DIR/new_selected_files.txt', 'r') as f:
            file_list = [line.strip() for line in f.readlines() if line.strip()]
        
        # ê²½ë¡œì—ì„œ ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì œê±°
        new_log_dir = '$NEW_LOG_DIR'
        relative_files = []
        for f in file_list[:20]:  # ìµœëŒ€ 20ê°œë§Œ
            if f.startswith(new_log_dir):
                relative_files.append(f.replace(new_log_dir + '/', '').replace(new_log_dir, ''))
            else:
                relative_files.append(os.path.basename(f))
        
        new_metadata['incremental_files'] = relative_files
    else:
        new_metadata['incremental_files'] = ['íŒŒì¼ ëª©ë¡ íŒŒì¼ ì—†ìŒ']
except Exception as e:
    new_metadata['incremental_files'] = [f'íŒŒì¼ ëª©ë¡ ìƒì„± ì‹¤íŒ¨: {str(e)}']

# ê¸°ì¡´ ë©”íƒ€ë°ì´í„°ì™€ ë³‘í•©
if old_metadata:
    new_metadata['original_metadata'] = old_metadata

with open('$OUTPUT_MODEL_DIR/metadata.json', 'w') as f:
    json.dump(new_metadata, f, indent=2, ensure_ascii=False)

print('âœ… ì ì§„ì  í•™ìŠµ ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ')
"

# ì¢…ë£Œ ì‹œê°„ ë° ì†Œìš” ì‹œê°„ ê³„ì‚°
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
MINUTES=$((DURATION / 60))
SECONDS=$((DURATION % 60))

echo ""
echo "ğŸ‰ ì ì§„ì  ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "â±ï¸  ì´ ì†Œìš” ì‹œê°„: ${MINUTES}ë¶„ ${SECONDS}ì´ˆ"
echo ""

# ê²°ê³¼ ìš”ì•½ ì¶œë ¥
echo "ğŸ“Š ì ì§„ì  í•™ìŠµ ê²°ê³¼:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

models_updated=0
if [ -f "$OUTPUT_MODEL_DIR/deeplog.pth" ]; then
    old_size=$(stat -c%s "$BACKUP_DIR/deeplog_original.pth" 2>/dev/null | numfmt --to=iec || echo "N/A")
    new_size=$(stat -c%s "$OUTPUT_MODEL_DIR/deeplog.pth" | numfmt --to=iec)
    echo "  ğŸ§  DeepLog ëª¨ë¸: ì—…ë°ì´íŠ¸ë¨ ($old_size â†’ $new_size)"
    models_updated=$((models_updated + 1))
else
    echo "  âŒ DeepLog ëª¨ë¸: ì—…ë°ì´íŠ¸ ì‹¤íŒ¨"
fi

if [ -f "$OUTPUT_MODEL_DIR/mscred.pth" ]; then
    old_size=$(stat -c%s "$BACKUP_DIR/mscred_original.pth" 2>/dev/null | numfmt --to=iec || echo "N/A")
    new_size=$(stat -c%s "$OUTPUT_MODEL_DIR/mscred.pth" | numfmt --to=iec)
    echo "  ğŸ”¬ MS-CRED ëª¨ë¸: ì—…ë°ì´íŠ¸ë¨ ($old_size â†’ $new_size)"
    models_updated=$((models_updated + 1))
else
    echo "  âŒ MS-CRED ëª¨ë¸: ì—…ë°ì´íŠ¸ ì‹¤íŒ¨"
fi

if [ -f "$OUTPUT_MODEL_DIR/baseline_stats.json" ]; then
    echo "  ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ í†µê³„: ì—…ë°ì´íŠ¸ë¨"
    models_updated=$((models_updated + 1))
else
    echo "  âŒ ë² ì´ìŠ¤ë¼ì¸ í†µê³„: ì—…ë°ì´íŠ¸ ì‹¤íŒ¨"
fi

echo ""
echo "ğŸ“ˆ ì ì§„ì  í•™ìŠµ í†µê³„:"
echo "  âœ… ì—…ë°ì´íŠ¸ëœ ëª¨ë¸: ${models_updated}/3ê°œ"
echo "  ğŸ“ ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ ìœ„ì¹˜: $OUTPUT_MODEL_DIR"
echo "  ğŸ’¾ ì›ë³¸ ëª¨ë¸ ë°±ì—…: $BACKUP_DIR"
echo "  ğŸ“Š ì„±ëŠ¥ ë¹„êµ ê²°ê³¼: $COMPARISON_DIR"
echo "  ğŸ“‹ ë©”íƒ€ë°ì´í„°: $OUTPUT_MODEL_DIR/metadata.json"
echo ""

# ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ìš”ì•½ (ìˆëŠ” ê²½ìš°)
if [ -f "$COMPARISON_DIR/comparison_report.md" ]; then
    echo "ğŸ“Š ì„±ëŠ¥ ë¹„êµ ìš”ì•½:"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    grep -E "^\*\*ì¶”ë¡  ì†ë„|^\*\*ì†ë„|^- \*\*" "$COMPARISON_DIR/comparison_report.md" | head -5
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
fi

# ì‚¬ìš©ë²• ì•ˆë‚´
echo "ğŸš€ ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ ì‚¬ìš© ë°©ë²•:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "  ./run_inference.sh $OUTPUT_MODEL_DIR /path/to/target.log"
echo ""
echo "ğŸ’¡ ì„±ëŠ¥ ë¹„êµ í™•ì¸:"
echo "  cat $COMPARISON_DIR/comparison_report.md"
echo ""
echo "ğŸ”„ ì¶”ê°€ ì ì§„ì  í•™ìŠµ:"
echo "  ./train_models_incremental.sh $OUTPUT_MODEL_DIR /path/to/newer_logs/"
echo ""

# ì„ì‹œ ì‘ì—… ë””ë ‰í† ë¦¬ ì •ë¦¬ ì•ˆë‚´
echo "ğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬:"
if [ -d "$WORK_DIR" ]; then
    echo "  ğŸ“ ì„ì‹œ ì‘ì—… ë””ë ‰í† ë¦¬: $WORK_DIR"
    echo "  ğŸ’¡ ì •ë¦¬í•˜ë ¤ë©´: rm -rf $WORK_DIR"
fi

echo ""
echo "ğŸ‰ ì ì§„ì  ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
echo "   - âœ… ê¸°ì¡´ ëª¨ë¸ ìƒíƒœ ë³´ì¡´ ë° í™•ì¥"
echo "   - âœ… ìƒˆë¡œìš´ ë¡œê·¸ ë°ì´í„° ì ì§„ì  ì¶”ê°€" 
echo "   - âœ… DeepLog/MS-CRED ì ì§„ì  í•™ìŠµ"
echo "   - âœ… ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸"
echo "   - âœ… í•™ìŠµ ì „í›„ ì„±ëŠ¥ ë¹„êµ"
echo "   - âœ… ì—…ë°ì´íŠ¸ëœ ë©”íƒ€ë°ì´í„° ì €ì¥"
echo ""
echo "ğŸ” ì´ì œ ì—…ë°ì´íŠ¸ëœ ëª¨ë¸ë¡œ ë” ì •í™•í•œ ì´ìƒíƒì§€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
