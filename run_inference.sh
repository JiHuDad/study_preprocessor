#!/bin/bash

# ë¡œê·¸ ì´ìƒíƒì§€ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
# í•™ìŠµëœ ëª¨ë¸ë“¤ì„ ì‚¬ìš©í•˜ì—¬ Target ë¡œê·¸ íŒŒì¼ì˜ ì´ìƒì„ íƒì§€í•©ë‹ˆë‹¤.
# ì‚¬ìš©ë²•: ./run_inference.sh <ëª¨ë¸ë””ë ‰í† ë¦¬> <targetë¡œê·¸íŒŒì¼> [ê²°ê³¼ë””ë ‰í† ë¦¬]

set -e  # ì—ëŸ¬ ë°œìƒì‹œ ì¦‰ì‹œ ì¤‘ë‹¨

# ê¸°ë³¸ê°’ ì„¤ì •
MODEL_DIR="$1"
TARGET_LOG="$2"
RESULT_DIR="${3:-inference_$(date +%Y%m%d_%H%M%S)}"

# ì¸ìˆ˜ í™•ì¸
if [ -z "$MODEL_DIR" ] || [ -z "$TARGET_LOG" ]; then
    echo "âŒ ì‚¬ìš©ë²•: $0 <ëª¨ë¸ë””ë ‰í† ë¦¬> <targetë¡œê·¸íŒŒì¼> [ê²°ê³¼ë””ë ‰í† ë¦¬]"
    echo ""
    echo "ì˜ˆì‹œ:"
    echo "  $0 models_20241002_143022 /var/log/suspicious.log"
    echo "  $0 models_20241002_143022 /var/log/suspicious.log my_results"
    echo ""
    echo "ğŸ“‹ ì„¤ëª…:"
    echo "  - ëª¨ë¸ë””ë ‰í† ë¦¬: train_models.shë¡œ ìƒì„±ëœ í•™ìŠµ ëª¨ë¸ í´ë”"
    echo "  - targetë¡œê·¸íŒŒì¼: ì´ìƒíƒì§€ë¥¼ ìˆ˜í–‰í•  ë¡œê·¸ íŒŒì¼"
    echo "  - ê²°ê³¼ë””ë ‰í† ë¦¬: ë¶„ì„ ê²°ê³¼ë¥¼ ì €ì¥í•  í´ë” (ìƒëµì‹œ ìë™ ìƒì„±)"
    echo ""
    echo "ğŸ’¡ íŠ¹ì§•:"
    echo "  - ğŸ§  DeepLog LSTM ì´ìƒíƒì§€"
    echo "  - ğŸ”¬ MS-CRED ë©€í‹°ìŠ¤ì¼€ì¼ ì´ìƒíƒì§€"
    echo "  - ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ê¸°ë°˜ ì´ìƒíƒì§€"
    echo "  - ğŸ• ì‹œê°„ ê¸°ë°˜ íŒ¨í„´ ë¶„ì„"
    echo "  - ğŸ“‹ ì‹¤ì œ ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ë° ë¶„ì„"
    echo "  - ğŸ“‹ ì¢…í•© ì´ìƒíƒì§€ ë¦¬í¬íŠ¸ ìƒì„±"
    echo ""
    echo "ğŸ“ í•„ìš”í•œ ëª¨ë¸ íŒŒì¼ë“¤:"
    echo "  - deeplog.pth (DeepLog ëª¨ë¸)"
    echo "  - mscred.pth (MS-CRED ëª¨ë¸)"
    echo "  - vocab.json (ì–´íœ˜ ì‚¬ì „)"
    echo "  - baseline_stats.json (ë² ì´ìŠ¤ë¼ì¸ í†µê³„)"
    echo "  - drain3_state.json (Drain3 ìƒíƒœ)"
    exit 1
fi

if [ ! -d "$MODEL_DIR" ]; then
    echo "âŒ ëª¨ë¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $MODEL_DIR"
    exit 1
fi

if [ ! -f "$TARGET_LOG" ]; then
    echo "âŒ Target ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: $TARGET_LOG"
    exit 1
fi

# ê°€ìƒí™˜ê²½ ìë™ ê°ì§€ ë° í™œì„±í™”
VENV_ACTIVATED=false

# 1. ì´ë¯¸ í™œì„±í™”ëœ ê°€ìƒí™˜ê²½ í™•ì¸
if [ -n "$VIRTUAL_ENV" ]; then
    echo "ğŸ”µ ê¸°ì¡´ ê°€ìƒí™˜ê²½ ê°ì§€ë¨: $VIRTUAL_ENV"
    VENV_ACTIVATED=true
elif [ -f ".venv/bin/activate" ]; then
    echo "ğŸ”µ .venv ê°€ìƒí™˜ê²½ ë°œê²¬, í™œì„±í™” ì¤‘..."
    source .venv/bin/activate
    VENV_ACTIVATED=true
    echo "âœ… ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨: $VIRTUAL_ENV"
elif [ -f "venv/bin/activate" ]; then
    echo "ğŸ”µ venv ê°€ìƒí™˜ê²½ ë°œê²¬, í™œì„±í™” ì¤‘..."
    source venv/bin/activate
    VENV_ACTIVATED=true
    echo "âœ… ê°€ìƒí™˜ê²½ í™œì„±í™”ë¨: $VIRTUAL_ENV"
fi

# Python ëª…ë ¹ì–´ ì„¤ì •
PYTHON_CMD="python"
if [ "$VENV_ACTIVATED" = false ]; then
    PYTHON_CMD="python3"
fi

# í”„ë¡œì íŠ¸ ì„¤ì¹˜ í™•ì¸
if ! $PYTHON_CMD -c "import study_preprocessor" 2>/dev/null; then
    echo "ğŸ”§ study_preprocessor íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘..."
    .venv/bin/pip install -e . || {
        echo "âŒ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨"
        exit 1
    }
    echo "âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ"
fi

# í•„ìˆ˜ ëª¨ë¸ íŒŒì¼ë“¤ í™•ì¸
required_files=(
    "$MODEL_DIR/vocab.json"
    "$MODEL_DIR/drain3_state.json"
)

optional_files=(
    "$MODEL_DIR/deeplog.pth"
    "$MODEL_DIR/mscred.pth"
    "$MODEL_DIR/baseline_stats.json"
)

echo "ğŸ” ëª¨ë¸ íŒŒì¼ í™•ì¸ ì¤‘..."
missing_required=false
for file in "${required_files[@]}"; do
    if [ ! -f "$file" ]; then
        echo "âŒ í•„ìˆ˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: $(basename "$file")"
        missing_required=true
    else
        echo "âœ… $(basename "$file")"
    fi
done

if [ "$missing_required" = true ]; then
    echo ""
    echo "âŒ í•„ìˆ˜ ëª¨ë¸ íŒŒì¼ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. train_models.shë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”."
    exit 1
fi

available_models=()
for file in "${optional_files[@]}"; do
    if [ -f "$file" ]; then
        echo "âœ… $(basename "$file")"
        available_models+=("$(basename "$file")")
    else
        echo "âš ï¸  $(basename "$file") (ì—†ìŒ)"
    fi
done

# ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p "$RESULT_DIR"

echo ""
echo "ğŸš€ ë¡œê·¸ ì´ìƒíƒì§€ ì¶”ë¡  ì‹œì‘"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“‚ ëª¨ë¸ ë””ë ‰í† ë¦¬: $MODEL_DIR"
echo "ğŸ¯ Target ë¡œê·¸ íŒŒì¼: $TARGET_LOG"
echo "ğŸ“ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬: $RESULT_DIR"
echo "ğŸ Python ì‹¤í–‰: $PYTHON_CMD"
echo ""
echo "ğŸ¤– ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤:"
for model in "${available_models[@]}"; do
    echo "  âœ… $model"
done
echo ""
echo "ğŸ”„ ìˆ˜í–‰í•  ì¶”ë¡  ë‹¨ê³„:"
echo "  1ï¸âƒ£  Target ë¡œê·¸ ì „ì²˜ë¦¬ (ê¸°ì¡´ Drain3 ìƒíƒœ ì‚¬ìš©)"
echo "  2ï¸âƒ£  ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ (í•™ìŠµëœ í†µê³„ì™€ ë¹„êµ)"
echo "  3ï¸âƒ£  DeepLog ì¶”ë¡  (LSTM ì‹œí€€ìŠ¤ ì˜ˆì¸¡)"
echo "  4ï¸âƒ£  MS-CRED ì¶”ë¡  (ë©€í‹°ìŠ¤ì¼€ì¼ ì¬êµ¬ì„± ì˜¤ì°¨)"
echo "  5ï¸âƒ£  ì‹œê°„ ê¸°ë°˜ ì´ìƒíƒì§€"
echo "  6ï¸âƒ£  ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ë° ë¶„ì„"
echo "  7ï¸âƒ£  ì¢…í•© ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±"
echo ""
echo "â±ï¸  ì˜ˆìƒ ì†Œìš” ì‹œê°„: 2-10ë¶„ (íŒŒì¼ í¬ê¸°ì— ë”°ë¼)"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# ì‹œì‘ ì‹œê°„ ê¸°ë¡
START_TIME=$(date +%s)

# 1ë‹¨ê³„: Target ë¡œê·¸ ì „ì²˜ë¦¬
echo "1ï¸âƒ£  Target ë¡œê·¸ ì „ì²˜ë¦¬ ì¤‘..."
TARGET_NAME=$(basename "$TARGET_LOG" .log)

# ê¸°ì¡´ Drain3 ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ì²˜ë¦¬
$PYTHON_CMD -c "
from study_preprocessor.preprocess import LogPreprocessor, PreprocessConfig
from pathlib import Path
import json

try:
    # ì „ì²˜ë¦¬ ì„¤ì • (ê¸°ì¡´ Drain3 ìƒíƒœ ì‚¬ìš©)
    cfg = PreprocessConfig(drain_state_path='$MODEL_DIR/drain3_state.json')
    pre = LogPreprocessor(cfg)
    
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    df = pre.process_file('$TARGET_LOG')
    print(f'Target ë¡œê·¸ ì „ì²˜ë¦¬ ì™„ë£Œ: {len(df)} ë ˆì½”ë“œ ìƒì„±')
    
    # ê²°ê³¼ ì €ì¥
    output_dir = Path('$RESULT_DIR')
    output_dir.mkdir(parents=True, exist_ok=True)
    
    parquet_path = output_dir / 'parsed.parquet'
    df.to_parquet(parquet_path, index=False)
    
    # ë¯¸ë¦¬ë³´ê¸° ì €ì¥
    preview = df.head(10).to_dict(orient='records')
    (output_dir / 'preview.json').write_text(json.dumps(preview, ensure_ascii=False, default=str, indent=2))
    
    print(f'ì €ì¥ ì™„ë£Œ: {parquet_path}')
    
except Exception as e:
    print(f'Target ë¡œê·¸ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"

if [ ! -f "$RESULT_DIR/parsed.parquet" ]; then
    echo "âŒ Target ë¡œê·¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨"
    exit 1
fi

# ì „ì²˜ë¦¬ ê²°ê³¼ í†µê³„
log_lines=$(wc -l < "$TARGET_LOG")
parsed_records=$(python3 -c "import pandas as pd; print(len(pd.read_parquet('$RESULT_DIR/parsed.parquet')))" 2>/dev/null || echo "N/A")
echo "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: $log_lines ë¼ì¸ â†’ $parsed_records ë ˆì½”ë“œ"
echo ""

# 2ë‹¨ê³„: ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€
echo "2ï¸âƒ£  ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ ì¤‘..."
if [ -f "$MODEL_DIR/baseline_stats.json" ]; then
    # ë² ì´ìŠ¤ë¼ì¸ íƒì§€ ì‹¤í–‰
    $PYTHON_CMD -c "
from study_preprocessor.detect import baseline_detect, BaselineParams

try:
    # ë² ì´ìŠ¤ë¼ì¸ íƒì§€ ì„¤ì •
    params = BaselineParams(window_size=50, stride=25, ewm_alpha=0.3, anomaly_quantile=0.95)
    
    print('ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ ì‹œì‘...')
    
    # ë² ì´ìŠ¤ë¼ì¸ íƒì§€ ì‹¤í–‰
    result_path = baseline_detect(
        parsed_parquet='$RESULT_DIR/parsed.parquet',
        out_dir='$RESULT_DIR',
        params=params
    )
    
    print(f'ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ ì™„ë£Œ: {result_path}')
    
except Exception as e:
    print(f'ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"
    
    if [ -f "$RESULT_DIR/baseline_scores.parquet" ]; then
        # í•™ìŠµëœ í†µê³„ì™€ ë¹„êµí•˜ì—¬ ì´ìƒ ì •ë„ ê³„ì‚°
        $PYTHON_CMD -c "
import pandas as pd
import json
import numpy as np

# ì¶”ë¡  ê²°ê³¼ì™€ í•™ìŠµ í†µê³„ ë¡œë“œ
infer_df = pd.read_parquet('$RESULT_DIR/baseline_scores.parquet')
with open('$MODEL_DIR/baseline_stats.json', 'r') as f:
    train_stats = json.load(f)

# í•™ìŠµëœ ì •ìƒ íŒ¨í„´ê³¼ ë¹„êµ
normal_unseen_rate_mean = train_stats['unseen_stats']['mean_unseen_rate']
normal_unseen_rate_std = train_stats['unseen_stats']['std_unseen_rate']
normal_freq_mean = train_stats['frequency_stats']['mean_freq_z']
normal_freq_std = train_stats['frequency_stats']['std_freq_z']

# Z-score ê³„ì‚° (í•™ìŠµ í†µê³„ ê¸°ì¤€)
infer_df['unseen_rate_zscore'] = (infer_df['unseen_rate'] - normal_unseen_rate_mean) / (normal_unseen_rate_std + 1e-8)
infer_df['freq_zscore'] = (infer_df['freq_z'] - normal_freq_mean) / (normal_freq_std + 1e-8)

# ì¢…í•© ì´ìƒ ì ìˆ˜ ê³„ì‚°
infer_df['anomaly_score'] = np.sqrt(infer_df['unseen_rate_zscore']**2 + infer_df['freq_zscore']**2)

# ê°•í™”ëœ ì´ìƒ íŒì • (í•™ìŠµ í†µê³„ ê¸°ì¤€)
threshold_95 = np.percentile(infer_df['anomaly_score'], 95)
infer_df['is_strong_anomaly'] = infer_df['anomaly_score'] > threshold_95

# ê²°ê³¼ ì €ì¥
infer_df.to_parquet('$RESULT_DIR/baseline_scores_enhanced.parquet', index=False)

# í†µê³„ ì¶œë ¥
total_windows = len(infer_df)
anomaly_windows = (infer_df['is_anomaly'] == True).sum()
strong_anomaly_windows = (infer_df['is_strong_anomaly'] == True).sum()

print(f'âœ… ë² ì´ìŠ¤ë¼ì¸ ë¶„ì„ ì™„ë£Œ:')
print(f'   ğŸ“Š ì´ ìœˆë„ìš°: {total_windows}ê°œ')
print(f'   ğŸš¨ ê¸°ë³¸ ì´ìƒ: {anomaly_windows}ê°œ ({100*anomaly_windows/total_windows:.1f}%)')
print(f'   ğŸ”¥ ê°•í•œ ì´ìƒ: {strong_anomaly_windows}ê°œ ({100*strong_anomaly_windows/total_windows:.1f}%)')
print(f'   ğŸ“ˆ í‰ê·  ì´ìƒ ì ìˆ˜: {infer_df[\"anomaly_score\"].mean():.3f}')
"
    else
        echo "âš ï¸  ë² ì´ìŠ¤ë¼ì¸ íƒì§€ ì‹¤í–‰ ì‹¤íŒ¨"
    fi
else
    echo "âš ï¸  ë² ì´ìŠ¤ë¼ì¸ í†µê³„ íŒŒì¼ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤."
fi
echo ""

# 3ë‹¨ê³„: DeepLog ì¶”ë¡ 
echo "3ï¸âƒ£  DeepLog ì¶”ë¡  ì¤‘..."
if [ -f "$MODEL_DIR/deeplog.pth" ] && [ -f "$MODEL_DIR/vocab.json" ]; then
    # DeepLog ì…ë ¥ ìƒì„±
    $PYTHON_CMD -c "
from study_preprocessor.builders.deeplog import build_deeplog_inputs

try:
    print('DeepLog ì…ë ¥ ìƒì„± ì‹œì‘...')
    
    # DeepLog ì…ë ¥ ìƒì„±
    build_deeplog_inputs(
        parsed_parquet='$RESULT_DIR/parsed.parquet',
        out_dir='$RESULT_DIR'
    )
    
    print('DeepLog ì…ë ¥ ìƒì„± ì™„ë£Œ')
    
except Exception as e:
    print(f'DeepLog ì…ë ¥ ìƒì„± ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"
    
    if [ -f "$RESULT_DIR/sequences.parquet" ]; then
        # DeepLog ì¶”ë¡  ì‹¤í–‰
        $PYTHON_CMD -c "
from study_preprocessor.builders.deeplog import infer_deeplog_topk
from pathlib import Path

try:
    print('DeepLog ì¶”ë¡  ì‹œì‘...')
    
    # DeepLog ì¶”ë¡  ì‹¤í–‰
    df = infer_deeplog_topk(
        sequences_parquet='$RESULT_DIR/sequences.parquet',
        model_path='$MODEL_DIR/deeplog.pth',
        k=3
    )
    
    # ê²°ê³¼ ì €ì¥
    output_path = Path('$RESULT_DIR') / 'deeplog_infer.parquet'
    df.to_parquet(output_path, index=False)
    
    print(f'DeepLog ì¶”ë¡  ì™„ë£Œ: {len(df)} ì‹œí€€ìŠ¤ ì²˜ë¦¬, ì €ì¥ë¨: {output_path}')
    
except Exception as e:
    print(f'DeepLog ì¶”ë¡  ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"
        
        if [ -f "$RESULT_DIR/deeplog_infer.parquet" ]; then
            # DeepLog ê²°ê³¼ í†µê³„
            $PYTHON_CMD -c "
import pandas as pd
df = pd.read_parquet('$RESULT_DIR/deeplog_infer.parquet')
total_sequences = len(df)
violations = (df['in_topk'] == False).sum()
print(f'âœ… DeepLog ë¶„ì„ ì™„ë£Œ:')
print(f'   ğŸ“Š ì´ ì‹œí€€ìŠ¤: {total_sequences}ê°œ')
if len(df) > 0:
    print(f'   ğŸš¨ Top-K ìœ„ë°˜: {violations}ê°œ ({100*violations/total_sequences:.1f}%)')
else:
    print('   ğŸš¨ Top-K ìœ„ë°˜: 0ê°œ (ì‹œí€€ìŠ¤ ë°ì´í„° ì—†ìŒ - ë¡œê·¸ê°€ ë„ˆë¬´ ì§§ìŒ)')
"
        else
            echo "âš ï¸  DeepLog ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨"
        fi
    else
        echo "âš ï¸  DeepLog ì…ë ¥ ìƒì„± ì‹¤íŒ¨"
    fi
else
    echo "âš ï¸  DeepLog ëª¨ë¸ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤."
fi
echo ""

# 4ë‹¨ê³„: MS-CRED ì¶”ë¡ 
echo "4ï¸âƒ£  MS-CRED ì¶”ë¡  ì¤‘..."
if [ -f "$MODEL_DIR/mscred.pth" ]; then
    # MS-CRED ì…ë ¥ ìƒì„±
    $PYTHON_CMD -c "
from study_preprocessor.builders.mscred import build_mscred_window_counts

try:
    print('MS-CRED ì…ë ¥ ìƒì„± ì‹œì‘...')
    
    # MS-CRED ì…ë ¥ ìƒì„±
    build_mscred_window_counts(
        parsed_parquet='$RESULT_DIR/parsed.parquet',
        out_dir='$RESULT_DIR',
        window_size=50,
        stride=25
    )
    
    print('MS-CRED ì…ë ¥ ìƒì„± ì™„ë£Œ')
    
except Exception as e:
    print(f'MS-CRED ì…ë ¥ ìƒì„± ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"
    
    if [ -f "$RESULT_DIR/window_counts.parquet" ]; then
        # MS-CRED ì¶”ë¡  ì‹¤í–‰
        $PYTHON_CMD -c "
from study_preprocessor.mscred_model import infer_mscred
from pathlib import Path

try:
    print('MS-CRED ì¶”ë¡  ì‹œì‘...')
    
    # MS-CRED ì¶”ë¡  ì‹¤í–‰
    output_path = Path('$RESULT_DIR') / 'mscred_infer.parquet'
    df = infer_mscred(
        window_counts_path='$RESULT_DIR/window_counts.parquet',
        model_path='$MODEL_DIR/mscred.pth',
        output_path=str(output_path),
        threshold_percentile=95.0
    )
    
    print(f'MS-CRED ì¶”ë¡  ì™„ë£Œ: {len(df)} ìœˆë„ìš° ì²˜ë¦¬, ì €ì¥ë¨: {output_path}')
    
except Exception as e:
    print(f'MS-CRED ì¶”ë¡  ì˜¤ë¥˜: {e}')
    import traceback
    traceback.print_exc()
    exit(1)
"
        
        if [ -f "$RESULT_DIR/mscred_infer.parquet" ]; then
            # MS-CRED ê²°ê³¼ í†µê³„
            $PYTHON_CMD -c "
import pandas as pd
df = pd.read_parquet('$RESULT_DIR/mscred_infer.parquet')
total_windows = len(df)
anomalies = (df['is_anomaly'] == True).sum()
print(f'âœ… MS-CRED ë¶„ì„ ì™„ë£Œ:')
print(f'   ğŸ“Š ì´ ìœˆë„ìš°: {total_windows}ê°œ')
print(f'   ğŸš¨ ì´ìƒ ìœˆë„ìš°: {anomalies}ê°œ ({100*anomalies/total_windows:.1f}%)')
print(f'   ğŸ“ˆ í‰ê·  ì¬êµ¬ì„± ì˜¤ì°¨: {df[\"recon_error\"].mean():.4f}')
"
        else
            echo "âš ï¸  MS-CRED ì¶”ë¡  ì‹¤í–‰ ì‹¤íŒ¨"
        fi
    else
        echo "âš ï¸  MS-CRED ì…ë ¥ ìƒì„± ì‹¤íŒ¨"
    fi
else
    echo "âš ï¸  MS-CRED ëª¨ë¸ì´ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤."
fi
echo ""

# 5ë‹¨ê³„: ì‹œê°„ ê¸°ë°˜ ì´ìƒíƒì§€
echo "5ï¸âƒ£  ì‹œê°„ ê¸°ë°˜ ì´ìƒíƒì§€ ì¤‘..."
if [ -f "temporal_anomaly_detector.py" ]; then
    $PYTHON_CMD temporal_anomaly_detector.py --data-dir "$RESULT_DIR" --output-dir "$RESULT_DIR/temporal_analysis"
    
    if [ -f "$RESULT_DIR/temporal_analysis/temporal_anomalies.json" ]; then
        temporal_count=$(python3 -c "import json; data=json.load(open('$RESULT_DIR/temporal_analysis/temporal_anomalies.json')); print(len(data))" 2>/dev/null || echo "N/A")
        echo "âœ… ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ: $temporal_count ê±´ì˜ ì´ìƒ íŒ¨í„´"
    else
        echo "âš ï¸  ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨"
    fi
else
    echo "âš ï¸  temporal_anomaly_detector.pyê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤."
fi
echo ""

# 6ë‹¨ê³„: ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ë° ë¶„ì„
echo "6ï¸âƒ£  ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ë° ë¶„ì„ ì¤‘..."
if [ -f "log_sample_analyzer.py" ]; then
    $PYTHON_CMD log_sample_analyzer.py "$RESULT_DIR" --output-dir "$RESULT_DIR/log_samples_analysis"
    
    if [ -f "$RESULT_DIR/log_samples_analysis/anomaly_analysis_report.md" ]; then
        # ìƒ˜í”Œ í†µê³„ ì¶”ì¶œ
        sample_stats=$(python3 -c "
import json
import os
if os.path.exists('$RESULT_DIR/log_samples_analysis/anomaly_samples.json'):
    with open('$RESULT_DIR/log_samples_analysis/anomaly_samples.json', 'r') as f:
        data = json.load(f)
    
    total_samples = 0
    methods = []
    for method, results in data.items():
        analyzed_count = results.get('analyzed_count', 0)
        if analyzed_count > 0:
            total_samples += analyzed_count
            methods.append(f'{method}({analyzed_count}ê°œ)')
    
    print(f'{total_samples}ê°œ ìƒ˜í”Œ ({', '.join(methods)})')
else:
    print('N/A')
" 2>/dev/null || echo "N/A")
        
        echo "âœ… ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ì™„ë£Œ: $sample_stats"
    else
        echo "âš ï¸  ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ì‹¤í–‰ ì‹¤íŒ¨"
    fi
else
    echo "âš ï¸  log_sample_analyzer.pyê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤."
fi
echo ""

# 7ë‹¨ê³„: ì¢…í•© ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±
echo "7ï¸âƒ£  ì¢…í•© ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."

# ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
$PYTHON_CMD -c "
import pandas as pd
import json
import os
from datetime import datetime

# ê²°ê³¼ íŒŒì¼ë“¤ í™•ì¸
result_files = {
    'baseline': '$RESULT_DIR/baseline_scores_enhanced.parquet',
    'deeplog': '$RESULT_DIR/deeplog_infer.parquet',
    'mscred': '$RESULT_DIR/mscred_infer.parquet',
    'temporal': '$RESULT_DIR/temporal_analysis/temporal_anomalies.json'
}

available_results = {k: v for k, v in result_files.items() if os.path.exists(v)}

# ë¦¬í¬íŠ¸ ìƒì„±
report_lines = []
report_lines.append('# ğŸ” ë¡œê·¸ ì´ìƒíƒì§€ ì¶”ë¡  ê²°ê³¼ ë¦¬í¬íŠ¸')
report_lines.append('')
report_lines.append(f'**ìƒì„± ì‹œê°„**: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')
report_lines.append(f'**Target ë¡œê·¸**: $TARGET_LOG')
report_lines.append(f'**ëª¨ë¸ ë””ë ‰í† ë¦¬**: $MODEL_DIR')
report_lines.append('')

# ê¸°ë³¸ ì •ë³´
if os.path.exists('$RESULT_DIR/parsed.parquet'):
    df = pd.read_parquet('$RESULT_DIR/parsed.parquet')
    report_lines.append('## ğŸ“Š ê¸°ë³¸ ì •ë³´')
    report_lines.append('')
    report_lines.append(f'- **ì´ ë¡œê·¸ ë ˆì½”ë“œ**: {len(df):,}ê°œ')
    report_lines.append(f'- **ê³ ìœ  í…œí”Œë¦¿**: {len(df[\"template_id\"].unique())}ê°œ')
    report_lines.append(f'- **ì‹œê°„ ë²”ìœ„**: {df[\"timestamp\"].min()} ~ {df[\"timestamp\"].max()}')
    report_lines.append('')

# ê° ëª¨ë¸ë³„ ê²°ê³¼
report_lines.append('## ğŸ¤– ëª¨ë¸ë³„ ì´ìƒíƒì§€ ê²°ê³¼')
report_lines.append('')

# ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼
if 'baseline' in available_results:
    df = pd.read_parquet(available_results['baseline'])
    total_windows = len(df)
    basic_anomalies = (df['is_anomaly'] == True).sum()
    strong_anomalies = (df['is_strong_anomaly'] == True).sum() if 'is_strong_anomaly' in df.columns else 0
    
    report_lines.append('### ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€')
    report_lines.append('')
    report_lines.append(f'- **ì´ ìœˆë„ìš°**: {total_windows:,}ê°œ')
    report_lines.append(f'- **ê¸°ë³¸ ì´ìƒ**: {basic_anomalies}ê°œ ({100*basic_anomalies/total_windows:.1f}%)')
    report_lines.append(f'- **ê°•í•œ ì´ìƒ**: {strong_anomalies}ê°œ ({100*strong_anomalies/total_windows:.1f}%)')
    report_lines.append(f'- **í‰ê·  ì´ìƒ ì ìˆ˜**: {df[\"anomaly_score\"].mean():.3f}' if 'anomaly_score' in df.columns else '- **í‰ê·  ì´ìƒ ì ìˆ˜**: N/A')
    report_lines.append('')

# DeepLog ê²°ê³¼
if 'deeplog' in available_results:
    df = pd.read_parquet(available_results['deeplog'])
    total_sequences = len(df)
    violations = (df['in_topk'] == False).sum()
    
    report_lines.append('### ğŸ§  DeepLog ì´ìƒíƒì§€')
    report_lines.append('')
    report_lines.append(f'- **ì´ ì‹œí€€ìŠ¤**: {total_sequences:,}ê°œ')
    if total_sequences > 0:
        report_lines.append(f'- **Top-K ìœ„ë°˜**: {violations}ê°œ ({100*violations/total_sequences:.1f}%)')
    else:
        report_lines.append(f'- **Top-K ìœ„ë°˜**: 0ê°œ (ì‹œí€€ìŠ¤ ì—†ìŒ)')
    report_lines.append('')

# MS-CRED ê²°ê³¼
if 'mscred' in available_results:
    df = pd.read_parquet(available_results['mscred'])
    total_windows = len(df)
    anomalies = (df['is_anomaly'] == True).sum()
    
    report_lines.append('### ğŸ”¬ MS-CRED ì´ìƒíƒì§€')
    report_lines.append('')
    report_lines.append(f'- **ì´ ìœˆë„ìš°**: {total_windows:,}ê°œ')
    report_lines.append(f'- **ì´ìƒ ìœˆë„ìš°**: {anomalies}ê°œ ({100*anomalies/total_windows:.1f}%)')
    report_lines.append(f'- **í‰ê·  ì¬êµ¬ì„± ì˜¤ì°¨**: {df[\"recon_error\"].mean():.4f}')
    report_lines.append('')

# ì‹œê°„ ê¸°ë°˜ ê²°ê³¼
if 'temporal' in available_results:
    with open(available_results['temporal'], 'r') as f:
        temporal_data = json.load(f)
    
    report_lines.append('### ğŸ• ì‹œê°„ ê¸°ë°˜ ì´ìƒíƒì§€')
    report_lines.append('')
    report_lines.append(f'- **ì´ìƒ íŒ¨í„´**: {len(temporal_data)}ê±´')
    report_lines.append('')

# ì¢…í•© ê²°ë¡ 
report_lines.append('## ğŸ¯ ì¢…í•© ê²°ë¡ ')
report_lines.append('')

# ì´ìƒ ì •ë„ ì¢…í•© í‰ê°€
anomaly_indicators = []
if 'baseline' in available_results:
    df = pd.read_parquet(available_results['baseline'])
    if 'is_strong_anomaly' in df.columns:
        strong_rate = (df['is_strong_anomaly'] == True).mean()
        if strong_rate > 0.1:
            anomaly_indicators.append(f'ë² ì´ìŠ¤ë¼ì¸ ê°•í•œ ì´ìƒ ë¹„ìœ¨ ë†’ìŒ ({strong_rate:.1%})')

if 'deeplog' in available_results:
    df = pd.read_parquet(available_results['deeplog'])
    violation_rate = (df['in_topk'] == False).mean()
    if violation_rate > 0.05:
        anomaly_indicators.append(f'DeepLog ìœ„ë°˜ìœ¨ ë†’ìŒ ({violation_rate:.1%})')

if 'mscred' in available_results:
    df = pd.read_parquet(available_results['mscred'])
    anomaly_rate = (df['is_anomaly'] == True).mean()
    if anomaly_rate > 0.05:
        anomaly_indicators.append(f'MS-CRED ì´ìƒìœ¨ ë†’ìŒ ({anomaly_rate:.1%})')

if anomaly_indicators:
    report_lines.append('ğŸš¨ **ì£¼ìš” ì´ìƒ ì§€í‘œ**:')
    for indicator in anomaly_indicators:
        report_lines.append(f'- {indicator}')
else:
    report_lines.append('âœ… **ì „ë°˜ì ìœ¼ë¡œ ì •ìƒ íŒ¨í„´**ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.')

report_lines.append('')
report_lines.append('## ğŸ“ ìƒì„±ëœ íŒŒì¼ë“¤')
report_lines.append('')
for name, path in available_results.items():
    rel_path = os.path.relpath(path, '$RESULT_DIR')
    report_lines.append(f'- **{name}**: {rel_path}')

# ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ê²°ê³¼ ì¶”ê°€
if os.path.exists('$RESULT_DIR/log_samples_analysis/anomaly_analysis_report.md'):
    report_lines.append('- **log_samples**: log_samples_analysis/anomaly_analysis_report.md')

# ë¦¬í¬íŠ¸ ì €ì¥
with open('$RESULT_DIR/inference_report.md', 'w', encoding='utf-8') as f:
    f.write('\\n'.join(report_lines))

print('âœ… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ')
"

# ì¢…ë£Œ ì‹œê°„ ë° ì†Œìš” ì‹œê°„ ê³„ì‚°
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
MINUTES=$((DURATION / 60))
SECONDS=$((DURATION % 60))

echo ""
echo "ğŸ‰ ì´ìƒíƒì§€ ì¶”ë¡  ì™„ë£Œ!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "â±ï¸  ì´ ì†Œìš” ì‹œê°„: ${MINUTES}ë¶„ ${SECONDS}ì´ˆ"
echo ""

# ê²°ê³¼ ìš”ì•½ ì¶œë ¥
echo "ğŸ“Š ì¶”ë¡  ê²°ê³¼ ìš”ì•½:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

completed_analyses=0
total_analyses=5

if [ -f "$RESULT_DIR/baseline_scores_enhanced.parquet" ]; then
    echo "  âœ… ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ ì™„ë£Œ"
    completed_analyses=$((completed_analyses + 1))
else
    echo "  âŒ ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ ì‹¤íŒ¨"
fi

if [ -f "$RESULT_DIR/deeplog_infer.parquet" ]; then
    echo "  âœ… DeepLog ì¶”ë¡  ì™„ë£Œ"
    completed_analyses=$((completed_analyses + 1))
else
    echo "  âŒ DeepLog ì¶”ë¡  ì‹¤íŒ¨"
fi

if [ -f "$RESULT_DIR/mscred_infer.parquet" ]; then
    echo "  âœ… MS-CRED ì¶”ë¡  ì™„ë£Œ"
    completed_analyses=$((completed_analyses + 1))
else
    echo "  âŒ MS-CRED ì¶”ë¡  ì‹¤íŒ¨"
fi

if [ -f "$RESULT_DIR/temporal_analysis/temporal_anomalies.json" ]; then
    echo "  âœ… ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ì™„ë£Œ"
    completed_analyses=$((completed_analyses + 1))
else
    echo "  âŒ ì‹œê°„ ê¸°ë°˜ ë¶„ì„ ì‹¤íŒ¨"
fi

if [ -f "$RESULT_DIR/log_samples_analysis/anomaly_analysis_report.md" ]; then
    echo "  âœ… ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ì™„ë£Œ"
    completed_analyses=$((completed_analyses + 1))
else
    echo "  âŒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ì‹¤íŒ¨"
fi

echo ""
echo "ğŸ“ˆ ì¶”ë¡  ê²°ê³¼ í†µê³„:"
echo "  âœ… ì™„ë£Œëœ ë¶„ì„: ${completed_analyses}/${total_analyses}ê°œ"
echo "  ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: $RESULT_DIR"
echo "  ğŸ“‹ ì¢…í•© ë¦¬í¬íŠ¸: $RESULT_DIR/inference_report.md"
echo ""

# ì£¼ìš” ê²°ê³¼ íŒŒì¼ë“¤ ë‚˜ì—´
echo "ğŸ“Š ìƒì„±ëœ ì£¼ìš” íŒŒì¼ë“¤:"
find "$RESULT_DIR" -name "*.parquet" -o -name "*.json" -o -name "*.md" | sort | while read file; do
    rel_path=$(echo "$file" | sed "s|^$(pwd)/||")
    size=$(stat -c%s "$file" 2>/dev/null | numfmt --to=iec)
    echo "  ğŸ“ $rel_path ($size)"
done
echo ""

# ë¦¬í¬íŠ¸ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
if [ -f "$RESULT_DIR/inference_report.md" ]; then
    echo "ğŸ“‹ ì¶”ë¡  ê²°ê³¼ ìš”ì•½:"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    
    # ë¦¬í¬íŠ¸ì—ì„œ í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œí•˜ì—¬ ì¶œë ¥
    grep -E "^\*\*|^- \*\*|^ğŸš¨|^âœ…" "$RESULT_DIR/inference_report.md" | head -15
    
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
fi

echo "ğŸ” ìƒì„¸ ë¶„ì„ ëª…ë ¹ì–´:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "  ğŸ“„ ì¢…í•© ë¦¬í¬íŠ¸: cat $RESULT_DIR/inference_report.md"

# ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ë¦¬í¬íŠ¸ ì¶”ì²œ
if [ -f "$RESULT_DIR/log_samples_analysis/anomaly_analysis_report.md" ]; then
    echo "  ğŸ“‹ ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„: cat $RESULT_DIR/log_samples_analysis/anomaly_analysis_report.md"
    echo "  ğŸ“Š ìƒì„¸ ìƒ˜í”Œ ë°ì´í„°: cat $RESULT_DIR/log_samples_analysis/anomaly_samples.json"
fi

# ì¶”ê°€ ë¶„ì„ ë„êµ¬ë“¤ í™•ì¸ ë° ì œì•ˆ
if [ -f "analyze_results.py" ]; then
    echo "  ğŸ“Š ìƒì„¸ ë¶„ì„: $PYTHON_CMD analyze_results.py --data-dir $RESULT_DIR"
fi
if [ -f "visualize_results.py" ]; then
    echo "  ğŸ“ˆ ì‹œê°í™”: $PYTHON_CMD visualize_results.py --data-dir $RESULT_DIR"
fi
if [ -f "mscred_analyzer.py" ] && [ -f "$RESULT_DIR/mscred_infer.parquet" ]; then
    echo "  ğŸ”¬ MS-CRED ë¶„ì„: $PYTHON_CMD mscred_analyzer.py --data-dir $RESULT_DIR"
fi

echo ""
echo "ğŸ’¡ ë‹¤ë¥¸ ë¡œê·¸ íŒŒì¼ ë¶„ì„:"
echo "  ./run_inference.sh $MODEL_DIR /path/to/another.log"
echo ""
echo "ğŸ‰ ì´ìƒíƒì§€ ì¶”ë¡ ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
echo "   - âœ… Target ë¡œê·¸ ì „ì²˜ë¦¬"
echo "   - âœ… ë² ì´ìŠ¤ë¼ì¸ í†µê³„ ê¸°ë°˜ ì´ìƒíƒì§€" 
echo "   - âœ… DeepLog LSTM ì´ìƒíƒì§€"
echo "   - âœ… MS-CRED ì»¨ë³¼ë£¨ì…˜ ì´ìƒíƒì§€"
echo "   - âœ… ì‹œê°„ ê¸°ë°˜ íŒ¨í„´ ë¶„ì„"
echo "   - âœ… ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ ë° ë¶„ì„"
echo "   - âœ… ì¢…í•© ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"
