### Anomaly Log Detector ì‚¬ìš© ê°€ì´ë“œ

**Anomaly Log Detector**ëŠ” ì»¤ë„/ì‹œìŠ¤í…œ ë¡œê·¸(.log) íŒŒì¼ì— ì „ì²˜ë¦¬ì™€ ì´ìƒíƒì§€ë¥¼ ì ìš©í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤. DeepLog, LogBERT, MS-CRED, ê·¸ë¦¬ê³  í†µê³„ì  ë² ì´ìŠ¤ë¼ì¸ ë°©ë²•ì„ ì œê³µí•©ë‹ˆë‹¤. ëª¨ë“  ì˜ˆì‹œëŠ” `venv + pip` ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

## ğŸ†• **ìµœì‹  ì—…ë°ì´íŠ¸ (2025-10-02)**

### âœ¨ **ìƒˆë¡œìš´ ì£¼ìš” ê¸°ëŠ¥ë“¤:**
- **ğŸ”„ í•™ìŠµ/ì¶”ë¡  ë¶„ë¦¬ ì›Œí¬í”Œë¡œìš°**: ëª¨ë¸ í•™ìŠµê³¼ ì¶”ë¡ ì„ ë¶„ë¦¬í•˜ì—¬ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
- **ğŸ“Š ëª¨ë¸ ë¹„êµ ë„êµ¬**: ì„œë¡œ ë‹¤ë¥¸ ì‹œì  ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ ê°ê´€ì  ë¹„êµ
- **ğŸ”„ ì ì§„ì  í•™ìŠµ**: ê¸°ì¡´ ëª¨ë¸ì— ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬ ì§€ì†ì  ê°œì„ 
- **ğŸ” ìë™í™”ëœ ëª¨ë¸ ê²€ì¦**: 0-100ì  í’ˆì§ˆ ì ìˆ˜ë¡œ ëª¨ë¸ ìƒíƒœ ìë™ í‰ê°€
- **ğŸ“‹ ì‹¤ì œ ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ**: ì´ìƒíƒì§€ ê²°ê³¼ì—ì„œ ë¬¸ì œ ë¡œê·¸ë“¤ì„ ìë™ ì¶”ì¶œ ë° ë¶„ì„
- **ğŸ¯ ì™¸ë¶€ Target íŒŒì¼ ì§€ì›**: ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ì„ Targetìœ¼ë¡œ ì§€ì • ê°€ëŠ¥
- **ğŸ“„ ì¢…í•© ë¦¬í¬íŠ¸ í†µí•©**: ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¦¬í¬íŠ¸ë¡œ í†µí•©

#### 1) ì„¤ì¹˜/í™˜ê²½
- ì‚¬ì „ ìš”êµ¬: macOS/Linux, Python 3.11+
- ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”:
```
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
python -m pip install -U pip wheel
```
- íŒ¨í‚¤ì§€ ì„¤ì¹˜(ë‘˜ ì¤‘ í•˜ë‚˜ ì„ íƒ)
  1) ê³ ì • ë²„ì „ ì„¤ì¹˜(requirements.txt):
  ```
  pip install -r requirements.txt
  ```
  2) ê°œë°œ í¸ì˜ë¥¼ ìœ„í•œ editable ì„¤ì¹˜:
```
pip install -e .
```

#### 2) ë‹¨ì¼ .log íŒŒì¼ ì „ì²˜ë¦¬
- ê¸°ë³¸ ì‹¤í–‰:
```
alog-detect parse \
  --input /path/to/your.log \
  --out-dir /path/to/outdir \
  --drain-state .cache/drain3.json
```
- ì£¼ìš” ì‚°ì¶œë¬¼:
  - `/path/to/outdir/parsed.parquet`: ì „ì²˜ë¦¬ ê²°ê³¼(raw/masked/template_id ë“±)
  - `/path/to/outdir/preview.json`: ìƒìœ„ 10í–‰ ë¯¸ë¦¬ë³´ê¸°(ì›ë¬¸ vs ë§ˆìŠ¤í‚¹)

- ë§ˆìŠ¤í‚¹ ì˜µì…˜(ê°œë³„ í† ê¸€): ê¸°ë³¸ì€ ëª¨ë‘ ë§ˆìŠ¤í‚¹ ON, ì•„ë˜ í”Œë˜ê·¸ë¡œ OFF ê°€ëŠ¥
  - `--no-mask-paths`, `--no-mask-hex`, `--no-mask-ips`, `--no-mask-mac`, `--no-mask-uuid`
  - `--no-mask-pid`, `--no-mask-device`, `--no-mask-num`
  - ì˜ˆ: ìˆ«ì/ë””ë°”ì´ìŠ¤ ì ‘ë¯¸ì‚¬ ë§ˆìŠ¤í‚¹ì„ ë„ê³  ì‹¤í–‰
```
alog-detect parse \
  --input /path/to/your.log \
  --out-dir /path/to/outdir \
  --no-mask-device --no-mask-num
```

- Drain3 ìƒíƒœ ì¬ì‚¬ìš©
  - `--drain-state .cache/drain3.json`ë¡œ ìƒíƒœë¥¼ ì €ì¥/ëˆ„ì í•˜ì—¬ í…œí”Œë¦¿ ì¼ê´€ì„±ì„ ìœ ì§€
  - ì—¬ëŸ¬ íŒŒì¼ì„ ìˆœì°¨ ì²˜ë¦¬í•  ë•Œ ê°™ì€ `--drain-state`ë¥¼ ì§€ì •í•˜ë©´ ê¸°ì¡´ í…œí”Œë¦¿ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.

#### 3) ì—¬ëŸ¬ .log íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬
- ì‰˜ ë£¨í”„ ì˜ˆì‹œ:
```
OUT=/path/to/processed
STATE=.cache/drain3.json
mkdir -p "$OUT"
for f in /var/log/*.log; do
  alog-detect parse --input "$f" --out-dir "$OUT/$(basename "$f" .log)" --drain-state "$STATE"
done
```
- ê²°ê³¼ ë³‘í•©(ì„ íƒ):
```
python - <<'PY'
import os, pandas as pd
base = '/path/to/processed'
parts = []
for d in os.listdir(base):
    p = os.path.join(base, d, 'parsed.parquet')
    if os.path.exists(p):
        df = pd.read_parquet(p)
        df['source'] = d
        parts.append(df)
if parts:
    pd.concat(parts, ignore_index=True).to_parquet(os.path.join(base, 'merged.parquet'), index=False)
    print('Merged ->', os.path.join(base, 'merged.parquet'))
else:
    print('No parquet found')
PY
```

#### 4) DeepLog/LogBERT/MSCRED ì…ë ¥ ìƒì„±
- DeepLog ì…ë ¥(ì‚¬ì „/ì‹œí€€ìŠ¤):
```
alog-detect build-deeplog \
  --parsed /path/to/outdir/parsed.parquet \
  --out-dir /path/to/outdir
```
- LogBERT ì…ë ¥(ì‚¬ì „/ì‹œí€€ìŠ¤ + íŠ¹ìˆ˜ í† í°):
```
alog-detect build-logbert \
  --parsed /path/to/outdir/parsed.parquet \
  --out-dir /path/to/outdir \
  --max-seq-len 512
```
- MS-CRED ì…ë ¥(ìœˆë„ìš° ì¹´ìš´íŠ¸):
```
alog-detect build-mscred \
  --parsed /path/to/outdir/parsed.parquet \
  --out-dir /path/to/outdir \
  --window-size 50 --stride 25
```

#### 5) ì´ìƒíƒì§€ ì‹¤í–‰
- ë² ì´ìŠ¤ë¼ì¸(ìƒˆ í…œí”Œë¦¿ ë¹„ìœ¨ + ë¹ˆë„ ê¸‰ë³€):
```
alog-detect detect \
  --parsed /path/to/outdir/parsed.parquet \
  --out-dir /path/to/outdir \
  --window-size 50 --stride 25 --ewm-alpha 0.3 --q 0.95
```
- DeepLog í•™ìŠµ/ì¶”ë¡ :
```
alog-detect deeplog-train \
  --seq /path/to/outdir/sequences.parquet \
  --vocab /path/to/outdir/vocab.json \
  --out .cache/deeplog.pth --seq-len 50 --epochs 3

alog-detect deeplog-infer \
  --seq /path/to/outdir/sequences.parquet \
  --model .cache/deeplog.pth --k 3
```
- LogBERT í•™ìŠµ/ì¶”ë¡  (BERT ê¸°ë°˜):
```
alog-detect logbert-train \
  --seq /path/to/outdir/sequences.parquet \
  --vocab /path/to/outdir/vocab.json \
  --out .cache/logbert.pth --seq-len 128 --epochs 10

alog-detect logbert-infer \
  --seq /path/to/outdir/sequences.parquet \
  --model .cache/logbert.pth \
  --vocab /path/to/outdir/vocab.json \
  --threshold-percentile 95.0
```
- MS-CRED í•™ìŠµ/ì¶”ë¡ :
```
alog-detect mscred-train \
  --window-counts /path/to/outdir/window_counts.parquet \
  --out .cache/mscred.pth --epochs 50

alog-detect mscred-infer \
  --window-counts /path/to/outdir/window_counts.parquet \
  --model .cache/mscred.pth --threshold 95.0
```
- ë¦¬í¬íŠ¸/ìš”ì•½ ìƒì„±:
```
# ê¸°ë³¸ ë¦¬í¬íŠ¸
alog-detect report --processed-dir /path/to/outdir

# ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ í¬í•¨ ë¦¬í¬íŠ¸
alog-detect report --processed-dir /path/to/outdir --with-samples
```
  - í¬í•¨: ë² ì´ìŠ¤ë¼ì¸ ì´ìƒ ìœˆë„ìš° ë¹„ìœ¨, ìƒìœ„ ìœˆë„ìš°/í…œí”Œë¦¿, DeepLog ìœ„ë°˜ìœ¨
  - `--with-samples`: ì‹¤ì œ ë¬¸ì œ ë¡œê·¸ ìƒ˜í”Œê³¼ ë¶„ì„ ì¶”ê°€

- ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ (ë‹¨ë…):
```
alog-detect analyze-samples --processed-dir /path/to/outdir
```
  - ğŸ” ì´ìƒíƒì§€ ê²°ê³¼ì—ì„œ ì‹¤ì œ ë¬¸ì œ ë¡œê·¸ë“¤ ì¶”ì¶œ
  - ğŸ“„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
  - ğŸ¯ ì „í›„ ë§¥ë½ê³¼ í•¨ê»˜ ì´ìƒ íŒ¨í„´ ì„¤ëª…

#### 6) í•©ì„± ë°ì´í„°ë¡œ E2E ê²€ì¦(ì˜µì…˜)
```
# í•©ì„± ë¡œê·¸ + ë¼ë²¨ ìƒì„±
alog-detect gen-synth --out data/raw/synth_long.log --lines 1000 --anomaly-rate 0.03

# ì „ì²˜ë¦¬ â†’ ë¹Œë” â†’ íƒì§€ â†’ í•™ìŠµ/ì¶”ë¡  â†’ ë¦¬í¬íŠ¸/í‰ê°€
alog-detect parse --input data/raw/synth_long.log --out-dir data/processed/synth --drain-state .cache/drain3.json
alog-detect build-deeplog --parsed data/processed/synth/parsed.parquet --out-dir data/processed/synth
alog-detect detect --parsed data/processed/synth/parsed.parquet --out-dir data/processed/synth --window-size 50 --stride 25 --ewm-alpha 0.3 --q 0.95
alog-detect deeplog-train --seq data/processed/synth/sequences.parquet --vocab data/processed/synth/vocab.json --out .cache/deeplog_synth.pth --seq-len 20 --epochs 2
alog-detect deeplog-infer --seq data/processed/synth/sequences.parquet --model .cache/deeplog_synth.pth --k 3
alog-detect report --processed-dir data/processed/synth
alog-detect eval --processed-dir data/processed/synth --labels data/raw/synth_long.log.labels.parquet --window-size 50 --seq-len 20
```

#### 7) ë¬¸ì œ í•´ê²° íŒ
- í…œí”Œë¦¿ì´ ê³¼ë„í•˜ê²Œ ëŠ˜ì–´ë‚˜ëŠ” ê²½ìš°: ë§ˆìŠ¤í‚¹ì„ ë” ê°•í•˜ê²Œ í•˜ê±°ë‚˜ `--drain-state`ë¥¼ ìœ ì§€í•˜ë©° ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
- íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± ì‹¤íŒ¨: ë¼ì¸ ì¸ë±ìŠ¤(`line_no`) ê¸°ì¤€ìœ¼ë¡œë„ ì •ë ¬ë˜ë©°, í¬ë§·ì´ ë‹¤ë¥¸ ê²½ìš° ì „ì²˜ë¦¬ ê·œì¹™ ë³´ê°• í•„ìš”
- ë©”ëª¨ë¦¬: ëŒ€í˜• íŒŒì¼ì€ ë””ë ‰í„°ë¦¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ  ì²˜ë¦¬ í›„ ë³‘í•© ê¶Œì¥

#### 8) ìë™í™” ìŠ¤í¬ë¦½íŠ¸ (í•œë²ˆì— ì‹¤í–‰)
ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•œë²ˆì— ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ìŠ¤í¬ë¦½íŠ¸ ì œê³µ:

**uv í™˜ê²½ìš©:**
```bash
./scripts/run_full_pipeline.sh /path/to/your.log [ì¶œë ¥ë””ë ‰í† ë¦¬]
```

**pip/venv í™˜ê²½ìš©:**
```bash
./scripts/run_full_pipeline_pip.sh /path/to/your.log [ì¶œë ¥ë””ë ‰í† ë¦¬]
```

ìë™ ê¸°ëŠ¥:
- ê°€ìƒí™˜ê²½ ìë™ ê°ì§€ ë° í™œì„±í™” (.venv, venv)
- ì˜ì¡´ì„± ìë™ ì„¤ì¹˜ (í•„ìš”ì‹œ)
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì§„í–‰ ìƒí™© í‘œì‹œ
- ê²°ê³¼ íŒŒì¼ ìë™ ì •ë¦¬ ë° ìš”ì•½

#### 9) ğŸ†• **í•™ìŠµ/ì¶”ë¡  ë¶„ë¦¬ ì›Œí¬í”Œë¡œìš°** â­ **ì¶”ì²œ**

íš¨ìœ¨ì ì¸ ëª¨ë¸ ì¬ì‚¬ìš©ì„ ìœ„í•œ ìƒˆë¡œìš´ ì›Œí¬í”Œë¡œìš°:

**1ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ**
```bash
# ì •ìƒ ë¡œê·¸ë¡œ ëª¨ë¸ í•™ìŠµ
./scripts/train_models.sh /var/log/normal/ my_models

# ëª¨ë¸ í’ˆì§ˆ ê²€ì¦
./scripts/validate_models.sh my_models
```

**2ë‹¨ê³„: ì´ìƒíƒì§€ ì¶”ë¡ **
```bash
# Target ë¡œê·¸ ì´ìƒíƒì§€ (ì‹¤ì œ ë¡œê·¸ ìƒ˜í”Œ í¬í•¨)
./scripts/run_inference.sh my_models /var/log/suspicious.log

# ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ í™•ì¸
cat inference_*/log_samples_analysis/anomaly_analysis_report.md
```

**ê³ ê¸‰ ê¸°ëŠ¥ë“¤:**
```bash
# ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
./scripts/compare_models.sh old_models new_models

# ì ì§„ì  í•™ìŠµ (ê¸°ì¡´ ëª¨ë¸ ê°œì„ )
./scripts/train_models_incremental.sh old_models /var/log/new_normal/ updated_models
```

**ì¥ì :**
- ğŸ”„ **íš¨ìœ¨ì„±**: í•œ ë²ˆ í•™ìŠµí•˜ë©´ ì—¬ëŸ¬ Targetì— ì¬ì‚¬ìš©
- ğŸ“Š **ì¼ê´€ì„±**: ë™ì¼í•œ ê¸°ì¤€ìœ¼ë¡œ ì¼ê´€ëœ ì´ìƒíƒì§€
- ğŸ” **ê²€ì¦**: ìë™í™”ëœ ëª¨ë¸ í’ˆì§ˆ í‰ê°€ (0-100ì )
- ğŸ“‹ **ìƒ˜í”Œ**: ì‹¤ì œ ë¬¸ì œ ë¡œê·¸ë“¤ì„ ìë™ ì¶”ì¶œ ë° ë¶„ì„

#### 10) ì‚°ì¶œë¬¼ í•´ì„ ìš”ì•½
- `parsed.parquet`: `raw`, `masked`, `template_id`, `template`, `timestamp`, `host` ë“±
- `baseline_scores.parquet`: `score`, `is_anomaly`, `window_start_line`
- `deeplog_infer.parquet`: `idx`, `target`, `in_topk` (top-k ìœ„ë°˜ ì—¬ë¶€)
- ğŸ†• `logbert_infer.parquet`: `seq_idx`, `avg_loss`, `is_anomaly`, `threshold` (BERT ê¸°ë°˜ ì´ìƒ ì ìˆ˜)
- `mscred_infer.parquet`: `window_idx`, `reconstruction_error`, `is_anomaly`, `threshold`
- `report.md`: ìƒìœ„ ì´ìƒ ìœˆë„ìš°ì™€ ê¸°ì—¬ í…œí”Œë¦¿/ìš”ì•½ ì§€í‘œ
- ğŸ†• `anomaly_analysis_report.md`: ì‹¤ì œ ì´ìƒ ë¡œê·¸ ìƒ˜í”Œë“¤ê³¼ ìƒì„¸ ë¶„ì„

## ğŸ†• ìƒˆë¡œìš´ ì´ìƒíƒì§€ ë°©ë²•

### ğŸ¤– LogBERT - BERT ê¸°ë°˜ ë¡œê·¸ ì´ìƒíƒì§€ (NEW!)

**íŠ¹ì§•**: Transformer ì•„í‚¤í…ì²˜ ê¸°ë°˜ ì–‘ë°©í–¥ ì»¨í…ìŠ¤íŠ¸ í•™ìŠµ
**ì¥ì **:
- ì–‘ë°©í–¥ ì»¨í…ìŠ¤íŠ¸ë¡œ ì •êµí•œ íŒ¨í„´ í•™ìŠµ
- Masked Language Model(MLM) ë°©ì‹ìœ¼ë¡œ ì •ìƒ ë¡œê·¸ íŒ¨í„´ í•™ìŠµ
- ê¸´ ì‹œí€€ìŠ¤ ì˜ì¡´ì„± í¬ì°© ê°€ëŠ¥
- ì„ë² ë”© ê³µê°„ì—ì„œ ì˜ë¯¸ì  ìœ ì‚¬ì„± í•™ìŠµ

#### ğŸš€ LogBERT ì‚¬ìš©ë²•
```bash
# 1. LogBERT ì…ë ¥ ìƒì„± (íŠ¹ìˆ˜ í† í° í¬í•¨)
alog-detect build-logbert --parsed data/processed/parsed.parquet --out-dir data/processed

# 2. ëª¨ë¸ í•™ìŠµ (Masked Language Modeling)
alog-detect logbert-train \
  --seq data/processed/sequences.parquet \
  --vocab data/processed/vocab.json \
  --out models/logbert.pth \
  --seq-len 128 \
  --epochs 10 \
  --batch-size 32 \
  --hidden-size 256 \
  --num-layers 4 \
  --num-heads 8

# 3. ì´ìƒíƒì§€ ì¶”ë¡ 
alog-detect logbert-infer \
  --seq data/processed/sequences.parquet \
  --model models/logbert.pth \
  --vocab data/processed/vocab.json \
  --threshold-percentile 95.0

# 4. ê²°ê³¼ í™•ì¸
cat data/processed/logbert_infer.parquet
```

**ì£¼ìš” íŒŒë¼ë¯¸í„°**:
- `--seq-len`: ì‹œí€€ìŠ¤ ê¸¸ì´ (ê¸°ë³¸ê°’: 128, BERTì˜ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°)
- `--hidden-size`: ì€ë‹‰ì¸µ í¬ê¸° (ê¸°ë³¸ê°’: 256, ì‘ì€ ëª¨ë¸ìš©)
- `--num-layers`: Transformer ë ˆì´ì–´ ìˆ˜ (ê¸°ë³¸ê°’: 4)
- `--num-heads`: Attention head ìˆ˜ (ê¸°ë³¸ê°’: 8)
- `--mask-ratio`: í•™ìŠµ ì‹œ ë§ˆìŠ¤í‚¹ ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.15, BERT í‘œì¤€)

### ğŸ”¬ MS-CRED ë©€í‹°ìŠ¤ì¼€ì¼ ë¶„ì„

**íŠ¹ì§•**: ë©€í‹°ìŠ¤ì¼€ì¼ ì»¨ë³¼ë£¨ì…˜ ì˜¤í† ì¸ì½”ë”ë¡œ ìœˆë„ìš° ë‹¨ìœ„ íŒ¨í„´ ë¶„ì„
**ì¥ì **: ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼ì˜ íŒ¨í„´ì„ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ ë¯¸ì„¸í•œ ì´ìƒë„ íƒì§€ ê°€ëŠ¥

#### ğŸš€ MS-CRED ì‚¬ìš©ë²•
```bash
# 1. MS-CRED ì…ë ¥ ìƒì„±
alog-detect build-mscred --parsed data/processed/parsed.parquet --out-dir data/processed

# 2. ëª¨ë¸ í•™ìŠµ
alog-detect mscred-train --window-counts data/processed/window_counts.parquet --out models/mscred.pth --epochs 50

# 3. ì´ìƒíƒì§€ ì¶”ë¡ 
alog-detect mscred-infer --window-counts data/processed/window_counts.parquet --model models/mscred.pth --threshold 95.0

# 4. ê²°ê³¼ ë¶„ì„
alog-detect analyze-mscred --data-dir data/processed
```

## ğŸ†• ìƒˆë¡œìš´ ë¶„ì„ ê¸°ëŠ¥

### ğŸ” ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ (NEW!)

**ë¬¸ì œ**: ì´ìƒíƒì§€ ê²°ê³¼ë§Œìœ¼ë¡œëŠ” ì‹¤ì œë¡œ ì–´ë–¤ ë¡œê·¸ê°€ ë¬¸ì œì¸ì§€ ì•Œê¸° ì–´ë ¤ì›€  
**í•´ê²°**: ì‹¤ì œ ë¬¸ì œ ë¡œê·¸ë“¤ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì¶”ì¶œí•˜ê³  ë¶„ì„

#### ğŸ¬ ë¹ ë¥¸ ë°ëª¨
```bash
# ì „ì²´ ê¸°ëŠ¥ì„ í•œë²ˆì— ì²´í—˜
./scripts/demo/demo_log_samples.sh

# MS-CRED ê¸°ëŠ¥ ë°ëª¨
./scripts/demo/demo_mscred.sh
```

#### ğŸ”§ ì£¼ìš” ê¸°ëŠ¥
- **ì‹¤ì œ ë¡œê·¸ ìƒ˜í”Œ**: ì´ìƒíƒì§€ ê²°ê³¼ì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” ì‹¤ì œ ë¡œê·¸ë“¤ ì¶”ì¶œ
- **ì „í›„ ë§¥ë½**: ì´ìƒ ë¡œê·¸ì˜ ì•ë’¤ ìƒí™©ì„ í•¨ê»˜ í‘œì‹œ
- **íŒ¨í„´ ë¶„ì„**: ì™œ ì´ìƒìœ¼ë¡œ íŒë‹¨ë˜ì—ˆëŠ”ì§€ ì„¤ëª…
- **ì‚¬ëŒ ì¹œí™”ì **: ê¸°ìˆ ì  ê²°ê³¼ë¥¼ ì¼ë°˜ì¸ë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ë²ˆì—­

#### ğŸ“„ ìƒì„±ë˜ëŠ” ë¦¬í¬íŠ¸ ì˜ˆì‹œ
```markdown
# ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸš¨ ì´ìƒ ìœˆë„ìš° #1 (ë¼ì¸ 250~)
**ê¸°ë³¸ ì •ë³´**: ì´ìƒ ì ìˆ˜ 0.95, ìƒˆ í…œí”Œë¦¿ ë¹„ìœ¨ 40%

**ëŒ€í‘œì ì¸ ë¬¸ì œ ë¡œê·¸ë“¤**:
ERROR (ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨):
[2025-09-20 14:32:15] kernel: BUG: unable to handle page fault
- í…œí”Œë¦¿: kernel BUG at <PATH>:<NUM>

**ì „í›„ ë§¥ë½**:
[ì´ì „] normal CPU activity...
[ì´í›„] system attempting recovery...
```

### ğŸ“Š ë°°ì¹˜ ë¡œê·¸ ë¶„ì„

#### ğŸ”¹ ê¸°ë³¸ ë°°ì¹˜ ë¶„ì„
> **ì°¸ê³ **: `run_batch_analysis.sh`ëŠ” ì´ì œ `run_enhanced_batch_analysis.sh`ì˜ wrapperì…ë‹ˆë‹¤.
> ì§ì ‘ í–¥ìƒëœ ë²„ì „ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.

```bash
# í´ë” ë‚´ ëª¨ë“  ë¡œê·¸ íŒŒì¼ ë¶„ì„ (í–¥ìƒëœ ë²„ì „ìœ¼ë¡œ ìë™ ë¦¬ë””ë ‰ì…˜)
./scripts/run_batch_analysis.sh /path/to/logs/

# íŠ¹ì • íŒŒì¼ì„ Targetìœ¼ë¡œ ì§€ì •
./scripts/run_batch_analysis.sh /path/to/logs/ server1.log my_analysis
```

#### ğŸŒŸ í–¥ìƒëœ ë°°ì¹˜ ë¶„ì„ (ì¶”ì²œ)
í•˜ìœ„ ë””ë ‰í† ë¦¬ ì¬ê·€ ìŠ¤ìº”ìœ¼ë¡œ ë‚ ì§œë³„/ì¹´í…Œê³ ë¦¬ë³„ êµ¬ì¡° ì§€ì›:

```bash
# ê¸°ë³¸ ì‚¬ìš©ë²•: ìë™ ë‚ ì§œ/ì‹œê°„ í´ë” ìƒì„±
./scripts/run_enhanced_batch_analysis.sh /var/log/

# Target íŒŒì¼ ì§€ì • (ê°™ì€ ë””ë ‰í† ë¦¬ ë‚´)
./scripts/run_enhanced_batch_analysis.sh /var/log/ system.log

# ğŸ†• ì™¸ë¶€ Target íŒŒì¼ ì§€ì› (ë‹¤ë¥¸ ë””ë ‰í† ë¦¬)
./scripts/run_enhanced_batch_analysis.sh /var/log/baseline/ /var/log/target/problem.log

# ì„¸ë¶€ ì˜µì…˜ ì§€ì • (ë””ë ‰í† ë¦¬, TargetíŒŒì¼, ê¹Šì´, ìµœëŒ€íŒŒì¼ìˆ˜, ê²°ê³¼í´ë”)
./scripts/run_enhanced_batch_analysis.sh /logs/2025/09/ app.log 3 20 my_analysis

# ê²°ê³¼ í™•ì¸ - ğŸ†• í†µí•© ì¢…í•© ë¦¬í¬íŠ¸
cat my_analysis/COMPREHENSIVE_ANALYSIS_REPORT.md

# ğŸ†• í–¥ìƒëœ ë°°ì¹˜ ë¶„ì„ ë°ëª¨
./demo_enhanced_batch.sh
```

**ğŸ†• ìµœì‹  í–¥ìƒ ì‚¬í•­**:
- ğŸ¯ **ì™¸ë¶€ Target íŒŒì¼**: ë‹¤ë¥¸ ë””ë ‰í† ë¦¬ì˜ íŒŒì¼ì„ Targetìœ¼ë¡œ ì§€ì • ê°€ëŠ¥
- ğŸ“Š **20ê°œ ë¡œê·¸ ìƒ˜í”Œ**: íƒ€ì…ë³„ ìµœëŒ€ 20ê°œ ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ìë™ ì¶”ì¶œ (ê¸°ì¡´ 10ê°œ â†’ 20ê°œ)
- ğŸ“„ **ì¢…í•© ë¦¬í¬íŠ¸**: ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ `COMPREHENSIVE_ANALYSIS_REPORT.md` í•˜ë‚˜ë¡œ í†µí•©
- ğŸ›¡ï¸ **Baseline í’ˆì§ˆ ê²€ì¦**: ë¬¸ì œìˆëŠ” Baseline íŒŒì¼ ìë™ í•„í„°ë§

## ğŸ†• **ìƒˆë¡œìš´ ê³ ê¸‰ ë„êµ¬ë“¤**

### ğŸ”§ **ëª¨ë¸ í•™ìŠµ ë„êµ¬**
```bash
# ì •ìƒ ë¡œê·¸ë¡œ ëª¨ë¸ í•™ìŠµ
./scripts/train_models.sh /var/log/normal/ my_models

# ì ì§„ì  í•™ìŠµ (ê¸°ì¡´ ëª¨ë¸ ê°œì„ )
./scripts/train_models_incremental.sh old_models /var/log/new_normal/ updated_models
```

### ğŸ” **ëª¨ë¸ ê²€ì¦ ë° ë¹„êµ**
```bash
# ëª¨ë¸ í’ˆì§ˆ ê²€ì¦ (0-100ì  í’ˆì§ˆ ì ìˆ˜)
./scripts/validate_models.sh my_models

# ë‘ ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ
./scripts/compare_models.sh old_models new_models
```

### ğŸ¯ **ì´ìƒíƒì§€ ì¶”ë¡ **
```bash
# Target ë¡œê·¸ ì´ìƒíƒì§€ (ì‹¤ì œ ë¡œê·¸ ìƒ˜í”Œ í¬í•¨)
./scripts/run_inference.sh my_models /var/log/suspicious.log

# ê²°ê³¼ í™•ì¸
cat inference_*/log_samples_analysis/anomaly_analysis_report.md
```

### ğŸ“‹ **ìƒì„¸ ê°€ì´ë“œ**
- **ì „ì²´ ì›Œí¬í”Œë¡œìš°**: `TRAIN_INFERENCE_GUIDE.md` ì°¸ì¡°
- **ë°°ì¹˜ ë¶„ì„**: `BATCH_ANALYSIS_GUIDE.md` ì°¸ì¡°
- ğŸ” **Target ê²€ì¦ ê°•í™”**: ì˜ëª»ëœ Target ì§€ì • ì‹œ ì•ˆì „í•œ ì—ëŸ¬ ì²˜ë¦¬

**ì§€ì›í•˜ëŠ” ë””ë ‰í† ë¦¬ êµ¬ì¡°**:
```
logs/
â”œâ”€â”€ 2025-09-15/server1/application.log    # ë‚ ì§œë³„ êµ¬ì¡°
â”œâ”€â”€ 2025-09-16/server2/system.log
â”œâ”€â”€ web-servers/nginx.log                 # ì„œë¹„ìŠ¤ë³„ êµ¬ì¡°  
â””â”€â”€ databases/mysql.log
```

### ğŸ• ì‹œê°„ ê¸°ë°˜ ì´ìƒ íƒì§€
ì‹œê°„ëŒ€ë³„/ìš”ì¼ë³„ íŒ¨í„´ í•™ìŠµìœ¼ë¡œ ì´ìƒ íƒì§€:

```bash
alog-detect analyze-temporal --data-dir data/processed
cat data/processed/temporal_analysis/temporal_report.md
```

### ğŸ“ˆ íŒŒì¼ë³„ ë¹„êµ ì´ìƒ íƒì§€
ì—¬ëŸ¬ íŒŒì¼ ê°„ íŒ¨í„´ ì°¨ì´ë¡œ ì´ìƒ íƒì§€:

```bash
alog-detect analyze-comparative \
  --target server1/parsed.parquet \
  --baselines server2/parsed.parquet --baselines server3/parsed.parquet
```

**ë¶„ì„ ë°©ë²• ë¹„êµ**:
- **ê¸°ì¡´ ìœˆë„ìš° ë°©ì‹**: ë‹¨ì¼ íŒŒì¼ ë‚´ ì‹œê°„ìˆœ íŒ¨í„´ ë³€í™”
- **ì‹œê°„ ê¸°ë°˜ íƒì§€**: ê³¼ê±° ë™ì¼ ì‹œê°„ëŒ€ì™€ í˜„ì¬ ë¹„êµ  
- **íŒŒì¼ë³„ ë¹„êµ**: ì—¬ëŸ¬ ì‹œìŠ¤í…œ/ì„œë¹„ìŠ¤ ê°„ ìƒëŒ€ì  ì°¨ì´

## ğŸ”„ Hybrid System (ONNX ë³€í™˜ & C ì¶”ë¡ )

ê³ ì„±ëŠ¥ C ì¶”ë¡  ì—”ì§„ì„ ìœ„í•œ ONNX ë³€í™˜ ë° ìë™í™” ë„êµ¬ì…ë‹ˆë‹¤.

### ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥

- **ìë™ ëª¨ë¸ ë³€í™˜**: PyTorch ëª¨ë¸ì„ ONNXë¡œ ìë™ ë³€í™˜
- **íŒŒì¼ ì‹œìŠ¤í…œ ê°ì‹œ**: ìƒˆ ëª¨ë¸ ìƒì„± ì‹œ ìë™ ë³€í™˜ (watch ëª¨ë“œ)
- **ë°°ì¹˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸**: í•™ìŠµë¶€í„° ë°°í¬ê¹Œì§€ ì „ì²´ ìë™í™”
- **C ì¶”ë¡  ì—”ì§„**: ê³ ì„±ëŠ¥ ì‹¤ì‹œê°„ ì´ìƒíƒì§€

### ğŸš€ ë¹ ë¥¸ ì‹œì‘

#### 1. ìë™ ëª¨ë¸ ë³€í™˜ ë° ë°°í¬

```bash
# ê°ì‹œ ëª¨ë“œ: ìƒˆ ëª¨ë¸ ìƒì„± ì‹œ ìë™ ë³€í™˜
python -m hybrid_system.training.auto_converter --mode watch

# ì¼ê´„ ë³€í™˜: ê¸°ì¡´ ëª¨ë¸ë“¤ ë³€í™˜
python -m hybrid_system.training.auto_converter --mode convert

# ì „ì²´ íŒŒì´í”„ë¼ì¸: í•™ìŠµ â†’ ë³€í™˜ â†’ ë°°í¬
python -m hybrid_system.training.auto_converter \
    --mode pipeline \
    --log-file data/raw/log.log
```

#### 2. ë°°ì¹˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸

```bash
# ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ìë™ ì‹¤í–‰
python -m hybrid_system.training.batch_trainer \
    data/raw/log.log \
    --output-dir data/processed/batch_$(date +%Y%m%d_%H%M%S)
```

#### 3. ONNX ë³€í™˜ (ìˆ˜ë™)

```bash
# DeepLog ëª¨ë¸ ë³€í™˜
python -m hybrid_system.training.model_converter \
    --deeplog-model models/deeplog.pth \
    --vocab data/processed/vocab.json \
    --output-dir hybrid_system/inference/models
```

**ì¶œë ¥ íŒŒì¼**:
- âœ… `deeplog.onnx` - ONNX ëª¨ë¸
- âœ… `deeplog_optimized.onnx` - ìµœì í™”ëœ ONNX ëª¨ë¸  
- âœ… `vocab.json` - **ìë™ìœ¼ë¡œ C ì—”ì§„ìš© í˜•ì‹ìœ¼ë¡œ ë³€í™˜ë¨!**
- âœ… `deeplog.onnx.meta.json` - ëª¨ë¸ ë©”íƒ€ë°ì´í„°

#### 4. C ì¶”ë¡  ì—”ì§„ ì‚¬ìš©

ìì„¸í•œ ë‚´ìš©: [hybrid_system/inference/README.md](hybrid_system/inference/README.md)

```bash
# ONNX Runtime ì„¤ì¹˜
./scripts/install_onnxruntime.sh

# Inference Engine ë¹Œë“œ
cd hybrid_system/inference
make clean && make

# ì‹¤í–‰
./bin/inference_engine \
    -d models/deeplog.onnx \
    -v models/vocab.json \
    -i /var/log/syslog \
    -o results.json
```

### ğŸ“š ìƒì„¸ ê°€ì´ë“œ

- **ONNX ë³€í™˜**: [docs/guides/ONNX_CONVERSION_GUIDE.md](docs/guides/ONNX_CONVERSION_GUIDE.md)
- **C ì¶”ë¡  ì—”ì§„**: [hybrid_system/inference/README.md](hybrid_system/inference/README.md)
- **ìë™ ë³€í™˜**: `python -m hybrid_system.training.auto_converter --help`
