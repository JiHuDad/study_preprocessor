### study-preprocessor ì‚¬ìš© ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” ì»¤ë„/ì‹œìŠ¤í…œ ë¡œê·¸(.log) íŒŒì¼ì— ì „ì²˜ë¦¬ì™€ ì´ìƒíƒì§€ë¥¼ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ë‹¨ê³„ë³„ë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤. ëª¨ë“  ì˜ˆì‹œëŠ” `venv + pip` ê¸°ë°˜ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.

#### 1) ì„¤ì¹˜/í™˜ê²½
- ì‚¬ì „ ìš”êµ¬: macOS/Linux, Python 3.11+
- ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”:
```
python3 -m venv .venv
source .venv/bin/activate  # Windows: .venv\\Scripts\\activate
python -m pip install -U pip wheel
```
- íŒ¨í‚¤ì§€ ì„¤ì¹˜(ë‘˜ ì¤‘ í•˜ë‚˜ ì„ íƒ)
  1) ê³ ì • ë²„ì „ ì„¤ì¹˜(requirements.txt):
  ```
  pip install -r requirements.txt
  ```
  2) ê°œë°œ í¸ì˜ë¥¼ ìœ„í•œ editable ì„¤ì¹˜:
```
pip install -e .
```

#### 2) ë‹¨ì¼ .log íŒŒì¼ ì „ì²˜ë¦¬
- ê¸°ë³¸ ì‹¤í–‰:
```
study-preprocess parse \
  --input /path/to/your.log \
  --out-dir /path/to/outdir \
  --drain-state .cache/drain3.json
```
- ì£¼ìš” ì‚°ì¶œë¬¼:
  - `/path/to/outdir/parsed.parquet`: ì „ì²˜ë¦¬ ê²°ê³¼(raw/masked/template_id ë“±)
  - `/path/to/outdir/preview.json`: ìƒìœ„ 10í–‰ ë¯¸ë¦¬ë³´ê¸°(ì›ë¬¸ vs ë§ˆìŠ¤í‚¹)

- ë§ˆìŠ¤í‚¹ ì˜µì…˜(ê°œë³„ í† ê¸€): ê¸°ë³¸ì€ ëª¨ë‘ ë§ˆìŠ¤í‚¹ ON, ì•„ë˜ í”Œë˜ê·¸ë¡œ OFF ê°€ëŠ¥
  - `--no-mask-paths`, `--no-mask-hex`, `--no-mask-ips`, `--no-mask-mac`, `--no-mask-uuid`
  - `--no-mask-pid`, `--no-mask-device`, `--no-mask-num`
  - ì˜ˆ: ìˆ«ì/ë””ë°”ì´ìŠ¤ ì ‘ë¯¸ì‚¬ ë§ˆìŠ¤í‚¹ì„ ë„ê³  ì‹¤í–‰
```
study-preprocess parse \
  --input /path/to/your.log \
  --out-dir /path/to/outdir \
  --no-mask-device --no-mask-num
```

- Drain3 ìƒíƒœ ì¬ì‚¬ìš©
  - `--drain-state .cache/drain3.json`ë¡œ ìƒíƒœë¥¼ ì €ì¥/ëˆ„ì í•˜ì—¬ í…œí”Œë¦¿ ì¼ê´€ì„±ì„ ìœ ì§€
  - ì—¬ëŸ¬ íŒŒì¼ì„ ìˆœì°¨ ì²˜ë¦¬í•  ë•Œ ê°™ì€ `--drain-state`ë¥¼ ì§€ì •í•˜ë©´ ê¸°ì¡´ í…œí”Œë¦¿ì„ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.

#### 3) ì—¬ëŸ¬ .log íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬
- ì‰˜ ë£¨í”„ ì˜ˆì‹œ:
```
OUT=/path/to/processed
STATE=.cache/drain3.json
mkdir -p "$OUT"
for f in /var/log/*.log; do
  study-preprocess parse --input "$f" --out-dir "$OUT/$(basename "$f" .log)" --drain-state "$STATE"
done
```
- ê²°ê³¼ ë³‘í•©(ì„ íƒ):
```
python - <<'PY'
import os, pandas as pd
base = '/path/to/processed'
parts = []
for d in os.listdir(base):
    p = os.path.join(base, d, 'parsed.parquet')
    if os.path.exists(p):
        df = pd.read_parquet(p)
        df['source'] = d
        parts.append(df)
if parts:
    pd.concat(parts, ignore_index=True).to_parquet(os.path.join(base, 'merged.parquet'), index=False)
    print('Merged ->', os.path.join(base, 'merged.parquet'))
else:
    print('No parquet found')
PY
```

#### 4) DeepLog/MSCRED ì…ë ¥ ìƒì„±
- DeepLog ì…ë ¥(ì‚¬ì „/ì‹œí€€ìŠ¤):
```
study-preprocess build-deeplog \
  --parsed /path/to/outdir/parsed.parquet \
  --out-dir /path/to/outdir
```
- MS-CRED ì…ë ¥(ìœˆë„ìš° ì¹´ìš´íŠ¸):
```
study-preprocess build-mscred \
  --parsed /path/to/outdir/parsed.parquet \
  --out-dir /path/to/outdir \
  --window-size 50 --stride 25
```

#### 5) ì´ìƒíƒì§€ ì‹¤í–‰
- ë² ì´ìŠ¤ë¼ì¸(ìƒˆ í…œí”Œë¦¿ ë¹„ìœ¨ + ë¹ˆë„ ê¸‰ë³€):
```
study-preprocess detect \
  --parsed /path/to/outdir/parsed.parquet \
  --out-dir /path/to/outdir \
  --window-size 50 --stride 25 --ewm-alpha 0.3 --q 0.95
```
- DeepLog í•™ìŠµ/ì¶”ë¡ :
```
study-preprocess deeplog-train \
  --seq /path/to/outdir/sequences.parquet \
  --vocab /path/to/outdir/vocab.json \
  --out .cache/deeplog.pth --seq-len 50 --epochs 3

study-preprocess deeplog-infer \
  --seq /path/to/outdir/sequences.parquet \
  --model .cache/deeplog.pth --k 3
```
- ë¦¬í¬íŠ¸/ìš”ì•½ ìƒì„±:
```
# ê¸°ë³¸ ë¦¬í¬íŠ¸
study-preprocess report --processed-dir /path/to/outdir

# ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ í¬í•¨ ë¦¬í¬íŠ¸
study-preprocess report --processed-dir /path/to/outdir --with-samples
```
  - í¬í•¨: ë² ì´ìŠ¤ë¼ì¸ ì´ìƒ ìœˆë„ìš° ë¹„ìœ¨, ìƒìœ„ ìœˆë„ìš°/í…œí”Œë¦¿, DeepLog ìœ„ë°˜ìœ¨
  - `--with-samples`: ì‹¤ì œ ë¬¸ì œ ë¡œê·¸ ìƒ˜í”Œê³¼ ë¶„ì„ ì¶”ê°€

- ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ (ë‹¨ë…):
```
study-preprocess analyze-samples --processed-dir /path/to/outdir
```
  - ğŸ” ì´ìƒíƒì§€ ê²°ê³¼ì—ì„œ ì‹¤ì œ ë¬¸ì œ ë¡œê·¸ë“¤ ì¶”ì¶œ
  - ğŸ“„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
  - ğŸ¯ ì „í›„ ë§¥ë½ê³¼ í•¨ê»˜ ì´ìƒ íŒ¨í„´ ì„¤ëª…

#### 6) í•©ì„± ë°ì´í„°ë¡œ E2E ê²€ì¦(ì˜µì…˜)
```
# í•©ì„± ë¡œê·¸ + ë¼ë²¨ ìƒì„±
study-preprocess gen-synth --out data/raw/synth_long.log --lines 1000 --anomaly-rate 0.03

# ì „ì²˜ë¦¬ â†’ ë¹Œë” â†’ íƒì§€ â†’ í•™ìŠµ/ì¶”ë¡  â†’ ë¦¬í¬íŠ¸/í‰ê°€
study-preprocess parse --input data/raw/synth_long.log --out-dir data/processed/synth --drain-state .cache/drain3.json
study-preprocess build-deeplog --parsed data/processed/synth/parsed.parquet --out-dir data/processed/synth
study-preprocess detect --parsed data/processed/synth/parsed.parquet --out-dir data/processed/synth --window-size 50 --stride 25 --ewm-alpha 0.3 --q 0.95
study-preprocess deeplog-train --seq data/processed/synth/sequences.parquet --vocab data/processed/synth/vocab.json --out .cache/deeplog_synth.pth --seq-len 20 --epochs 2
study-preprocess deeplog-infer --seq data/processed/synth/sequences.parquet --model .cache/deeplog_synth.pth --k 3
study-preprocess report --processed-dir data/processed/synth
study-preprocess eval --processed-dir data/processed/synth --labels data/raw/synth_long.log.labels.parquet --window-size 50 --seq-len 20
```

#### 7) ë¬¸ì œ í•´ê²° íŒ
- í…œí”Œë¦¿ì´ ê³¼ë„í•˜ê²Œ ëŠ˜ì–´ë‚˜ëŠ” ê²½ìš°: ë§ˆìŠ¤í‚¹ì„ ë” ê°•í•˜ê²Œ í•˜ê±°ë‚˜ `--drain-state`ë¥¼ ìœ ì§€í•˜ë©° ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
- íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹± ì‹¤íŒ¨: ë¼ì¸ ì¸ë±ìŠ¤(`line_no`) ê¸°ì¤€ìœ¼ë¡œë„ ì •ë ¬ë˜ë©°, í¬ë§·ì´ ë‹¤ë¥¸ ê²½ìš° ì „ì²˜ë¦¬ ê·œì¹™ ë³´ê°• í•„ìš”
- ë©”ëª¨ë¦¬: ëŒ€í˜• íŒŒì¼ì€ ë””ë ‰í„°ë¦¬ ë‹¨ìœ„ë¡œ ë‚˜ëˆ  ì²˜ë¦¬ í›„ ë³‘í•© ê¶Œì¥

#### 8) ìë™í™” ìŠ¤í¬ë¦½íŠ¸ (í•œë²ˆì— ì‹¤í–‰)
ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ í•œë²ˆì— ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ìŠ¤í¬ë¦½íŠ¸ ì œê³µ:

**uv í™˜ê²½ìš©:**
```bash
./run_full_pipeline.sh /path/to/your.log [ì¶œë ¥ë””ë ‰í† ë¦¬]
```

**pip/venv í™˜ê²½ìš©:**
```bash
./run_full_pipeline_pip.sh /path/to/your.log [ì¶œë ¥ë””ë ‰í† ë¦¬]
```

ìë™ ê¸°ëŠ¥:
- ê°€ìƒí™˜ê²½ ìë™ ê°ì§€ ë° í™œì„±í™” (.venv, venv)
- ì˜ì¡´ì„± ìë™ ì„¤ì¹˜ (í•„ìš”ì‹œ)
- ì—ëŸ¬ ì²˜ë¦¬ ë° ì§„í–‰ ìƒí™© í‘œì‹œ
- ê²°ê³¼ íŒŒì¼ ìë™ ì •ë¦¬ ë° ìš”ì•½

#### 9) ì‚°ì¶œë¬¼ í•´ì„ ìš”ì•½
- `parsed.parquet`: `raw`, `masked`, `template_id`, `template`, `timestamp`, `host` ë“±
- `baseline_scores.parquet`: `score`, `is_anomaly`, `window_start_line`
- `deeplog_infer.parquet`: `idx`, `target`, `in_topk` (top-k ìœ„ë°˜ ì—¬ë¶€)
- `report.md`: ìƒìœ„ ì´ìƒ ìœˆë„ìš°ì™€ ê¸°ì—¬ í…œí”Œë¦¿/ìš”ì•½ ì§€í‘œ

## ğŸ†• ìƒˆë¡œìš´ ë¶„ì„ ê¸°ëŠ¥

### ğŸ” ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ (NEW!)

**ë¬¸ì œ**: ì´ìƒíƒì§€ ê²°ê³¼ë§Œìœ¼ë¡œëŠ” ì‹¤ì œë¡œ ì–´ë–¤ ë¡œê·¸ê°€ ë¬¸ì œì¸ì§€ ì•Œê¸° ì–´ë ¤ì›€  
**í•´ê²°**: ì‹¤ì œ ë¬¸ì œ ë¡œê·¸ë“¤ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì¶”ì¶œí•˜ê³  ë¶„ì„

#### ğŸ¬ ë¹ ë¥¸ ë°ëª¨
```bash
# ì „ì²´ ê¸°ëŠ¥ì„ í•œë²ˆì— ì²´í—˜
./demo_log_samples.sh
```

#### ğŸ”§ ì£¼ìš” ê¸°ëŠ¥
- **ì‹¤ì œ ë¡œê·¸ ìƒ˜í”Œ**: ì´ìƒíƒì§€ ê²°ê³¼ì—ì„œ ë¬¸ì œê°€ ë˜ëŠ” ì‹¤ì œ ë¡œê·¸ë“¤ ì¶”ì¶œ
- **ì „í›„ ë§¥ë½**: ì´ìƒ ë¡œê·¸ì˜ ì•ë’¤ ìƒí™©ì„ í•¨ê»˜ í‘œì‹œ
- **íŒ¨í„´ ë¶„ì„**: ì™œ ì´ìƒìœ¼ë¡œ íŒë‹¨ë˜ì—ˆëŠ”ì§€ ì„¤ëª…
- **ì‚¬ëŒ ì¹œí™”ì **: ê¸°ìˆ ì  ê²°ê³¼ë¥¼ ì¼ë°˜ì¸ë„ ì´í•´í•  ìˆ˜ ìˆê²Œ ë²ˆì—­

#### ğŸ“„ ìƒì„±ë˜ëŠ” ë¦¬í¬íŠ¸ ì˜ˆì‹œ
```markdown
# ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸš¨ ì´ìƒ ìœˆë„ìš° #1 (ë¼ì¸ 250~)
**ê¸°ë³¸ ì •ë³´**: ì´ìƒ ì ìˆ˜ 0.95, ìƒˆ í…œí”Œë¦¿ ë¹„ìœ¨ 40%

**ëŒ€í‘œì ì¸ ë¬¸ì œ ë¡œê·¸ë“¤**:
ERROR (ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨):
[2025-09-20 14:32:15] kernel: BUG: unable to handle page fault
- í…œí”Œë¦¿: kernel BUG at <PATH>:<NUM>

**ì „í›„ ë§¥ë½**:
[ì´ì „] normal CPU activity...
[ì´í›„] system attempting recovery...
```

### ğŸ“Š ë°°ì¹˜ ë¡œê·¸ ë¶„ì„

#### ğŸ”¹ ê¸°ë³¸ ë°°ì¹˜ ë¶„ì„
ë‹¨ì¼ ë””ë ‰í† ë¦¬ì˜ ë¡œê·¸ íŒŒì¼ë“¤ì„ ë¶„ì„:

```bash
# í´ë” ë‚´ ëª¨ë“  ë¡œê·¸ íŒŒì¼ ë¶„ì„
./run_batch_analysis.sh /path/to/logs/

# íŠ¹ì • íŒŒì¼ì„ Targetìœ¼ë¡œ ì§€ì •
./run_batch_analysis.sh /path/to/logs/ server1.log my_analysis
```

#### ğŸŒŸ í–¥ìƒëœ ë°°ì¹˜ ë¶„ì„ (ì¶”ì²œ)
í•˜ìœ„ ë””ë ‰í† ë¦¬ ì¬ê·€ ìŠ¤ìº”ìœ¼ë¡œ ë‚ ì§œë³„/ì¹´í…Œê³ ë¦¬ë³„ êµ¬ì¡° ì§€ì›:

```bash
# í•˜ìœ„ ë””ë ‰í† ë¦¬ í¬í•¨ ì „ì²´ ìŠ¤ìº”
./run_enhanced_batch_analysis.sh /var/log/

# ì„¸ë¶€ ì˜µì…˜ ì§€ì • (ë””ë ‰í† ë¦¬, TargetíŒŒì¼, ê¹Šì´, ìµœëŒ€íŒŒì¼ìˆ˜, ê²°ê³¼í´ë”)
./run_enhanced_batch_analysis.sh /logs/2025/09/ app.log 3 20 analysis_result

# ê²°ê³¼ í™•ì¸
cat analysis_result/ENHANCED_ANALYSIS_SUMMARY.md
```

**ğŸ’¡ ìƒˆë¡œìš´ ê¸°ëŠ¥**: ì´ì œ í–¥ìƒëœ ë°°ì¹˜ ë¶„ì„ì—ì„œ **ì´ìƒ ë¡œê·¸ ìƒ˜í”Œ ì¶”ì¶œ**ì´ ìë™ìœ¼ë¡œ í¬í•¨ë©ë‹ˆë‹¤!
- ğŸ” ì‹¤ì œ ë¬¸ì œê°€ ë˜ëŠ” ë¡œê·¸ë“¤ì„ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì¶”ì¶œ
- ğŸ“„ ì „í›„ ë§¥ë½ê³¼ í•¨ê»˜ ì´ìƒ íŒ¨í„´ ì„¤ëª… ì œê³µ
- ğŸ¯ ì´ìƒíƒì§€ ê²°ê³¼ë¥¼ ì‹¤ì œ ë¡œê·¸ì™€ ì—°ê²°í•˜ì—¬ í•´ì„ ìš©ì´

**ì§€ì›í•˜ëŠ” ë””ë ‰í† ë¦¬ êµ¬ì¡°**:
```
logs/
â”œâ”€â”€ 2025-09-15/server1/application.log    # ë‚ ì§œë³„ êµ¬ì¡°
â”œâ”€â”€ 2025-09-16/server2/system.log
â”œâ”€â”€ web-servers/nginx.log                 # ì„œë¹„ìŠ¤ë³„ êµ¬ì¡°  
â””â”€â”€ databases/mysql.log
```

### ğŸ• ì‹œê°„ ê¸°ë°˜ ì´ìƒ íƒì§€
ì‹œê°„ëŒ€ë³„/ìš”ì¼ë³„ íŒ¨í„´ í•™ìŠµìœ¼ë¡œ ì´ìƒ íƒì§€:

```bash
python temporal_anomaly_detector.py --data-dir data/processed
cat data/processed/temporal_analysis/temporal_report.md
```

### ğŸ“ˆ íŒŒì¼ë³„ ë¹„êµ ì´ìƒ íƒì§€  
ì—¬ëŸ¬ íŒŒì¼ ê°„ íŒ¨í„´ ì°¨ì´ë¡œ ì´ìƒ íƒì§€:

```bash
python comparative_anomaly_detector.py \
  --target server1/parsed.parquet \
  --baselines server2/parsed.parquet server3/parsed.parquet
```

**ë¶„ì„ ë°©ë²• ë¹„êµ**:
- **ê¸°ì¡´ ìœˆë„ìš° ë°©ì‹**: ë‹¨ì¼ íŒŒì¼ ë‚´ ì‹œê°„ìˆœ íŒ¨í„´ ë³€í™”
- **ì‹œê°„ ê¸°ë°˜ íƒì§€**: ê³¼ê±° ë™ì¼ ì‹œê°„ëŒ€ì™€ í˜„ì¬ ë¹„êµ  
- **íŒŒì¼ë³„ ë¹„êµ**: ì—¬ëŸ¬ ì‹œìŠ¤í…œ/ì„œë¹„ìŠ¤ ê°„ ìƒëŒ€ì  ì°¨ì´
