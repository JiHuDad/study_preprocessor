# C Inference Engine í…œí”Œë¦¿ ë§¤ì¹­ ë¬¸ì œ í•´ê²°

## ğŸ› ë¬¸ì œ

ONNX inference engineì—ì„œ 77ê°œ í…œí”Œë¦¿ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆì§€ë§Œ, ëª¨ë“  ë¡œê·¸ê°€ "Unknown template"ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤.

### ì¦ìƒ

```bash
$ ./bin/inference_engine -d models/deeplog.onnx -v models/vocab.json -t

Loaded vocabulary: 77 templates  âœ…
Processing test logs:
Log 1: Unknown template  âŒ
Log 2: Unknown template  âŒ
Log 3: Unknown template  âŒ
...
```

## ğŸ” ì›ì¸ ë¶„ì„

### 1. í…œí”Œë¦¿ í˜•ì‹

**vocab.jsonì˜ í…œí”Œë¦¿**:
```
[<NUM>] usb 1-1: new high-speed USB device number <NUM> using ehci-pci
```

**ì‹¤ì œ ë¡œê·¸**:
```
[12345.678901] usb 1-1: new high-speed USB device number 2 using ehci-pci
```

### 2. í˜„ì¬ ìœ ì‚¬ë„ ê³„ì‚° ë¡œì§ (ë¬¸ì œ)

```c
// log_parser.cì˜ string_similarity()
static int string_similarity(const char* s1, const char* s2) {
    // ì•ë¶€ë¶„ë¶€í„° ê°™ì€ ë¬¸ì ê°œìˆ˜ ì„¸ê¸°
    for (int i = 0; i < min_len; i++) {
        if (s1[i] == s2[i]) {
            common++;
        } else {
            break;  // ë‹¤ë¥¸ ë¬¸ìê°€ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨!
        }
    }
    return common;
}
```

**ë¬¸ì œ**:
```
ë¡œê·¸:      [12345.678901] usb...
í…œí”Œë¦¿:    [<NUM>] usb...
           â†‘
           '[' ë‹¤ìŒ ë¬¸ìê°€ ë‹¤ë¦„ â†’ ìœ ì‚¬ë„ = 1 (ë§¤ìš° ë‚®ìŒ!)
```

### 3. ë§ˆìŠ¤í‚¹ ë¡œì§ (ë¶ˆì™„ì „)

í˜„ì¬ `normalize_log_line()`ì€ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë§ˆìŠ¤í‚¹í•˜ì§€ë§Œ:
- ì •ê·œì‹ì´ ë³µì¡í•˜ê³  ëŠë¦¼
- Pythonì˜ ë§ˆìŠ¤í‚¹ê³¼ ë‹¤ë¥´ê²Œ ë™ì‘
- í…œí”Œë¦¿ê³¼ ì •í™•íˆ ë§¤ì¹­ë˜ì§€ ì•ŠìŒ

## âœ… í•´ê²° ë°©ë²•

### Option 1: Python ë§ˆìŠ¤í‚¹ ì‚¬ìš© (ê¶Œì¥!)

**ì•„ì´ë””ì–´**: C ì—”ì§„ì—ì„œ ë³µì¡í•œ ë§ˆìŠ¤í‚¹ì„ í•˜ì§€ ë§ê³ , ì´ë¯¸ ë§ˆìŠ¤í‚¹ëœ ë¡œê·¸ë¥¼ ì…ë ¥ë°›ê¸°

#### ì›Œí¬í”Œë¡œìš° ë³€ê²½

**í˜„ì¬ (ë¬¸ì œ)**:
```
Raw ë¡œê·¸ â†’ C ì—”ì§„ (ë§ˆìŠ¤í‚¹ + í…œí”Œë¦¿ ë§¤ì¹­) â†’ ì¶”ë¡ 
```

**ê°œì„ ì•ˆ**:
```
Raw ë¡œê·¸ â†’ Python íŒŒì„œ (ë§ˆìŠ¤í‚¹) â†’ ë§ˆìŠ¤í‚¹ëœ ë¡œê·¸ â†’ C ì—”ì§„ (í…œí”Œë¦¿ ë§¤ì¹­) â†’ ì¶”ë¡ 
```

#### êµ¬í˜„

**1. Python ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸**:

```python
# scripts/preprocess_for_c_engine.py
import sys
from anomaly_log_detector.preprocess import mask_message

def preprocess_log_for_c_engine(input_file, output_file):
    """ë¡œê·¸ë¥¼ C ì—”ì§„ìš©ìœ¼ë¡œ ì „ì²˜ë¦¬ (ë§ˆìŠ¤í‚¹ë§Œ)"""
    with open(input_file) as f_in, open(output_file, 'w') as f_out:
        for line in f_in:
            # Pythonì˜ mask_message ì‚¬ìš©
            masked = mask_message(line.strip())
            f_out.write(masked + '\n')

if __name__ == "__main__":
    if len(sys.argv) != 3:
        print("Usage: python preprocess_for_c_engine.py <input> <output>")
        sys.exit(1)

    preprocess_log_for_c_engine(sys.argv[1], sys.argv[2])
```

**2. C ì—”ì§„ ì‚¬ìš©**:

```bash
# 1. Pythonìœ¼ë¡œ ë§ˆìŠ¤í‚¹
python scripts/preprocess_for_c_engine.py \
    /var/log/syslog \
    /tmp/masked.log

# 2. C ì—”ì§„ìœ¼ë¡œ ì¶”ë¡ 
./bin/inference_engine \
    -d models/deeplog.onnx \
    -v models/vocab.json \
    -i /tmp/masked.log
```

### Option 2: C ì—”ì§„ì˜ ìœ ì‚¬ë„ ê³„ì‚° ê°œì„ 

ë” ë‚˜ì€ ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„:

```c
// ê°œì„ ëœ string_similarity()
static int string_similarity(const char* s1, const char* s2) {
    int len1 = strlen(s1);
    int len2 = strlen(s2);

    if (len1 == 0) return 0;
    if (len2 == 0) return 0;

    // Levenshtein distance ë˜ëŠ” í† í° ê¸°ë°˜ ìœ ì‚¬ë„
    // ì˜ˆ: ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ í† í° ë¹„êµ

    int matches = 0;
    int total = 0;

    // ê°„ë‹¨í•œ í† í° ê¸°ë°˜ ë¹„êµ
    char* s1_copy = strdup(s1);
    char* s2_copy = strdup(s2);

    char* token1 = strtok(s1_copy, " ");
    while (token1) {
        total++;
        char* token2 = strtok(s2_copy, " ");
        while (token2) {
            if (strcmp(token1, token2) == 0) {
                matches++;
                break;
            }
            token2 = strtok(NULL, " ");
        }
        token1 = strtok(NULL, " ");
    }

    free(s1_copy);
    free(s2_copy);

    return matches;
}
```

### Option 3: Template ID ì§ì ‘ ì „ë‹¬ (ê°€ì¥ ë¹ ë¦„!)

**ì•„ì´ë””ì–´**: Pythonì—ì„œ ì´ë¯¸ template_idë¥¼ ê³„ì‚°í–ˆë‹¤ë©´, ê·¸ê²ƒì„ C ì—”ì§„ì— ì „ë‹¬

#### ì›Œí¬í”Œë¡œìš°

```
Raw ë¡œê·¸ â†’ Python íŒŒì„œ (íŒŒì‹± + template_id ê³„ì‚°) â†’ JSON â†’ C ì—”ì§„ (template_id ì‚¬ìš©) â†’ ì¶”ë¡ 
```

**ì¥ì **:
- C ì—”ì§„ì—ì„œ í…œí”Œë¦¿ ë§¤ì¹­ ë¶ˆí•„ìš”
- ê°€ì¥ ë¹ ë¥´ê³  ì •í™•
- Pythonê³¼ ë™ì¼í•œ ê²°ê³¼ ë³´ì¥

## ğŸ¯ ê¶Œì¥ í•´ê²°ì±…: Hybrid ì ‘ê·¼

### Step 1: Pythonìœ¼ë¡œ ì „ì²˜ë¦¬ (ì •í™•ì„±)

```python
# scripts/prepare_for_onnx_inference.py
import pandas as pd
import json
from anomaly_log_detector.preprocess import parse_and_mask_logs

def prepare_logs_for_onnx(input_log, output_json, vocab_json):
    """ë¡œê·¸ë¥¼ ONNX ì¶”ë¡ ìš©ìœ¼ë¡œ ì¤€ë¹„"""

    # 1. ë¡œê·¸ íŒŒì‹± (Pythonì˜ drain3 ì‚¬ìš©)
    df = parse_and_mask_logs(input_log)

    # 2. vocab ë¡œë“œ
    with open(vocab_json) as f:
        vocab = json.load(f)

    # 3. template_idë¥¼ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    reverse_vocab = {str(v): int(k) for k, v in vocab.items()}
    df['template_index'] = df['template_id'].astype(str).map(reverse_vocab)

    # 4. JSONìœ¼ë¡œ ì €ì¥
    result = {
        'logs': df[['line_no', 'timestamp', 'template_index', 'masked']].to_dict('records')
    }

    with open(output_json, 'w') as f:
        json.dump(result, f)

    print(f"âœ… Prepared {len(df)} logs for ONNX inference")
    return df

if __name__ == "__main__":
    prepare_logs_for_onnx(
        'data/raw/system.log',
        'data/prepared.json',
        'basemodel/training_workspace/vocab.json'
    )
```

### Step 2: C ì—”ì§„ ìˆ˜ì • (JSON ì…ë ¥ ì§€ì›)

```c
// C ì—”ì§„ì´ JSONì„ ì½ê³  template_indexë¥¼ ì§ì ‘ ì‚¬ìš©
int process_prepared_json(InferenceEngine* engine, const char* json_path) {
    // JSON íŒŒì‹±
    // logs ë°°ì—´ì—ì„œ template_index ì¶”ì¶œ
    // ONNX ëª¨ë¸ì— template_index ì‹œí€€ìŠ¤ ì…ë ¥
}
```

### Step 3: í†µí•© ì‚¬ìš©

```bash
# 1. Pythonìœ¼ë¡œ ì „ì²˜ë¦¬ (ì •í™•í•œ template_id ê³„ì‚°)
python scripts/prepare_for_onnx_inference.py \
    --input data/raw/system.log \
    --vocab basemodel/training_workspace/vocab.json \
    --output data/prepared.json

# 2. C ì—”ì§„ìœ¼ë¡œ ê³ ì† ì¶”ë¡ 
./bin/inference_engine \
    -d models/deeplog.onnx \
    --prepared data/prepared.json \
    -o results.json
```

## ğŸ“Š ë¹„êµí‘œ

| ë°©ë²• | ì •í™•ë„ | ì†ë„ | êµ¬í˜„ ë³µì¡ë„ | ê¶Œì¥ë„ |
|------|--------|------|------------|--------|
| Option 1: Python ë§ˆìŠ¤í‚¹ | ë†’ìŒ | ì¤‘ê°„ | ë‚®ìŒ | â­â­â­â­ |
| Option 2: C ìœ ì‚¬ë„ ê°œì„  | ì¤‘ê°„ | ë¹ ë¦„ | ë†’ìŒ | â­â­â­ |
| Option 3: Template ID ì „ë‹¬ | ìµœê³  | ë§¤ìš° ë¹ ë¦„ | ì¤‘ê°„ | â­â­â­â­â­ |

## ğŸš€ ì„ì‹œ í•´ê²°ì±… (ì§€ê¸ˆ ë‹¹ì¥!)

C ì—”ì§„ì˜ ì„ê³„ê°’ì„ ë‚®ì¶”ê¸°:

```c
// log_parser.cì˜ 108-115ë²ˆ ë¼ì¸ ìˆ˜ì •

// ë³€ê²½ ì „
if (best_similarity < template_len * 0.5) {  // 50% ì„ê³„ê°’
    return -1;
}

// ë³€ê²½ í›„
if (best_similarity < 5) {  // ìµœì†Œ 5ê¸€ìë§Œ ì¼ì¹˜í•˜ë©´ OK
    return -1;
}

// ë˜ëŠ” ì„ê³„ê°’ ì™„ì „ ì œê±° (í…ŒìŠ¤íŠ¸ìš©)
// return best_template_id;  // ê°€ì¥ ìœ ì‚¬í•œ ê²ƒ ë¬´ì¡°ê±´ ë°˜í™˜
```

**ì¬ì»´íŒŒì¼**:
```bash
cd hybrid_system/inference
make clean && make
./bin/inference_engine -d models/deeplog.onnx -v models/vocab.json -t
```

## âœ… ìµœì¢… ê¶Œì¥ì‚¬í•­

**Option 3 (Template ID ì „ë‹¬) + Option 1 (Python ë§ˆìŠ¤í‚¹) ì¡°í•©**:

1. **ë‹¨ê¸°**: ì„ê³„ê°’ ë‚®ì¶”ê¸° (ì„ì‹œ í•´ê²°)
2. **ì¤‘ê¸°**: Python ë§ˆìŠ¤í‚¹ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
3. **ì¥ê¸°**: Template IDë¥¼ í¬í•¨í•œ JSON ì…ë ¥ ì§€ì›

### êµ¬í˜„ ìš°ì„ ìˆœìœ„

1. âœ… **ì¦‰ì‹œ**: ì„ê³„ê°’ ì¡°ì • (5ë¶„)
2. ğŸ“‹ **1ì£¼ì¼ ë‚´**: Python ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸ ì¶”ê°€
3. ğŸ“‹ **2ì£¼ì¼ ë‚´**: C ì—”ì§„ JSON ì…ë ¥ ì§€ì›

## ğŸ”— ê´€ë ¨ íŒŒì¼

- `hybrid_system/inference/src/log_parser.c` (108-115ë²ˆ ë¼ì¸)
- `hybrid_system/inference/src/anomaly_detector.c`
- `anomaly_log_detector/preprocess.py` (mask_message í•¨ìˆ˜)

---

**ì—…ë°ì´íŠ¸**: 2025-10-17
