# Vocabulary ë³€í™˜ FAQ

## â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸

### Q1: "í…œí”Œë¦¿ ë¬¸ìì—´ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ê²½ê³ ê°€ ë‚˜ì™”ì–´ìš”. export_vocab_with_templates.pyë¥¼ ë”°ë¡œ ìˆ˜í–‰í•´ì•¼ í•˜ë‚˜ìš”?

**ë‹µë³€**: **ëŒ€ë¶€ë¶„ì˜ ê²½ìš° í•„ìš” ì—†ìŠµë‹ˆë‹¤!** ì´ ë©”ì‹œì§€ëŠ” ìë™ ë³€í™˜ì´ ì‹¤íŒ¨í–ˆì„ ë•Œë§Œ ë‚˜íƒ€ë‚˜ëŠ” ì•ˆë‚´ì…ë‹ˆë‹¤.

#### âœ… ìë™ ë³€í™˜ì´ ì„±ê³µí•˜ëŠ” ê²½ìš° (99%)

```bash
$ python hybrid_system/training/model_converter.py \
    --deeplog-model .cache/deeplog.pth \
    --vocab data/processed/vocab.json \
    --output-dir hybrid_system/inference/models

INFO:__main__:ğŸ”„ vocabì„ C ì—”ì§„ìš© í…œí”Œë¦¿ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘...
INFO:__main__:ğŸ“‚ parsed.parquetì—ì„œ í…œí”Œë¦¿ ì¶”ì¶œ: data/processed/parsed.parquet
INFO:__main__:âœ… 7ê°œ í…œí”Œë¦¿ ì¶”ì¶œ ì™„ë£Œ
INFO:__main__:âœ… C ì—”ì§„ìš© vocab í˜•ì‹ (template strings): 7 templates  â† ì„±ê³µ!
```

**ì¡°ê±´**: `data/processed/` ë””ë ‰í† ë¦¬ì— ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ìë™ ë³€í™˜ ì„±ê³µ
- âœ… `parsed.parquet` (ìš°ì„ ìˆœìœ„ 1)
- âœ… `preview.json` (ìš°ì„ ìˆœìœ„ 2)

#### âš ï¸  ìˆ˜ë™ ë³€í™˜ì´ í•„ìš”í•œ ê²½ìš° (1%)

```bash
WARNING:__main__:âš ï¸  í…œí”Œë¦¿ ë¬¸ìì—´ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
WARNING:__main__:âš ï¸  /some/other/pathì— parsed.parquet ë˜ëŠ” preview.jsonì´ í•„ìš”í•©ë‹ˆë‹¤.
WARNING:__main__:âš ï¸  C ì—”ì§„ ì‚¬ìš©ì„ ìœ„í•´ ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:
    python hybrid_system/training/export_vocab_with_templates.py \
        /some/other/path/parsed.parquet \
        hybrid_system/inference/models/vocab.json
```

**ìƒí™©**: ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ìˆ˜í•œ ê²½ìš°ì—ë§Œ ë°œìƒ
- âŒ vocab.jsonì´ parsed.parquetì™€ **ë‹¤ë¥¸ ë””ë ‰í† ë¦¬**ì— ìˆìŒ
- âŒ vocab.json ë””ë ‰í† ë¦¬ì— `parsed.parquet`ë„ `preview.json`ë„ ì—†ìŒ

### Q2: ìë™ ë³€í™˜ì´ ì„±ê³µí–ˆëŠ”ì§€ ì–´ë–»ê²Œ í™•ì¸í•˜ë‚˜ìš”?

#### ë°©ë²• 1: ë¡œê·¸ ë©”ì‹œì§€ í™•ì¸

ì„±ê³µ ì‹œ:
```
âœ… 7ê°œ í…œí”Œë¦¿ ì¶”ì¶œ ì™„ë£Œ
âœ… C ì—”ì§„ìš© vocab í˜•ì‹ (template strings): 7 templates
```

ì‹¤íŒ¨ ì‹œ:
```
âš ï¸  í…œí”Œë¦¿ ë¬¸ìì—´ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
âš ï¸  vocabì´ ì¸ë±ìŠ¤ í˜•ì‹ì…ë‹ˆë‹¤.
```

#### ë°©ë²• 2: vocab.json íŒŒì¼ í™•ì¸

```bash
cat hybrid_system/inference/models/vocab.json | head -5
```

**ì˜¬ë°”ë¥¸ í˜•ì‹** (í…œí”Œë¦¿ ë¬¸ìì—´):
```json
{
  "1": "[<NUM>] usb 1-1: new high-speed USB device number <NUM> using ehci-pci",  âœ…
  "2": "[<NUM>] CPU<ID>: Core temperature above threshold, cpu clock throttled",  âœ…
  ...
}
```

**ì˜ëª»ëœ í˜•ì‹** (ì¸ë±ìŠ¤):
```json
{
  "1": 0,  âŒ
  "2": 1,  âŒ
  ...
}
```

#### ë°©ë²• 3: C inference engineìœ¼ë¡œ í™•ì¸

```bash
cd hybrid_system/inference
./bin/inference_engine -d models/deeplog.onnx -v models/vocab.json -t
```

**ì„±ê³µ**:
```
Loaded vocabulary: 7 templates  âœ…
```

**ì‹¤íŒ¨**:
```
Loaded vocabulary: 0 templates  âŒ
```

### Q3: ì–¸ì œ ìˆ˜ë™ìœ¼ë¡œ export_vocab_with_templates.pyë¥¼ ì‹¤í–‰í•˜ë‚˜ìš”?

#### ì¼€ì´ìŠ¤ 1: vocab.jsonê³¼ parsed.parquetê°€ ë‹¤ë¥¸ ìœ„ì¹˜

```bash
# ìƒí™©: vocab.jsonì´ /tmp/vocab.jsonì´ê³  parsed.parquetê°€ data/processed/ì— ìˆìŒ
python hybrid_system/training/model_converter.py \
    --vocab /tmp/vocab.json \  # parsed.parquetê°€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ì—†ìŒ!
    ...

# í•´ê²°: ìˆ˜ë™ ë³€í™˜
python hybrid_system/training/export_vocab_with_templates.py \
    data/processed/parsed.parquet \
    hybrid_system/inference/models/vocab.json
```

#### ì¼€ì´ìŠ¤ 2: íŠ¹ì • parsed.parquetë¥¼ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œ

```bash
# ë‹¤ë¥¸ ë°ì´í„°ì…‹ì˜ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œ
python hybrid_system/training/export_vocab_with_templates.py \
    /path/to/other/dataset/parsed.parquet \
    hybrid_system/inference/models/vocab.json
```

#### ì¼€ì´ìŠ¤ 3: vocab.jsonë§Œ ë³„ë„ë¡œ ì—…ë°ì´íŠ¸

```bash
# ONNX ëª¨ë¸ì€ ê·¸ëŒ€ë¡œ ë‘ê³  vocabë§Œ ì—…ë°ì´íŠ¸
python hybrid_system/training/export_vocab_with_templates.py \
    data/processed/parsed.parquet \
    hybrid_system/inference/models/vocab.json
```

### Q4: í‘œì¤€ ì›Œí¬í”Œë¡œìš°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

#### ì¶”ì²œ ì›Œí¬í”Œë¡œìš° (ìë™ ë³€í™˜)

```bash
# 1. ë¡œê·¸ íŒŒì‹± (parsed.parquet + preview.json ìƒì„±)
alog-detect parse --input data/raw/system.log --out-dir data/processed

# 2. ëª¨ë¸ í•™ìŠµ
alog-detect train-deeplog \
    --parsed data/processed/parsed.parquet \
    --out-dir data/processed

# 3. ONNX ë³€í™˜ (ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥¸ vocab.json ìƒì„±!)
python hybrid_system/training/model_converter.py \
    --deeplog-model .cache/deeplog.pth \
    --vocab data/processed/vocab.json \
    --output-dir hybrid_system/inference/models

# 4. C ì—”ì§„ ì‹¤í–‰
cd hybrid_system/inference
make && ./bin/inference_engine -d models/deeplog.onnx -v models/vocab.json -t
```

**í•µì‹¬**: `--vocab data/processed/vocab.json`ë¥¼ ì§€ì •í•˜ë©´, ê°™ì€ ë””ë ‰í† ë¦¬ì˜ `parsed.parquet`ì—ì„œ ìë™ìœ¼ë¡œ í…œí”Œë¦¿ ì¶”ì¶œ!

### Q5: ë””ë ‰í† ë¦¬ êµ¬ì¡°ê°€ ì¤‘ìš”í•œê°€ìš”?

#### âœ… ê¶Œì¥ êµ¬ì¡° (ìë™ ë³€í™˜ ì„±ê³µ)

```
data/processed/
â”œâ”€â”€ parsed.parquet       â† vocab.jsonê³¼ ê°™ì€ ë””ë ‰í† ë¦¬!
â”œâ”€â”€ preview.json         â† ë˜ëŠ” ì´ê²ƒì´ë¼ë„ ìˆìœ¼ë©´ OK
â”œâ”€â”€ vocab.json           â† ì—¬ê¸°ë¥¼ --vocabìœ¼ë¡œ ì§€ì •
â””â”€â”€ sequences.parquet
```

```bash
# ì´ë ‡ê²Œ ì‹¤í–‰í•˜ë©´ ìë™ ë³€í™˜ ì„±ê³µ!
python model_converter.py --vocab data/processed/vocab.json ...
```

#### âŒ ë¬¸ì œê°€ ë˜ëŠ” êµ¬ì¡°

```
data/processed/
â”œâ”€â”€ parsed.parquet
â””â”€â”€ vocab.json

/tmp/
â””â”€â”€ vocab.json           â† vocabë§Œ ë³„ë„ ìœ„ì¹˜
```

```bash
# ì´ë ‡ê²Œ ì‹¤í–‰í•˜ë©´ ìë™ ë³€í™˜ ì‹¤íŒ¨ (parsed.parquetë¥¼ ëª» ì°¾ìŒ)
python model_converter.py --vocab /tmp/vocab.json ...

# í•´ê²°: ìˆ˜ë™ ë³€í™˜
python export_vocab_with_templates.py \
    data/processed/parsed.parquet \
    hybrid_system/inference/models/vocab.json
```

### Q6: ìë™ ë³€í™˜ ë¡œì§ì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?

```python
# model_converter.pyì˜ _convert_vocab_for_c_engine()

# 1. vocab.jsonì˜ í˜•ì‹ í™•ì¸
if ê°’ì´_ì´ë¯¸_í…œí”Œë¦¿_ë¬¸ìì—´:
    return vocab  # ë³€í™˜ ë¶ˆí•„ìš”

# 2. vocab.jsonê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ ì°¾ê¸°
vocab_dir = Path(vocab_path).parent  # ì˜ˆ: data/processed/

# 3. parsed.parquetì—ì„œ ì¶”ì¶œ ì‹œë„
if (vocab_dir / "parsed.parquet").exists():
    template_map = parquetì—ì„œ_ì¶”ì¶œ()
    return template_map  âœ…

# 4. preview.jsonì—ì„œ ì¶”ì¶œ ì‹œë„
if (vocab_dir / "preview.json").exists():
    template_map = jsonì—ì„œ_ì¶”ì¶œ()
    return template_map  âœ…

# 5. ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ê²½ê³ 
logger.warning("âš ï¸  í…œí”Œë¦¿ ë¬¸ìì—´ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
logger.warning("âš ï¸  {vocab_dir}ì— parsed.parquet ë˜ëŠ” preview.jsonì´ í•„ìš”í•©ë‹ˆë‹¤.")
return vocab  # ì›ë³¸ vocab ë°˜í™˜ (ì¸ë±ìŠ¤ í˜•ì‹)
```

## ğŸ“Š ìš”ì•½

| ìƒí™© | ìë™ ë³€í™˜ | ìˆ˜ë™ ë³€í™˜ í•„ìš” |
|------|----------|-------------|
| vocab.jsonê³¼ parsed.parquetê°€ ê°™ì€ ë””ë ‰í† ë¦¬ | âœ… ì„±ê³µ | âŒ ë¶ˆí•„ìš” |
| vocab.jsonê³¼ preview.jsonì´ ê°™ì€ ë””ë ‰í† ë¦¬ | âœ… ì„±ê³µ | âŒ ë¶ˆí•„ìš” |
| vocab.jsonë§Œ ë‹¤ë¥¸ ìœ„ì¹˜ì— ë³µì‚¬ | âŒ ì‹¤íŒ¨ | âœ… í•„ìš” |
| ë‹¤ë¥¸ ë°ì´í„°ì…‹ì˜ í…œí”Œë¦¿ ì‚¬ìš© | âŒ (ì˜ë„ì ) | âœ… í•„ìš” |

## âœ… ê²°ë¡ 

### ëŒ€ë¶€ë¶„ì˜ ê²½ìš° (í‘œì¤€ ì›Œí¬í”Œë¡œìš°)

```bash
# ì´ê²ƒë§Œ ì‹¤í–‰í•˜ë©´ ë!
python hybrid_system/training/model_converter.py \
    --deeplog-model .cache/deeplog.pth \
    --vocab data/processed/vocab.json \
    --output-dir hybrid_system/inference/models

# export_vocab_with_templates.pyëŠ” ì‹¤í–‰ ì•ˆ í•´ë„ ë¨! âœ…
```

### íŠ¹ìˆ˜í•œ ê²½ìš°ì—ë§Œ

```bash
# vocab.jsonì´ parsed.parquetì™€ ë‹¤ë¥¸ ìœ„ì¹˜ì— ìˆê±°ë‚˜
# ë‹¤ë¥¸ ë°ì´í„°ì…‹ì˜ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œë§Œ
python hybrid_system/training/export_vocab_with_templates.py \
    <parsed.parquet> \
    <output_vocab.json>
```

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [ONNX Conversion Guide](./ONNX_CONVERSION_GUIDE.md) - ì „ì²´ ë³€í™˜ ê°€ì´ë“œ
- [Vocab Issue Resolved](../development/VOCAB_ISSUE_RESOLVED.md) - ë¬¸ì œ ë¶„ì„
- [Auto Vocab Conversion](../development/AUTO_VOCAB_CONVERSION.md) - êµ¬í˜„ ìƒì„¸
