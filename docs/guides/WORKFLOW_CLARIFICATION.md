# í•™ìŠµ â†’ ONNX ë³€í™˜ ì›Œí¬í”Œë¡œìš° ëª…í™•í™”

## ğŸ¯ í•µì‹¬ ê°œë…

**ë‘ ê°œì˜ vocab.jsonì´ ì¡´ì¬í•˜ë©°, ê°ê° ë‹¤ë¥¸ ìš©ë„ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤!**

| íŒŒì¼ ìœ„ì¹˜ | ìš©ë„ | í˜•ì‹ | ìƒì„± ì‹œì  |
|----------|------|------|----------|
| `data/processed/vocab.json` | Python í•™ìŠµ | ì¸ë±ìŠ¤ | `train.sh` ì‹¤í–‰ ì‹œ |
| `hybrid_system/inference/models/vocab.json` | ONNX/C ì—”ì§„ | í…œí”Œë¦¿ ë¬¸ìì—´ | `model_converter.py` ì‹¤í–‰ ì‹œ |

## ğŸ“‹ ì „ì²´ ì›Œí¬í”Œë¡œìš°

### Step 1: ë¡œê·¸ íŒŒì‹± (Parse)

```bash
alog-detect parse --input data/raw/system.log --out-dir data/processed
```

**ìƒì„±ë˜ëŠ” íŒŒì¼**:
```
data/processed/
â”œâ”€â”€ parsed.parquet       # âœ… í…œí”Œë¦¿ ë¬¸ìì—´ í¬í•¨!
â”œâ”€â”€ preview.json         # âœ… í…œí”Œë¦¿ ë¬¸ìì—´ í¬í•¨!
â”œâ”€â”€ vocab.json           # âš ï¸  ì¸ë±ìŠ¤ í˜•ì‹ (Pythonìš©)
â””â”€â”€ sequences.parquet
```

**vocab.json ë‚´ìš©** (Python í•™ìŠµìš©):
```json
{
  "1": 0,   // template_id â†’ index
  "2": 1,
  "3": 2
}
```

### Step 2: ëª¨ë¸ í•™ìŠµ (Train)

```bash
# scripts/train.sh ë˜ëŠ”
alog-detect train-deeplog \
    --parsed data/processed/parsed.parquet \
    --out-dir data/processed
```

**ì‚¬ìš©í•˜ëŠ” íŒŒì¼**:
- âœ… `data/processed/vocab.json` (ì¸ë±ìŠ¤ í˜•ì‹) â† Python í•™ìŠµì— ì í•©
- âœ… `data/processed/sequences.parquet`

**ìƒì„±ë˜ëŠ” íŒŒì¼**:
```
.cache/
â””â”€â”€ deeplog.pth          # PyTorch ëª¨ë¸
```

**ì¤‘ìš”**: `data/processed/vocab.json`ì€ **ìˆ˜ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!** ì¸ë±ìŠ¤ í˜•ì‹ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.

### Step 3: ONNX ë³€í™˜ (Convert)

```bash
python hybrid_system/training/model_converter.py \
    --deeplog-model .cache/deeplog.pth \
    --vocab data/processed/vocab.json \              # â† Pythonìš© vocab ì…ë ¥
    --output-dir hybrid_system/inference/models
```

**ì…ë ¥ íŒŒì¼**:
- âœ… `.cache/deeplog.pth` (PyTorch ëª¨ë¸)
- âœ… `data/processed/vocab.json` (ì¸ë±ìŠ¤ í˜•ì‹)
- âœ… `data/processed/parsed.parquet` (ìë™ ê°ì§€!)

**ìƒì„±ë˜ëŠ” íŒŒì¼**:
```
hybrid_system/inference/models/
â”œâ”€â”€ deeplog.onnx                 # ONNX ëª¨ë¸
â”œâ”€â”€ deeplog_optimized.onnx       # ìµœì í™”ëœ ONNX
â”œâ”€â”€ deeplog.onnx.meta.json       # ë©”íƒ€ë°ì´í„°
â”œâ”€â”€ vocab.json                   # âœ… ìë™ìœ¼ë¡œ í…œí”Œë¦¿ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ìƒì„±!
â””â”€â”€ conversion_summary.json
```

**ì¶œë ¥ vocab.json ë‚´ìš©** (ONNX/C ì—”ì§„ìš©):
```json
{
  "1": "[<NUM>] usb 1-1: new high-speed USB device number <NUM> using ehci-pci",
  "2": "[<NUM>] CPU<ID>: Core temperature above threshold, cpu clock throttled",
  "3": "[<NUM>] CPU<ID>: Core temperature<PATH> normal"
}
```

**ìë™ ë³€í™˜ ë¡œì§**:
1. `--vocab data/processed/vocab.json` ì§€ì •
2. ê°™ì€ ë””ë ‰í† ë¦¬ì˜ `parsed.parquet` ìë™ ê°ì§€
3. `parsed.parquet`ì—ì„œ í…œí”Œë¦¿ ë¬¸ìì—´ ì¶”ì¶œ
4. `hybrid_system/inference/models/vocab.json`ì„ í…œí”Œë¦¿ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ìƒì„±

### Step 4: C ì—”ì§„ ì‹¤í–‰ (Inference)

```bash
cd hybrid_system/inference
make && ./bin/inference_engine \
    -d models/deeplog.onnx \
    -v models/vocab.json \        # â† í…œí”Œë¦¿ ë¬¸ìì—´ í˜•ì‹
    -t
```

**ì‚¬ìš©í•˜ëŠ” íŒŒì¼**:
- âœ… `models/deeplog.onnx`
- âœ… `models/vocab.json` (í…œí”Œë¦¿ ë¬¸ìì—´ í˜•ì‹)

## ğŸ”„ ì™œ ë‘ ê°œì˜ vocab.jsonì´ í•„ìš”í•œê°€?

### Python í•™ìŠµ í™˜ê²½

```python
# PyTorch ëª¨ë¸ì€ ì¸ë±ìŠ¤ë§Œ í•„ìš”
vocab = {"1": 0, "2": 1, "3": 2}

# ì‹œí€€ìŠ¤ ë°ì´í„°
sequence = [0, 1, 2, 0, 1]  # ì¸ë±ìŠ¤ë¡œë§Œ êµ¬ì„±

# ëª¨ë¸ ì…ë ¥
input_tensor = torch.tensor([0, 1, 2])  # ì¸ë±ìŠ¤
```

**ì´ìœ **: PyTorchëŠ” í…œí”Œë¦¿ IDë¥¼ ìˆ«ì ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ í•™ìŠµí•©ë‹ˆë‹¤. í…œí”Œë¦¿ ë¬¸ìì—´ì€ í•„ìš” ì—†ìŠµë‹ˆë‹¤.

### C ì¶”ë¡  ì—”ì§„

```c
// C ì—”ì§„ì€ ë¡œê·¸ ë¼ì¸ì„ í…œí”Œë¦¿ê³¼ ë§¤ì¹­í•´ì•¼ í•¨
char* log_line = "[12345.678901] usb 1-1: new high-speed USB device...";

// í…œí”Œë¦¿ê³¼ ìœ ì‚¬ë„ ë¹„êµ
for (i = 0; i < vocab_size; i++) {
    similarity = compare(log_line, vocab->templates[i]);
    // "usb 1-1: new high-speed" vs "[<NUM>] usb 1-1: new high-speed..."
}
```

**ì´ìœ **: C ì—”ì§„ì€ ì‹¤ì œ ë¡œê·¸ ë¼ì¸ê³¼ í…œí”Œë¦¿ì„ ë¹„êµí•˜ì—¬ ê°€ì¥ ìœ ì‚¬í•œ í…œí”Œë¦¿ì„ ì°¾ì•„ì•¼ í•©ë‹ˆë‹¤. ë¬¸ìì—´ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.

## â“ ìì£¼ í•˜ëŠ” ì‹¤ìˆ˜

### âŒ ì‹¤ìˆ˜ 1: Pythonìš© vocabì„ ONNX ë³€í™˜ í›„ì— ìˆ˜ì •

```bash
# ì˜ëª»ëœ ë°©ë²•
alog-detect train-deeplog ...
python model_converter.py --vocab data/processed/vocab.json ...

# vocab.jsonì„ ìˆ˜ë™ìœ¼ë¡œ ìˆ˜ì • âŒ
python export_vocab_with_templates.py \
    data/processed/parsed.parquet \
    data/processed/vocab.json  # â† Python í•™ìŠµ ë””ë ‰í† ë¦¬ë¥¼ ìˆ˜ì •í•˜ë©´ ì•ˆ ë¨!
```

**ë¬¸ì œ**: `data/processed/vocab.json`ì€ Python í•™ìŠµìš©ì´ë¯€ë¡œ ì¸ë±ìŠ¤ í˜•ì‹ìœ¼ë¡œ ìœ ì§€ë˜ì–´ì•¼ í•©ë‹ˆë‹¤!

**ì˜¬ë°”ë¥¸ ë°©ë²•**:
```bash
# model_converter.pyê°€ ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ìœ„ì¹˜ì— ìƒì„±
# data/processed/vocab.jsonì€ ê·¸ëŒ€ë¡œ ë‘  âœ…
```

### âŒ ì‹¤ìˆ˜ 2: ONNX vocabì„ Python í•™ìŠµì— ì‚¬ìš©

```bash
# ì˜ëª»ëœ ë°©ë²•
cp hybrid_system/inference/models/vocab.json data/processed/vocab.json  # âŒ

alog-detect train-deeplog --parsed data/processed/parsed.parquet ...
# â†’ ì—ëŸ¬ ë°œìƒ! í…œí”Œë¦¿ ë¬¸ìì—´ì„ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŒ
```

**ì˜¬ë°”ë¥¸ ë°©ë²•**: ê° vocab.jsonì„ ìê¸° ìœ„ì¹˜ì— ìœ ì§€ âœ…

### âŒ ì‹¤ìˆ˜ 3: vocab.jsonì„ ë‹¤ë¥¸ ìœ„ì¹˜ë¡œ ì´ë™

```bash
# ì˜ëª»ëœ ë°©ë²•
mv data/processed/vocab.json /tmp/vocab.json

python model_converter.py --vocab /tmp/vocab.json ...
# â†’ ìë™ ë³€í™˜ ì‹¤íŒ¨! parsed.parquetë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ
```

**ì˜¬ë°”ë¥¸ ë°©ë²•**: vocab.jsonì„ ì›ë˜ ìœ„ì¹˜ì— ìœ ì§€ âœ…

## âœ… ì˜¬ë°”ë¥¸ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ system.log
â”‚   â””â”€â”€ processed/              # Python í•™ìŠµ ì˜ì—­
â”‚       â”œâ”€â”€ parsed.parquet      # âœ… í…œí”Œë¦¿ ë¬¸ìì—´ ë³´ìœ  (ìë™ ë³€í™˜ì— ì‚¬ìš©)
â”‚       â”œâ”€â”€ preview.json        # âœ… í…œí”Œë¦¿ ë¬¸ìì—´ ë³´ìœ  (fallback)
â”‚       â”œâ”€â”€ vocab.json          # âš ï¸  ì¸ë±ìŠ¤ í˜•ì‹ (Python í•™ìŠµìš©)
â”‚       â””â”€â”€ sequences.parquet
â”‚
â”œâ”€â”€ .cache/
â”‚   â””â”€â”€ deeplog.pth             # PyTorch ëª¨ë¸
â”‚
â””â”€â”€ hybrid_system/
    â”œâ”€â”€ training/
    â”‚   â”œâ”€â”€ model_converter.py  # ONNX ë³€í™˜ + ìë™ vocab ë³€í™˜
    â”‚   â””â”€â”€ export_vocab_with_templates.py  # ìˆ˜ë™ ë³€í™˜ (ê±°ì˜ ì‚¬ìš© ì•ˆ í•¨)
    â””â”€â”€ inference/
        â””â”€â”€ models/             # C ì—”ì§„ ì˜ì—­
            â”œâ”€â”€ deeplog.onnx
            â””â”€â”€ vocab.json      # âœ… í…œí”Œë¦¿ ë¬¸ìì—´ í˜•ì‹ (C ì—”ì§„ìš©)
```

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### í•™ìŠµ ì™„ë£Œ í›„ í™•ì¸

```bash
# 1. Pythonìš© vocab í™•ì¸ (ì¸ë±ìŠ¤ í˜•ì‹ì´ì–´ì•¼ í•¨)
cat data/processed/vocab.json
# ì¶œë ¥: {"1": 0, "2": 1, ...}  âœ…

# 2. parsed.parquet ì¡´ì¬ í™•ì¸ (ìë™ ë³€í™˜ì— í•„ìš”)
ls -lh data/processed/parsed.parquet  âœ…
```

### ONNX ë³€í™˜ í›„ í™•ì¸

```bash
# 1. ONNX vocab í™•ì¸ (í…œí”Œë¦¿ ë¬¸ìì—´ì´ì–´ì•¼ í•¨)
cat hybrid_system/inference/models/vocab.json
# ì¶œë ¥: {"1": "[<NUM>] usb ...", ...}  âœ…

# 2. Python vocabì€ ê·¸ëŒ€ë¡œ ìœ ì§€ í™•ì¸
cat data/processed/vocab.json
# ì¶œë ¥: {"1": 0, "2": 1, ...}  âœ… (ë³€ê²½ë˜ì§€ ì•ŠìŒ!)
```

### C ì—”ì§„ ì‹¤í–‰ ì „ í™•ì¸

```bash
cd hybrid_system/inference

# 1. Vocab ë¡œë“œ í™•ì¸
./bin/inference_engine -d models/deeplog.onnx -v models/vocab.json -t 2>&1 | grep "Loaded vocabulary"
# ì¶œë ¥: Loaded vocabulary: 7 templates  âœ… (0ì´ ì•„ë‹ˆì–´ì•¼ í•¨!)
```

## ğŸ¯ ë‹¤ë¥¸ ì‹œìŠ¤í…œì—ì„œ ì‘ì—…í•  ë•Œ

### ì‹œë‚˜ë¦¬ì˜¤: í•™ìŠµì€ ì„œë²„ A, ì¶”ë¡ ì€ ì„œë²„ B

#### ì„œë²„ A (í•™ìŠµ)

```bash
# 1. íŒŒì‹±
alog-detect parse --input data/raw/system.log --out-dir data/processed

# 2. í•™ìŠµ
alog-detect train-deeplog --parsed data/processed/parsed.parquet --out-dir data/processed

# 3. ONNX ë³€í™˜
python hybrid_system/training/model_converter.py \
    --deeplog-model .cache/deeplog.pth \
    --vocab data/processed/vocab.json \
    --output-dir hybrid_system/inference/models

# 4. í•„ìš”í•œ íŒŒì¼ë§Œ ë³µì‚¬ ì¤€ë¹„
tar -czf onnx_bundle.tar.gz \
    hybrid_system/inference/models/deeplog.onnx \
    hybrid_system/inference/models/vocab.json
```

#### ì„œë²„ B (ì¶”ë¡ )

```bash
# 1. íŒŒì¼ ì „ì†¡
scp serverA:onnx_bundle.tar.gz .
tar -xzf onnx_bundle.tar.gz

# 2. C ì—”ì§„ ë¹Œë“œ
cd hybrid_system/inference
make

# 3. ì‹¤í–‰
./bin/inference_engine \
    -d models/deeplog.onnx \
    -v models/vocab.json \
    -i /var/log/syslog
```

**ì¤‘ìš”**: `data/processed/vocab.json`ì€ ì „ì†¡í•  í•„ìš” ì—†ìŠµë‹ˆë‹¤! C ì—”ì§„ì€ `hybrid_system/inference/models/vocab.json`ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.

## ğŸ“Š ìš”ì•½ í‘œ

| ë‹¨ê³„ | ëª…ë ¹ì–´ | vocab.json ìœ„ì¹˜ | vocab.json í˜•ì‹ | ìˆ˜ì • ì—¬ë¶€ |
|------|--------|---------------|--------------|----------|
| Parse | `alog-detect parse` | `data/processed/` | ì¸ë±ìŠ¤ ìƒì„± | ìƒì„±ë¨ |
| Train | `alog-detect train-deeplog` | `data/processed/` | ì¸ë±ìŠ¤ (ì‚¬ìš©) | ìœ ì§€ |
| Convert | `model_converter.py` | `data/processed/` (ì…ë ¥)<br>`hybrid_system/inference/models/` (ì¶œë ¥) | ì¸ë±ìŠ¤ (ì…ë ¥)<br>í…œí”Œë¦¿ ë¬¸ìì—´ (ì¶œë ¥) | `data/processed/` ìœ ì§€<br>`models/` ìƒì„± |
| Inference | `inference_engine` | `hybrid_system/inference/models/` | í…œí”Œë¦¿ ë¬¸ìì—´ (ì‚¬ìš©) | ìœ ì§€ |

## âœ… ìµœì¢… ë‹µë³€

### ì§ˆë¬¸: "train.sh ìˆ˜í–‰ ì‹œì— basemodel ë””ë ‰í† ë¦¬ì˜ vocab.jsonì„ ë³€ê²½í•˜ëŠ”ê²Œ ë§ì•„?"

**ë‹µë³€**: âŒ **ì•„ë‹ˆìš”! ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!**

- `data/processed/vocab.json`ì€ ì¸ë±ìŠ¤ í˜•ì‹ìœ¼ë¡œ ìœ ì§€
- `model_converter.py`ê°€ ìë™ìœ¼ë¡œ `hybrid_system/inference/models/vocab.json`ì„ í…œí”Œë¦¿ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ìƒì„±

### ì§ˆë¬¸: "basemodel í•˜ìœ„ì— onnxë¥¼ ìƒì„±í•˜ê³  ê·¸ ì•ˆì— vocab.jsonì„ ë§Œë“¤ê³ .. convert ì‹œì— í•´ë‹¹ íŒŒì¼ ìœ„ì¹˜ë¥¼ ë„£ì–´ì¤˜ì•¼ í•˜ëŠ”ê±°ì•¼?"

**ë‹µë³€**: âŒ **ì•„ë‹ˆìš”! ê·¸ ë°˜ëŒ€ì…ë‹ˆë‹¤!**

**ì˜¬ë°”ë¥¸ ìˆœì„œ**:
1. `--vocab data/processed/vocab.json` (ì¸ë±ìŠ¤ í˜•ì‹) ì…ë ¥
2. `model_converter.py`ê°€ ìë™ìœ¼ë¡œ `parsed.parquet`ì—ì„œ í…œí”Œë¦¿ ì¶”ì¶œ
3. `--output-dir hybrid_system/inference/models/vocab.json` (í…œí”Œë¦¿ ë¬¸ìì—´) ìë™ ìƒì„±

## ğŸ‰ í•µì‹¬ ì •ë¦¬

```bash
# í•œ ì¤„ ìš”ì•½: ì´ê²ƒë§Œ í•˜ë©´ ëª¨ë“  ê²ƒì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤!

# 1. íŒŒì‹± + í•™ìŠµ
alog-detect parse --input data/raw/system.log --out-dir data/processed
alog-detect train-deeplog --parsed data/processed/parsed.parquet --out-dir data/processed

# 2. ONNX ë³€í™˜ (ìë™ vocab ë³€í™˜!)
python hybrid_system/training/model_converter.py \
    --deeplog-model .cache/deeplog.pth \
    --vocab data/processed/vocab.json \          # â† ì¸ë±ìŠ¤ í˜•ì‹ ì…ë ¥
    --output-dir hybrid_system/inference/models   # â† í…œí”Œë¦¿ ë¬¸ìì—´ ìë™ ìƒì„±!

# data/processed/vocab.jsonì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë¨ âœ…
# hybrid_system/inference/models/vocab.jsonì´ ìë™ ìƒì„±ë¨ âœ…
```

**ìˆ˜ë™ ì‘ì—… ë¶ˆí•„ìš”!** ëª¨ë“  ê²ƒì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤! ğŸ‰
