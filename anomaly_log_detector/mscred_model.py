"""
MS-CRED (Multi-Scale Convolutional Recurrent Encoder-Decoder) Î™®Îç∏ Íµ¨ÌòÑ

MS-CREDÎäî ÏãúÍ≥ÑÏó¥ Ïù¥ÏÉÅÌÉêÏßÄÎ•º ÏúÑÌïú Î©ÄÌã∞Ïä§ÏºÄÏùº Ïª®Î≥ºÎ£®ÏÖò Ïò§ÌÜ†Ïù∏ÏΩîÎçîÏûÖÎãàÎã§.
Î°úÍ∑∏ ÌÖúÌîåÎ¶ø Ïπ¥Ïö¥Ìä∏ Îß§Ìä∏Î¶≠Ïä§Î•º ÏûÖÎ†•ÏúºÎ°ú Î∞õÏïÑ Ïû¨Íµ¨ÏÑ± Ïò§Ï∞®Î•º ÌÜµÌï¥ Ïù¥ÏÉÅÏùÑ ÌÉêÏßÄÌï©ÎãàÎã§.
"""

from __future__ import annotations

import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Tuple, List, Dict, Optional
import json
from tqdm import tqdm


class MultiScaleConvBlock(nn.Module):
    """Î©ÄÌã∞Ïä§ÏºÄÏùº Ïª®Î≥ºÎ£®ÏÖò Î∏îÎ°ù"""
    
    def __init__(self, in_channels: int, out_channels: int, kernel_sizes: List[int] = [3, 5, 7]):
        super().__init__()
        self.kernel_sizes = kernel_sizes
        
        # Í∞Å Ïª§ÎÑêÏùò Ï±ÑÎÑê ÏàòÎ•º Í∑†Îì±ÌïòÍ≤å Î∂ÑÎ∞∞ÌïòÎêò ÎÇòÎ®∏ÏßÄÎäî Ï≤´ Î≤àÏß∏ Ïª§ÎÑêÏóê Ìï†Îãπ
        channels_per_kernel = out_channels // len(kernel_sizes)
        remainder = out_channels % len(kernel_sizes)
        
        # Í∞Å Ïª§ÎÑê ÌÅ¨Í∏∞Î≥Ñ Ïª®Î≥ºÎ£®ÏÖò Î†àÏù¥Ïñ¥
        self.convs = nn.ModuleList()
        for i, k in enumerate(kernel_sizes):
            # Ï≤´ Î≤àÏß∏ Ïª§ÎÑêÏóê ÎÇòÎ®∏ÏßÄ Ï±ÑÎÑê Ï∂îÍ∞Ä
            current_channels = channels_per_kernel + (remainder if i == 0 else 0)
            self.convs.append(
                nn.Conv2d(in_channels, current_channels, kernel_size=k, padding=k//2)
            )
        
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Í∞Å Ïª§ÎÑê ÌÅ¨Í∏∞Î≥ÑÎ°ú Ïª®Î≥ºÎ£®ÏÖò Ï†ÅÏö© ÌõÑ Ï±ÑÎÑê Ï∞®ÏõêÏóêÏÑú Í≤∞Ìï©
        conv_outputs = [conv(x) for conv in self.convs]
        out = torch.cat(conv_outputs, dim=1)
        out = self.bn(out)
        out = self.relu(out)
        return out


class AttentionModule(nn.Module):
    """Ïñ¥ÌÖêÏÖò Î™®Îìà"""
    
    def __init__(self, channels: int):
        super().__init__()
        self.conv_att = nn.Conv2d(channels, 1, kernel_size=1)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Ï±ÑÎÑêÎ≥Ñ Ïñ¥ÌÖêÏÖò Í∞ÄÏ§ëÏπò Í≥ÑÏÇ∞
        att_weights = torch.sigmoid(self.conv_att(x))
        return x * att_weights


class MSCREDEncoder(nn.Module):
    """MS-CRED Ïù∏ÏΩîÎçî"""
    
    def __init__(self, input_channels: int = 1, base_channels: int = 32):
        super().__init__()
        
        # Î©ÄÌã∞Ïä§ÏºÄÏùº Ïª®Î≥ºÎ£®ÏÖò Î†àÏù¥Ïñ¥Îì§
        self.conv1 = MultiScaleConvBlock(input_channels, base_channels)
        self.conv2 = MultiScaleConvBlock(base_channels, base_channels * 2)
        self.conv3 = MultiScaleConvBlock(base_channels * 2, base_channels * 4)
        
        # Ïñ¥ÌÖêÏÖò Î™®ÎìàÎì§
        self.att1 = AttentionModule(base_channels)
        self.att2 = AttentionModule(base_channels * 2)
        self.att3 = AttentionModule(base_channels * 4)
        
        # Îã§Ïö¥ÏÉòÌîåÎßÅ
        self.pool = nn.MaxPool2d(2, 2)
        
    def forward(self, x: torch.Tensor) -> List[torch.Tensor]:
        # x: (batch, 1, height, width) - height: time_steps, width: num_templates
        
        # Ï≤´ Î≤àÏß∏ Ïä§ÏºÄÏùº
        x1 = self.conv1(x)
        x1_att = self.att1(x1)
        
        # Îëê Î≤àÏß∏ Ïä§ÏºÄÏùº 
        x2 = self.pool(x1_att)
        x2 = self.conv2(x2)
        x2_att = self.att2(x2)
        
        # ÏÑ∏ Î≤àÏß∏ Ïä§ÏºÄÏùº
        x3 = self.pool(x2_att)
        x3 = self.conv3(x3)
        x3_att = self.att3(x3)
        
        return [x1_att, x2_att, x3_att]


class MSCREDDecoder(nn.Module):
    """MS-CRED ÎîîÏΩîÎçî (Í∞ÑÏÜåÌôî Î≤ÑÏ†Ñ)"""
    
    def __init__(self, base_channels: int = 32, output_channels: int = 1):
        super().__init__()
        
        # Í∞ÑÎã®Ìïú ÏóÖÏÉòÌîåÎßÅ ÎîîÏΩîÎçî
        self.deconv3 = nn.ConvTranspose2d(base_channels * 4, base_channels * 2, 
                                         kernel_size=4, stride=2, padding=1)
        self.deconv2 = nn.ConvTranspose2d(base_channels * 2, base_channels, 
                                         kernel_size=4, stride=2, padding=1)
        self.deconv1 = nn.Conv2d(base_channels, output_channels, kernel_size=3, padding=1)
        
        self.relu = nn.ReLU(inplace=True)
        
    def forward(self, encoder_outputs: List[torch.Tensor]) -> torch.Tensor:
        # Í∞ÄÏû• ÏûëÏùÄ ÌîºÏ≤òÎßµ(Í∞ÄÏû• ÍπäÏùÄ Ïù∏ÏΩîÎî©)Îßå ÏÇ¨Ïö©
        _, _, x3_att = encoder_outputs
        
        # ÏóÖÏÉòÌîåÎßÅÏúºÎ°ú ÏõêÎûò ÌÅ¨Í∏∞Î°ú Î≥µÏõê
        x = self.relu(self.deconv3(x3_att))
        x = self.relu(self.deconv2(x))
        x = self.deconv1(x)
        
        return x


class MSCREDModel(nn.Module):
    """MS-CRED Ï†ÑÏ≤¥ Î™®Îç∏"""
    
    def __init__(self, input_channels: int = 1, base_channels: int = 32):
        super().__init__()
        self.encoder = MSCREDEncoder(input_channels, base_channels)
        self.decoder = MSCREDDecoder(base_channels, input_channels)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # ÏûÖÎ†• ÌÅ¨Í∏∞ Ï†ÄÏû•
        input_shape = x.shape

        encoded = self.encoder(x)
        reconstructed = self.decoder(encoded)

        # Ï∂úÎ†• ÌÅ¨Í∏∞Î•º ÏûÖÎ†• ÌÅ¨Í∏∞ÏôÄ Ï†ïÌôïÌûà ÎßûÏ∂§
        # ONNX Ï∂îÏ†Å Ìò∏ÌôòÏÑ±: shape ÎπÑÍµê ÎåÄÏã† Ìï≠ÏÉÅ interpolate ÏàòÌñâ
        # (ÏûÖÎ†•Í≥º Ï∂úÎ†•Ïù¥ Í∞ôÏúºÎ©¥ interpolateÎäî no-op)
        reconstructed = F.interpolate(
            reconstructed,
            size=(input_shape[2], input_shape[3]),
            mode='bilinear',
            align_corners=False
        )

        return reconstructed
    
    def compute_reconstruction_error(self, x: torch.Tensor, reconstructed: torch.Tensor) -> torch.Tensor:
        """Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞"""
        return F.mse_loss(reconstructed, x, reduction='none').mean(dim=[1, 2, 3])


class MSCREDTrainer:
    """MS-CRED Î™®Îç∏ Ìä∏Î†àÏù¥ÎÑà"""
    
    def __init__(self, model: MSCREDModel, device: str = 'cpu'):
        self.model = model.to(device)
        self.device = device
        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5, patience=5
        )
        
    def prepare_data(self, window_counts_df: pd.DataFrame) -> torch.Tensor:
        """ÏúàÎèÑÏö∞ Ïπ¥Ïö¥Ìä∏ Îç∞Ïù¥ÌÑ∞Î•º ÌÖêÏÑúÎ°ú Î≥ÄÌôò"""
        # start_index Ïª¨Îüº Ï†úÍ±∞ÌïòÍ≥† ÌÖúÌîåÎ¶ø Ïπ¥Ïö¥Ìä∏Îßå Ï∂îÏ∂ú
        template_cols = [col for col in window_counts_df.columns if col.startswith('t')]
        data = window_counts_df[template_cols].fillna(0).values
        
        # Ï†ïÍ∑úÌôî
        data = (data - data.mean(axis=0)) / (data.std(axis=0) + 1e-8)
        
        # 2D Îß§Ìä∏Î¶≠Ïä§Î•º Ïù¥ÎØ∏ÏßÄ ÌòïÌÉúÎ°ú Î≥ÄÌôò (time_steps, num_templates)
        # ÏãúÌÄÄÏä§ Í∏∏Ïù¥ ÏÑ§Ï†ï (Ïòà: 20Í∞ú ÏúàÎèÑÏö∞Ïî©)
        seq_len = 20
        sequences = []
        
        for i in range(len(data) - seq_len + 1):
            seq = data[i:i+seq_len]  # (seq_len, num_templates)
            sequences.append(seq)
        
        if not sequences:
            # Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±Ìïú Í≤ΩÏö∞ Ìå®Îî©
            padded_data = np.pad(data, ((0, seq_len - len(data)), (0, 0)), mode='constant')
            sequences = [padded_data]
        
        # (batch, 1, time_steps, num_templates) ÌòïÌÉúÎ°ú Î≥ÄÌôò
        sequences = np.array(sequences)
        return torch.FloatTensor(sequences).unsqueeze(1)
    
    def train(self, window_counts_path: str | Path, epochs: int = 50, 
              validation_split: float = 0.2) -> Dict:
        """Î™®Îç∏ ÌïôÏäµ"""
        
        # Îç∞Ïù¥ÌÑ∞ Î°úÎìú
        df = pd.read_parquet(window_counts_path)
        data_tensor = self.prepare_data(df).to(self.device)
        
        # ÌïôÏäµ/Í≤ÄÏ¶ù Î∂ÑÌï†
        n_train = int(len(data_tensor) * (1 - validation_split))
        train_data = data_tensor[:n_train]
        val_data = data_tensor[n_train:]
        
        print(f"üìä ÌïôÏäµ Îç∞Ïù¥ÌÑ∞: {len(train_data)}, Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞: {len(val_data)}")
        print(f"üìê Îç∞Ïù¥ÌÑ∞ ÌòïÌÉú: {data_tensor.shape}")
        
        train_losses = []
        val_losses = []
        
        self.model.train()
        
        for epoch in tqdm(range(epochs), desc="MS-CRED ÌïôÏäµ"):
            # ÌïôÏäµ
            epoch_train_loss = 0
            for i in range(0, len(train_data), 32):  # Î∞∞Ïπò ÌÅ¨Í∏∞ 32
                batch = train_data[i:i+32]
                
                self.optimizer.zero_grad()
                reconstructed = self.model(batch)
                loss = F.mse_loss(reconstructed, batch)
                loss.backward()
                self.optimizer.step()
                
                epoch_train_loss += loss.item()
            
            # Í≤ÄÏ¶ù
            self.model.eval()
            epoch_val_loss = 0
            with torch.no_grad():
                for i in range(0, len(val_data), 32):
                    batch = val_data[i:i+32]
                    reconstructed = self.model(batch)
                    loss = F.mse_loss(reconstructed, batch)
                    epoch_val_loss += loss.item()
            
            self.model.train()
            
            avg_train_loss = epoch_train_loss / (len(train_data) // 32 + 1)
            avg_val_loss = epoch_val_loss / (len(val_data) // 32 + 1) if len(val_data) > 0 else 0
            
            train_losses.append(avg_train_loss)
            val_losses.append(avg_val_loss)
            
            self.scheduler.step(avg_val_loss)
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}")
        
        return {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'final_train_loss': train_losses[-1],
            'final_val_loss': val_losses[-1]
        }
    
    def save_model(self, path: str | Path):
        """Î™®Îç∏ Ï†ÄÏû•"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
        }, path)
        print(f"‚úÖ Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {path}")
    
    def load_model(self, path: str | Path):
        """Î™®Îç∏ Î°úÎìú"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        print(f"‚úÖ Î™®Îç∏ Î°úÎìú ÏôÑÎ£å: {path}")


class MSCREDInference:
    """MS-CRED Ï∂îÎ°†"""
    
    def __init__(self, model_path: str | Path, device: str = 'cpu'):
        self.device = device
        self.model = MSCREDModel().to(device)
        
        # Î™®Îç∏ Î°úÎìú
        checkpoint = torch.load(model_path, map_location=device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
    def detect_anomalies(self, window_counts_path: str | Path, 
                        threshold_percentile: float = 95.0) -> pd.DataFrame:
        """Ïù¥ÏÉÅ ÌÉêÏßÄ ÏàòÌñâ"""
        
        # Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
        trainer = MSCREDTrainer(self.model, self.device)
        df = pd.read_parquet(window_counts_path)
        data_tensor = trainer.prepare_data(df).to(self.device)
        
        print(f"üìä Ï∂îÎ°† Îç∞Ïù¥ÌÑ∞ ÌòïÌÉú: {data_tensor.shape}")
        
        # Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® Í≥ÑÏÇ∞
        reconstruction_errors = []
        
        with torch.no_grad():
            for i in range(0, len(data_tensor), 32):
                batch = data_tensor[i:i+32]
                reconstructed = self.model(batch)
                errors = self.model.compute_reconstruction_error(batch, reconstructed)
                reconstruction_errors.extend(errors.cpu().numpy())
        
        # ÏûÑÍ≥ÑÍ∞í Í≥ÑÏÇ∞
        errors_array = np.array(reconstruction_errors)
        threshold = np.percentile(errors_array, threshold_percentile)
        
        # Í≤∞Í≥º Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ±
        results = []
        for i, error in enumerate(reconstruction_errors):
            is_anomaly = error > threshold
            
            # ÏõêÎ≥∏ ÏúàÎèÑÏö∞ Ï†ïÎ≥¥ Îß§Ìïë
            if i < len(df):
                start_index = df.iloc[i].get('start_index', i)
            else:
                start_index = i
            
            results.append({
                'window_idx': i,
                'start_index': start_index,
                'reconstruction_error': float(error),
                'is_anomaly': bool(is_anomaly),
                'threshold': float(threshold)
            })
        
        results_df = pd.DataFrame(results)
        
        # ÌÜµÍ≥Ñ Ï∂úÎ†•
        anomaly_rate = results_df['is_anomaly'].mean()
        print(f"üìà Ïû¨Íµ¨ÏÑ± Ïò§Ï∞® ÏûÑÍ≥ÑÍ∞í: {threshold:.4f} ({threshold_percentile}%)")
        print(f"üö® Ïù¥ÏÉÅ ÌÉêÏßÄÏú®: {anomaly_rate:.3f} ({results_df['is_anomaly'].sum()}/{len(results_df)})")
        
        return results_df


def train_mscred(window_counts_path: str | Path, model_output_path: str | Path, 
                epochs: int = 50) -> Dict:
    """MS-CRED Î™®Îç∏ ÌïôÏäµ Ìï®Ïàò"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"üîß ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: {device}")
    
    model = MSCREDModel()
    trainer = MSCREDTrainer(model, device)
    
    # ÌïôÏäµ Ïã§Ìñâ
    training_stats = trainer.train(window_counts_path, epochs)
    
    # Î™®Îç∏ Ï†ÄÏû•
    trainer.save_model(model_output_path)
    
    return training_stats


def infer_mscred(window_counts_path: str | Path, model_path: str | Path, 
                output_path: str | Path, threshold_percentile: float = 95.0) -> pd.DataFrame:
    """MS-CRED Ïù¥ÏÉÅ ÌÉêÏßÄ Ï∂îÎ°† Ìï®Ïàò"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"üîß ÏÇ¨Ïö© ÎîîÎ∞îÏù¥Ïä§: {device}")
    
    # Ï∂îÎ°† Ïã§Ìñâ
    inference = MSCREDInference(model_path, device)
    results_df = inference.detect_anomalies(window_counts_path, threshold_percentile)
    
    # Í≤∞Í≥º Ï†ÄÏû•
    results_df.to_parquet(output_path, index=False)
    print(f"‚úÖ MS-CRED Ï∂îÎ°† Í≤∞Í≥º Ï†ÄÏû•: {output_path}")
    
    return results_df
