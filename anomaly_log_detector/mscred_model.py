"""  # ëª¨ë“ˆ ì „ì²´ ì„¤ëª… ì‹œì‘
MS-CRED (Multi-Scale Convolutional Recurrent Encoder-Decoder) ëª¨ë¸ êµ¬í˜„  # MS-CRED ëª¨ë¸ êµ¬í˜„ì„ ì„¤ëª…

MS-CREDëŠ” ì‹œê³„ì—´ ì´ìƒíƒì§€ë¥¼ ìœ„í•œ ë©€í‹°ìŠ¤ì¼€ì¼ ì»¨ë³¼ë£¨ì…˜ ì˜¤í† ì¸ì½”ë”ì…ë‹ˆë‹¤.  # ëª¨ë¸ ê°œìš”
ë¡œê·¸ í…œí”Œë¦¿ ì¹´ìš´íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì¬êµ¬ì„± ì˜¤ì°¨ë¥¼ í†µí•´ ì´ìƒì„ íƒì§€í•©ë‹ˆë‹¤.  # ì…ë ¥ê³¼ ëª©ì 
"""  # ëª¨ë“ˆ ì„¤ëª… ë

from __future__ import annotations  # ìˆœí™˜ ì°¸ì¡° ë“± íƒ€ì… íŒíŠ¸ë¥¼ ë¬¸ìì—´ ì—†ì´ ì‚¬ìš©í•˜ê¸° ìœ„í•¨

import torch  # PyTorch ê¸°ë³¸ ëª¨ë“ˆ
import torch.nn as nn  # ì‹ ê²½ë§ ë ˆì´ì–´ ì •ì˜ìš©
import torch.nn.functional as F  # í•¨ìˆ˜í˜• API (ì†ì‹¤, í™œì„±í•¨ìˆ˜ ë“±)
from pathlib import Path  # ê²½ë¡œ ì²˜ë¦¬ë¥¼ ìœ„í•œ Path í´ë˜ìŠ¤
import pandas as pd  # ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬ìš©
import numpy as np  # ìˆ˜ì¹˜ ì—°ì‚° ë¼ì´ë¸ŒëŸ¬ë¦¬
from typing import Tuple, List, Dict, Optional  # íƒ€ì… íŒíŠ¸ìš©
import json  # JSON ì…ì¶œë ¥ (í˜„ì¬ ì‚¬ìš©ì€ ì—†ì§€ë§Œ ìœ ì§€)
from tqdm import tqdm  # ì§„í–‰ë¥  í‘œì‹œ ë°”


class MultiScaleConvBlock(nn.Module):  # ë©€í‹°ìŠ¤ì¼€ì¼ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡ ì •ì˜
    """ë©€í‹°ìŠ¤ì¼€ì¼ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡"""  # í´ë˜ìŠ¤ ì„¤ëª…
    
    def __init__(self, in_channels: int, out_channels: int, kernel_sizes: List[int] = [3, 5, 7]):  # ìƒì„±ì
        super().__init__()  # ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        self.kernel_sizes = kernel_sizes  # ì‚¬ìš©í•  ì»¤ë„ í¬ê¸° ë¦¬ìŠ¤íŠ¸ ì €ì¥
        
        # ê° ì»¤ë„ì˜ ì±„ë„ ìˆ˜ë¥¼ ê· ë“±í•˜ê²Œ ë¶„ë°°í•˜ë˜ ë‚˜ë¨¸ì§€ëŠ” ì²« ë²ˆì§¸ ì»¤ë„ì— í• ë‹¹  # ì±„ë„ ë¶„ë°° ë¡œì§
        channels_per_kernel = out_channels // len(kernel_sizes)  # ì»¤ë„ë‹¹ ê¸°ë³¸ ì±„ë„ ìˆ˜
        remainder = out_channels % len(kernel_sizes)  # ë¶„ë°° í›„ ë‚¨ëŠ” ì±„ë„ ìˆ˜
        
        # ê° ì»¤ë„ í¬ê¸°ë³„ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´  # ë³‘ë ¬ ë‹¤ì¤‘ ì»¤ë„
        self.convs = nn.ModuleList()  # ë™ì  ë ˆì´ì–´ ë¦¬ìŠ¤íŠ¸
        for i, k in enumerate(kernel_sizes):  # ê° ì»¤ë„ í¬ê¸°ì— ëŒ€í•´ ë°˜ë³µ
            # ì²« ë²ˆì§¸ ì»¤ë„ì— ë‚˜ë¨¸ì§€ ì±„ë„ ì¶”ê°€  # ì±„ë„ ê· í˜• ìœ ì§€
            current_channels = channels_per_kernel + (remainder if i == 0 else 0)  # í˜„ì¬ ì»¤ë„ì˜ ì¶œë ¥ ì±„ë„ ìˆ˜
            self.convs.append(
                nn.Conv2d(in_channels, current_channels, kernel_size=k, padding=k//2)  # ê°™ì€ í¬ê¸° ìœ ì§€ íŒ¨ë”©
            )  # ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ ì¶”ê°€
        
        self.bn = nn.BatchNorm2d(out_channels)  # ë°°ì¹˜ ì •ê·œí™”ë¡œ ì•ˆì •í™”
        self.relu = nn.ReLU(inplace=True)  # ReLU í™œì„±í•¨ìˆ˜ (inplaceë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:  # ìˆœì „íŒŒ ì •ì˜
        # ê° ì»¤ë„ í¬ê¸°ë³„ë¡œ ì»¨ë³¼ë£¨ì…˜ ì ìš© í›„ ì±„ë„ ì°¨ì›ì—ì„œ ê²°í•©  # ë©€í‹°ìŠ¤ì¼€ì¼ íŠ¹ì§• ê²°í•©
        conv_outputs = [conv(x) for conv in self.convs]  # ê° ì»¨ë³¼ë£¨ì…˜ì˜ ì¶œë ¥ ë¦¬ìŠ¤íŠ¸
        out = torch.cat(conv_outputs, dim=1)  # ì±„ë„ ë°©í–¥ìœ¼ë¡œ í•©ì¹˜ê¸°
        out = self.bn(out)  # ë°°ì¹˜ ì •ê·œí™” ì ìš©
        out = self.relu(out)  # ReLU í™œì„±í™”
        return out  # ì¶œë ¥ ë°˜í™˜


class AttentionModule(nn.Module):  # ì–´í…ì…˜ ëª¨ë“ˆ ì •ì˜
    """ì–´í…ì…˜ ëª¨ë“ˆ"""  # í´ë˜ìŠ¤ ì„¤ëª…
    
    def __init__(self, channels: int):  # ìƒì„±ì
        super().__init__()  # ë¶€ëª¨ ì´ˆê¸°í™”
        self.conv_att = nn.Conv2d(channels, 1, kernel_size=1)  # ì±„ë„ ì¶•ì†Œë¥¼ í†µí•œ ì£¼ì˜ ê°€ì¤‘ì¹˜ ìƒì„±
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:  # ìˆœì „íŒŒ
        # ì±„ë„ë³„ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°  # ì¤‘ìš” ì˜ì—­ ê°•ì¡°
        att_weights = torch.sigmoid(self.conv_att(x))  # 0~1 ë²”ìœ„ì˜ ê°€ì¤‘ì¹˜
        return x * att_weights  # ì…ë ¥ì— ê°€ì¤‘ì¹˜ ì ìš©


class MSCREDEncoder(nn.Module):  # ì¸ì½”ë” ë¶€ë¶„ ì •ì˜
    """MS-CRED ì¸ì½”ë”"""  # í´ë˜ìŠ¤ ì„¤ëª…
    
    def __init__(self, input_channels: int = 1, base_channels: int = 32):  # ìƒì„±ì
        super().__init__()  # ë¶€ëª¨ ì´ˆê¸°í™”
        
        # ë©€í‹°ìŠ¤ì¼€ì¼ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë“¤  # ì ì°¨ ì±„ë„ ìˆ˜ ì¦ê°€
        self.conv1 = MultiScaleConvBlock(input_channels, base_channels)  # 1ë‹¨ê³„ íŠ¹ì§• ì¶”ì¶œ
        self.conv2 = MultiScaleConvBlock(base_channels, base_channels * 2)  # 2ë‹¨ê³„ íŠ¹ì§• ì¶”ì¶œ
        self.conv3 = MultiScaleConvBlock(base_channels * 2, base_channels * 4)  # 3ë‹¨ê³„ íŠ¹ì§• ì¶”ì¶œ
        
        # ì–´í…ì…˜ ëª¨ë“ˆë“¤  # ê° ìŠ¤ì¼€ì¼ ì¶œë ¥ì— ì£¼ì˜ ë©”ì»¤ë‹ˆì¦˜ ì ìš©
        self.att1 = AttentionModule(base_channels)  # 1ë‹¨ê³„ ì–´í…ì…˜
        self.att2 = AttentionModule(base_channels * 2)  # 2ë‹¨ê³„ ì–´í…ì…˜
        self.att3 = AttentionModule(base_channels * 4)  # 3ë‹¨ê³„ ì–´í…ì…˜
        
        # ë‹¤ìš´ìƒ˜í”Œë§  # ê³µê°„ í¬ê¸°ë¥¼ ì ˆë°˜ìœ¼ë¡œ ì¤„ì„
        self.pool = nn.MaxPool2d(2, 2)  # ì»¤ë„ 2, ìŠ¤íŠ¸ë¼ì´ë“œ 2
        
    def forward(self, x: torch.Tensor) -> List[torch.Tensor]:  # ìˆœì „íŒŒ, ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§• ë°˜í™˜
        # x: (batch, 1, height, width) - height: time_steps, width: num_templates  # ì…ë ¥ í˜•íƒœ ì„¤ëª…
        
        # ì²« ë²ˆì§¸ ìŠ¤ì¼€ì¼  # ì´ˆê¸° íŠ¹ì§• ì¶”ì¶œê³¼ ì–´í…ì…˜
        x1 = self.conv1(x)  # conv1 í†µê³¼
        x1_att = self.att1(x1)  # ì–´í…ì…˜ ì ìš©
        
        # ë‘ ë²ˆì§¸ ìŠ¤ì¼€ì¼  # ë‹¤ìš´ìƒ˜í”Œë§ í›„ 2ë‹¨ê³„ íŠ¹ì§•
        x2 = self.pool(x1_att)  # ë§¥ìŠ¤í’€ë§
        x2 = self.conv2(x2)  # conv2 í†µê³¼
        x2_att = self.att2(x2)  # ì–´í…ì…˜ ì ìš©
        
        # ì„¸ ë²ˆì§¸ ìŠ¤ì¼€ì¼  # ì¬ë‹¤ìš´ìƒ˜í”Œë§ í›„ 3ë‹¨ê³„ íŠ¹ì§•
        x3 = self.pool(x2_att)  # ë§¥ìŠ¤í’€ë§
        x3 = self.conv3(x3)  # conv3 í†µê³¼
        x3_att = self.att3(x3)  # ì–´í…ì…˜ ì ìš©
        
        return [x1_att, x2_att, x3_att]  # ê° ìŠ¤ì¼€ì¼ì˜ ì–´í…ì…˜ ê²°ê³¼ ë°˜í™˜


class MSCREDDecoder(nn.Module):  # ë””ì½”ë” ì •ì˜
    """MS-CRED ë””ì½”ë” (ê°„ì†Œí™” ë²„ì „)"""  # í´ë˜ìŠ¤ ì„¤ëª…
    
    def __init__(self, base_channels: int = 32, output_channels: int = 1):  # ìƒì„±ì
        super().__init__()  # ë¶€ëª¨ ì´ˆê¸°í™”
        
        # ê°„ë‹¨í•œ ì—…ìƒ˜í”Œë§ ë””ì½”ë”  # ConvTranspose2dë¡œ í•´ìƒë„ ë³µì›
        self.deconv3 = nn.ConvTranspose2d(base_channels * 4, base_channels * 2, 
                                         kernel_size=4, stride=2, padding=1)  # 3->2 ë‹¨ê³„ ì—…ìƒ˜í”Œë§
        self.deconv2 = nn.ConvTranspose2d(base_channels * 2, base_channels, 
                                         kernel_size=4, stride=2, padding=1)  # 2->1 ë‹¨ê³„ ì—…ìƒ˜í”Œë§
        self.deconv1 = nn.Conv2d(base_channels, output_channels, kernel_size=3, padding=1)  # ìµœì¢… ì±„ë„ íˆ¬ì˜
        
        self.relu = nn.ReLU(inplace=True)  # í™œì„±í•¨ìˆ˜
        
    def forward(self, encoder_outputs: List[torch.Tensor]) -> torch.Tensor:  # ìˆœì „íŒŒ
        # ê°€ì¥ ì‘ì€ í”¼ì²˜ë§µ(ê°€ì¥ ê¹Šì€ ì¸ì½”ë”©)ë§Œ ì‚¬ìš©  # ê°„ì†Œí™”ëœ skip ì—°ê²° ì—†ìŒ
        _, _, x3_att = encoder_outputs  # ì„¸ ë²ˆì§¸ ìŠ¤ì¼€ì¼ë§Œ ì‚¬ìš©
        
        # ì—…ìƒ˜í”Œë§ìœ¼ë¡œ ì›ë˜ í¬ê¸°ë¡œ ë³µì›  # ë‹¨ê³„ì  ë³µì›
        x = self.relu(self.deconv3(x3_att))  # ì²« ì—…ìƒ˜í”Œë§
        x = self.relu(self.deconv2(x))  # ë‘ ë²ˆì§¸ ì—…ìƒ˜í”Œë§
        x = self.deconv1(x)  # ìµœì¢… ì¶œë ¥ ì±„ë„ë¡œ íˆ¬ì˜
        
        return x  # ì¬êµ¬ì„± ê²°ê³¼ ë°˜í™˜


class MSCREDModel(nn.Module):  # ì¸ì½”ë”-ë””ì½”ë” ê²°í•© ëª¨ë¸
    """MS-CRED ì „ì²´ ëª¨ë¸"""  # í´ë˜ìŠ¤ ì„¤ëª…
    
    def __init__(self, input_channels: int = 1, base_channels: int = 32):  # ìƒì„±ì
        super().__init__()  # ë¶€ëª¨ ì´ˆê¸°í™”
        self.encoder = MSCREDEncoder(input_channels, base_channels)  # ì¸ì½”ë” ìƒì„±
        self.decoder = MSCREDDecoder(base_channels, input_channels)  # ë””ì½”ë” ìƒì„±
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:  # ìˆœì „íŒŒ ì •ì˜
        # ì…ë ¥ í¬ê¸° ì €ì¥  # ONNX í˜¸í™˜ ë³´ì •ìš©
        input_shape = x.shape  # ë°°ì¹˜, ì±„ë„, ë†’ì´, ë„ˆë¹„

        encoded = self.encoder(x)  # ì¸ì½”ë” í†µê³¼í•˜ì—¬ ë©€í‹°ìŠ¤ì¼€ì¼ íŠ¹ì§• ì¶”ì¶œ
        reconstructed = self.decoder(encoded)  # ë””ì½”ë”ë¡œ ì¬êµ¬ì„± ìˆ˜í–‰

        # ì¶œë ¥ í¬ê¸°ë¥¼ ì…ë ¥ í¬ê¸°ì™€ ì •í™•íˆ ë§ì¶¤  # í›„ì²˜ë¦¬ í¬ê¸° ë³´ì •
        # ONNX ì¶”ì  í˜¸í™˜ì„±: shape ë¹„êµ ëŒ€ì‹  í•­ìƒ interpolate ìˆ˜í–‰  # ì•ˆì •ì  ì¶”ì 
        # (ì…ë ¥ê³¼ ì¶œë ¥ì´ ê°™ìœ¼ë©´ interpolateëŠ” no-op)  # ë™ì¼ í¬ê¸° ì‹œ ì˜í–¥ ì—†ìŒ
        reconstructed = F.interpolate(
            reconstructed,  # ë³´ì • ëŒ€ìƒ í…ì„œ
            size=(input_shape[2], input_shape[3]),  # ë†’ì´, ë„ˆë¹„ë¥¼ ì…ë ¥ê³¼ ë™ì¼í•˜ê²Œ
            mode='bilinear',  # ì–‘ì„ í˜• ë³´ê°„
            align_corners=False  # ì¢Œí‘œ ì •ë ¬ ë¹„í™œì„±í™”ë¡œ ì¼ë°˜ì  ì„¤ì •
        )  # ë³´ê°„ ê²°ê³¼

        return reconstructed  # ìµœì¢… ì¬êµ¬ì„± ê²°ê³¼ ë°˜í™˜
    
    def compute_reconstruction_error(self, x: torch.Tensor, reconstructed: torch.Tensor) -> torch.Tensor:  # ì˜¤ì°¨ ê³„ì‚° í•¨ìˆ˜
        """ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°"""  # í•¨ìˆ˜ ì„¤ëª…
        return F.mse_loss(reconstructed, x, reduction='none').mean(dim=[1, 2, 3])  # ë°°ì¹˜ë³„ í‰ê·  MSE ë°˜í™˜


class MSCREDTrainer:  # í•™ìŠµ ê´€ë¦¬ í´ë˜ìŠ¤
    """MS-CRED ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ"""  # í´ë˜ìŠ¤ ì„¤ëª…
    
    def __init__(self, model: MSCREDModel, device: str = 'cpu'):  # ìƒì„±ì
        self.model = model.to(device)  # ëª¨ë¸ ë””ë°”ì´ìŠ¤ ì´ë™
        self.device = device  # ë””ë°”ì´ìŠ¤ ì €ì¥
        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  # Adam ì˜µí‹°ë§ˆì´ì €
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5, patience=5
        )  # ê²€ì¦ ì†ì‹¤ ê°ì†Œ ì •ì²´ ì‹œ í•™ìŠµë¥  ê°ì†Œ
        
    def prepare_data(self, window_counts_df: pd.DataFrame, target_num_templates: Optional[int] = None) -> Tuple[torch.Tensor, int]:  # ë°ì´í„° ì¤€ë¹„
        """ìœˆë„ìš° ì¹´ìš´íŠ¸ ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜

        Args:
            window_counts_df: ìœˆë„ìš° ì¹´ìš´íŠ¸ ë°ì´í„°í”„ë ˆì„  # ì…ë ¥ ë°ì´í„°í”„ë ˆì„
            target_num_templates: ëª©í‘œ í…œí”Œë¦¿ ê°œìˆ˜ (ì¶”ë¡  ì‹œ í•™ìŠµ ëª¨ë¸ê³¼ ë§ì¶”ê¸° ìœ„í•´)  # í…œí”Œë¦¿ ì •í•© ì˜µì…˜

        Returns:
            (í…ì„œ ë°ì´í„°, ì‹¤ì œ í…œí”Œë¦¿ ê°œìˆ˜)  # í…ì„œì™€ í…œí”Œë¦¿ ìˆ˜ ë°˜í™˜
        """  # ì„¤ëª… ë
        # start_index ì»¬ëŸ¼ ì œê±°í•˜ê³  í…œí”Œë¦¿ ì¹´ìš´íŠ¸ë§Œ ì¶”ì¶œ  # íŠ¹ì§•ë§Œ ì„ íƒ
        template_cols = [col for col in window_counts_df.columns if col.startswith('t')]  # í…œí”Œë¦¿ ì»¬ëŸ¼ ëª©ë¡
        data = window_counts_df[template_cols].fillna(0).values  # NaNì„ 0ìœ¼ë¡œ ì±„ìš°ê³  ë°°ì—´í™”
        actual_num_templates = data.shape[1]  # ì‹¤ì œ í…œí”Œë¦¿ ê°œìˆ˜

        # ëª©í‘œ í…œí”Œë¦¿ ê°œìˆ˜ê°€ ì§€ì •ëœ ê²½ìš° í¬ê¸° ì¡°ì •  # ì¶”ë¡ /í•™ìŠµ ì •í•©ì„± ìœ ì§€
        if target_num_templates is not None and actual_num_templates != target_num_templates:  # ì •í•© í•„ìš” ì—¬ë¶€ í™•ì¸
            if actual_num_templates < target_num_templates:  # ë¶€ì¡±í•˜ë©´ íŒ¨ë”©
                # íŒ¨ë”©: ë¶€ì¡±í•œ í…œí”Œë¦¿ì€ 0ìœ¼ë¡œ ì±„ì›€  # ì°¨ì› í™•ì¥
                padding = np.zeros((data.shape[0], target_num_templates - actual_num_templates))  # 0 íŒ¨ë”© ìƒì„±
                data = np.hstack([data, padding])  # ìš°ì¸¡ì— ë¶™ì—¬ í™•ì¥
                print(f"ğŸ“Š í…œí”Œë¦¿ ê°œìˆ˜ íŒ¨ë”©: {actual_num_templates} â†’ {target_num_templates}")  # ë¡œê·¸ ì¶œë ¥
            else:  # ì´ˆê³¼í•˜ë©´ ì ˆë‹¨
                # Truncate: ì´ˆê³¼ í…œí”Œë¦¿ì€ ì˜ë¼ëƒ„  # ì°¨ì› ì¶•ì†Œ
                data = data[:, :target_num_templates]  # ì¢Œì¸¡ë¶€í„° targetê¹Œì§€ ìœ ì§€
                print(f"ğŸ“Š í…œí”Œë¦¿ ê°œìˆ˜ ì¶•ì†Œ: {actual_num_templates} â†’ {target_num_templates}")  # ë¡œê·¸ ì¶œë ¥
            actual_num_templates = target_num_templates  # ì‹¤ì œ ê°œìˆ˜ ê°±ì‹ 

        # ì •ê·œí™”  # ì»¬ëŸ¼ë³„ í‰ê· 0, í‘œì¤€í¸ì°¨1ë¡œ ìŠ¤ì¼€ì¼ë§
        data = (data - data.mean(axis=0)) / (data.std(axis=0) + 1e-8)  # ìˆ˜ì¹˜ ì•ˆì •ì„± ìœ„í•´ epsilon ì¶”ê°€

        # 2D ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³€í™˜ (time_steps, num_templates)  # CNN ì…ë ¥ìœ¼ë¡œ ë³€í˜•
        # ì‹œí€€ìŠ¤ ê¸¸ì´ ì„¤ì • (ì˜ˆ: 20ê°œ ìœˆë„ìš°ì”©)  # ê³ ì • ê¸¸ì´ ì‹œí€€ìŠ¤ êµ¬ì„±
        seq_len = 20  # ì‹œí€€ìŠ¤ ê¸¸ì´
        sequences = []  # ì‹œí€€ìŠ¤ ëˆ„ì  ë¦¬ìŠ¤íŠ¸

        for i in range(len(data) - seq_len + 1):  # ê°€ëŠ¥í•œ ì‹œì‘ ìœ„ì¹˜ ìˆœíšŒ
            seq = data[i:i+seq_len]  # (seq_len, num_templates)  # ìœˆë„ìš° ìŠ¬ë¼ì´ìŠ¤
            sequences.append(seq)  # ì‹œí€€ìŠ¤ ì¶”ê°€

        if not sequences:  # ì‹œí€€ìŠ¤ê°€ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°
            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° íŒ¨ë”©  # ìƒí•˜ë‹¨ 0 íŒ¨ë”©ìœ¼ë¡œ ê¸¸ì´ ë§ì¶¤
            padded_data = np.pad(data, ((0, seq_len - len(data)), (0, 0)), mode='constant')  # íŒ¨ë”© ì ìš©
            sequences = [padded_data]  # ë‹¨ì¼ ì‹œí€€ìŠ¤ë¡œ êµ¬ì„±

        # (batch, 1, time_steps, num_templates) í˜•íƒœë¡œ ë³€í™˜  # ì±„ë„ ì°¨ì› ì¶”ê°€
        sequences = np.array(sequences)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì—´ë¡œ ë³€í™˜
        return torch.FloatTensor(sequences).unsqueeze(1), actual_num_templates  # í…ì„œì™€ í…œí”Œë¦¿ ìˆ˜ ë°˜í™˜
    
    def train(self, window_counts_path: str | Path, epochs: int = 50,
              validation_split: float = 0.2) -> Dict:  # ëª¨ë¸ í•™ìŠµ ë£¨í‹´
        """ëª¨ë¸ í•™ìŠµ"""  # í•¨ìˆ˜ ì„¤ëª…

        # ë°ì´í„° ë¡œë“œ  # ì…ë ¥ íŒŒì¼ì—ì„œ íŒŒì¼€ ë¡œë“œ
        df = pd.read_parquet(window_counts_path)  # DataFrame ë¡œë“œ
        data_tensor, num_templates = self.prepare_data(df)  # í…ì„œ ë³€í™˜ ë° í…œí”Œë¦¿ ìˆ˜ íšë“
        data_tensor = data_tensor.to(self.device)  # ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        
        # í•™ìŠµ/ê²€ì¦ ë¶„í•   # í™€ë“œì•„ì›ƒ ê²€ì¦
        n_train = int(len(data_tensor) * (1 - validation_split))  # í•™ìŠµ ë°ì´í„° í¬ê¸°
        train_data = data_tensor[:n_train]  # í•™ìŠµ ë¶€ë¶„
        val_data = data_tensor[n_train:]  # ê²€ì¦ ë¶€ë¶„
        
        print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_data)}, ê²€ì¦ ë°ì´í„°: {len(val_data)}")  # ë°ì´í„° ìˆ˜ ì¶œë ¥
        print(f"ğŸ“ ë°ì´í„° í˜•íƒœ: {data_tensor.shape}")  # í…ì„œ í˜•íƒœ ì¶œë ¥
        
        train_losses = []  # ì—í­ë³„ í•™ìŠµ ì†ì‹¤ ê¸°ë¡
        val_losses = []  # ì—í­ë³„ ê²€ì¦ ì†ì‹¤ ê¸°ë¡

        self.model.train()  # í•™ìŠµ ëª¨ë“œ ì„¤ì •

        for epoch in tqdm(range(epochs), desc="MS-CRED í•™ìŠµ"):  # ì—í­ ë°˜ë³µ
            # í•™ìŠµ  # ë°°ì¹˜ ë°˜ë³µìœ¼ë¡œ ìµœì í™”
            epoch_train_loss = 0  # ì—í­ í•™ìŠµ ì†ì‹¤ ëˆ„ì 
            for i in range(0, len(train_data), 32):  # ë°°ì¹˜ í¬ê¸° 32  # ë¯¸ë‹ˆë°°ì¹˜ í•™ìŠµ
                batch = train_data[i:i+32]  # ë°°ì¹˜ ìŠ¬ë¼ì´ìŠ¤

                self.optimizer.zero_grad()  # ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
                reconstructed = self.model(batch)  # ìˆœì „íŒŒ
                loss = F.mse_loss(reconstructed, batch)  # ì¬êµ¬ì„± ì†ì‹¤(MSE)
                loss.backward()  # ì—­ì „íŒŒ
                self.optimizer.step()  # íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

                epoch_train_loss += loss.item()  # ì†ì‹¤ ëˆ„ì 

            # ê²€ì¦  # í‰ê°€ ëª¨ë“œì—ì„œ ì†ì‹¤ ì¸¡ì •
            self.model.eval()  # í‰ê°€ ëª¨ë“œ ì„¤ì •
            epoch_val_loss = 0  # ì—í­ ê²€ì¦ ì†ì‹¤ ëˆ„ì 
            with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™”
                for i in range(0, len(val_data), 32):  # ë°°ì¹˜ ë°˜ë³µ
                    batch = val_data[i:i+32]  # ë°°ì¹˜ ìŠ¬ë¼ì´ìŠ¤
                    reconstructed = self.model(batch)  # ìˆœì „íŒŒ
                    loss = F.mse_loss(reconstructed, batch)  # ì†ì‹¤ ê³„ì‚°
                    epoch_val_loss += loss.item()  # ëˆ„ì 

            self.model.train()  # ë‹¤ì‹œ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜

            avg_train_loss = epoch_train_loss / (len(train_data) // 32 + 1)  # í‰ê·  í•™ìŠµ ì†ì‹¤
            avg_val_loss = epoch_val_loss / (len(val_data) // 32 + 1) if len(val_data) > 0 else 0  # í‰ê·  ê²€ì¦ ì†ì‹¤

            train_losses.append(avg_train_loss)  # ê¸°ë¡ ì¶”ê°€
            val_losses.append(avg_val_loss)  # ê¸°ë¡ ì¶”ê°€

            self.scheduler.step(avg_val_loss)  # Plateau ìŠ¤ì¼€ì¤„ëŸ¬ ê°±ì‹ 

            if epoch % 10 == 0:  # 10ì—í­ë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
                print(f"Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}")  # ì§„í–‰ ë¡œê·¸

        # í•™ìŠµ ì™„ë£Œ í›„ ê²€ì¦ ë°ì´í„°ì˜ ì¬êµ¬ì„± ì˜¤ì°¨ ìˆ˜ì§‘ (ì„ê³„ê°’ ê³„ì‚°ìš©)
        print("\nğŸ“Š ì„ê³„ê°’ ê³„ì‚°ì„ ìœ„í•œ ê²€ì¦ ë°ì´í„° ì¬êµ¬ì„± ì˜¤ì°¨ ìˆ˜ì§‘ ì¤‘...")
        self.model.eval()  # í‰ê°€ ëª¨ë“œ
        val_reconstruction_errors = []  # ê²€ì¦ ë°ì´í„° ì¬êµ¬ì„± ì˜¤ì°¨ ë¦¬ìŠ¤íŠ¸

        with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™”
            for i in range(0, len(val_data), 32):  # ë°°ì¹˜ ë°˜ë³µ
                batch = val_data[i:i+32]  # ë°°ì¹˜ ìŠ¬ë¼ì´ìŠ¤
                reconstructed = self.model(batch)  # ì¬êµ¬ì„±
                errors = self.model.compute_reconstruction_error(batch, reconstructed)  # ìƒ˜í”Œë³„ ì¬êµ¬ì„± ì˜¤ì°¨
                val_reconstruction_errors.extend(errors.cpu().numpy())  # CPUë¡œ ì´ë™ í›„ ì¶”ê°€

        # ì„ê³„ê°’ ê³„ì‚° (ì •ìƒ ë°ì´í„° ë¶„í¬ ê¸°ë°˜)
        val_errors_array = np.array(val_reconstruction_errors)
        threshold_stats = {
            # ë°±ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì„ê³„ê°’
            'threshold_95': float(np.percentile(val_errors_array, 95.0)),
            'threshold_99': float(np.percentile(val_errors_array, 99.0)),
            'threshold_99_9': float(np.percentile(val_errors_array, 99.9)),
            # í†µê³„ì  ë°©ë²• (3-sigma)
            'mean': float(np.mean(val_errors_array)),
            'std': float(np.std(val_errors_array)),
            'threshold_3sigma': float(np.mean(val_errors_array) + 3 * np.std(val_errors_array)),
            # ì¤‘ì•™ê°’ ê¸°ë°˜ (MAD - Median Absolute Deviation)
            'median': float(np.median(val_errors_array)),
            'mad': float(np.median(np.abs(val_errors_array - np.median(val_errors_array)))),
            'threshold_mad': float(np.median(val_errors_array) + 3 * 1.4826 * np.median(np.abs(val_errors_array - np.median(val_errors_array)))),
        }

        print(f"âœ… ì„ê³„ê°’ ê³„ì‚° ì™„ë£Œ:")
        print(f"   - 95 ë°±ë¶„ìœ„ìˆ˜: {threshold_stats['threshold_95']:.4f}")
        print(f"   - 99 ë°±ë¶„ìœ„ìˆ˜: {threshold_stats['threshold_99']:.4f} (ê¶Œì¥)")
        print(f"   - 99.9 ë°±ë¶„ìœ„ìˆ˜: {threshold_stats['threshold_99_9']:.4f}")
        print(f"   - 3-sigma: {threshold_stats['threshold_3sigma']:.4f}")
        print(f"   - MAD (3*1.4826): {threshold_stats['threshold_mad']:.4f}")

        return {
            'train_losses': train_losses,  # í•™ìŠµ ì†ì‹¤ ëª©ë¡
            'val_losses': val_losses,  # ê²€ì¦ ì†ì‹¤ ëª©ë¡
            'final_train_loss': train_losses[-1],  # ìµœì¢… í•™ìŠµ ì†ì‹¤
            'final_val_loss': val_losses[-1],  # ìµœì¢… ê²€ì¦ ì†ì‹¤
            'num_templates': num_templates,  # ì‚¬ìš©ëœ í…œí”Œë¦¿ ê°œìˆ˜
            'threshold_stats': threshold_stats,  # ì„ê³„ê°’ í†µê³„ ì¶”ê°€
            'val_reconstruction_errors': val_reconstruction_errors,  # ê²€ì¦ ì˜¤ì°¨ ëª©ë¡ (ì„ íƒì  ë¶„ì„ìš©)
        }  # í†µê³„ ë°˜í™˜
    
    def save_model(self, path: str | Path, num_templates: int, threshold_stats: Optional[Dict] = None):  # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        """ëª¨ë¸ ì €ì¥ (í…œí”Œë¦¿ ê°œìˆ˜ ë° ì„ê³„ê°’ ë©”íƒ€ë°ì´í„° í¬í•¨)"""  # í•¨ìˆ˜ ì„¤ëª…
        checkpoint = {
            'model_state_dict': self.model.state_dict(),  # ëª¨ë¸ ê°€ì¤‘ì¹˜
            'optimizer_state_dict': self.optimizer.state_dict(),  # ì˜µí‹°ë§ˆì´ì € ìƒíƒœ
            'num_templates': num_templates,  # í•™ìŠµ ì‹œ í…œí”Œë¦¿ ê°œìˆ˜ ì €ì¥
        }

        # ì„ê³„ê°’ í†µê³„ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if threshold_stats is not None:
            checkpoint['threshold_stats'] = threshold_stats

        torch.save(checkpoint, path)  # íŒŒì¼ë¡œ ì €ì¥
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")  # ì €ì¥ ë¡œê·¸
        print(f"ğŸ“Š ì €ì¥ëœ í…œí”Œë¦¿ ê°œìˆ˜: {num_templates}")  # ë©”íƒ€ë°ì´í„° ë¡œê·¸

        if threshold_stats is not None:
            print(f"ğŸ“Š ì €ì¥ëœ ì„ê³„ê°’ ì •ë³´:")
            print(f"   - 99 ë°±ë¶„ìœ„ìˆ˜ (ê¶Œì¥): {threshold_stats['threshold_99']:.4f}")
            print(f"   - 3-sigma: {threshold_stats['threshold_3sigma']:.4f}")
    
    def load_model(self, path: str | Path):  # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        """ëª¨ë¸ ë¡œë“œ"""  # í•¨ìˆ˜ ì„¤ëª…
        checkpoint = torch.load(path, map_location=self.device)  # ë””ë°”ì´ìŠ¤ì— ë§ê²Œ ë¡œë“œ
        self.model.load_state_dict(checkpoint['model_state_dict'])  # ê°€ì¤‘ì¹˜ ë³µì›
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])  # ì˜µí‹°ë§ˆì´ì € ìƒíƒœ ë³µì›
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")  # ì™„ë£Œ ë¡œê·¸


class MSCREDInference:  # ì¶”ë¡  ì „ìš© í´ë˜ìŠ¤
    """MS-CRED ì¶”ë¡ """  # í´ë˜ìŠ¤ ì„¤ëª…

    def __init__(self, model_path: str | Path, device: str = 'cpu'):  # ìƒì„±ì
        self.device = device  # ë””ë°”ì´ìŠ¤ ì €ì¥
        self.model = MSCREDModel().to(device)  # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì´ë™

        # ëª¨ë¸ ë¡œë“œ  # ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê°€ì¤‘ì¹˜ ë³µì›
        checkpoint = torch.load(model_path, map_location=device)  # ë””ë°”ì´ìŠ¤ì— ë§ì¶° ë¡œë“œ
        self.model.load_state_dict(checkpoint['model_state_dict'])  # ê°€ì¤‘ì¹˜ ì„¤ì •
        self.model.eval()  # í‰ê°€ ëª¨ë“œë¡œ ì „í™˜

        # í•™ìŠµ ì‹œ ì‚¬ìš©ëœ í…œí”Œë¦¿ ê°œìˆ˜ ë¡œë“œ  # ì…ë ¥ ì°¨ì› ì •í•©ì„± í™•ì¸ìš©
        self.num_templates = checkpoint.get('num_templates', None)  # ì¡´ì¬ ì‹œ ì €ì¥
        if self.num_templates is not None:  # ë©”íƒ€ë°ì´í„°ê°€ ìˆì„ ê²½ìš°
            print(f"ğŸ“Š í•™ìŠµ ì‹œ í…œí”Œë¦¿ ê°œìˆ˜: {self.num_templates}")  # ì •ë³´ ì¶œë ¥
        else:  # ì—†ì„ ê²½ìš° ê²½ê³ 
            print("âš ï¸  ê²½ê³ : ëª¨ë¸ì— í…œí”Œë¦¿ ê°œìˆ˜ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì°¨ì› ë¶ˆì¼ì¹˜ ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")  # ê²½ê³  ì¶œë ¥

        # í•™ìŠµ ì‹œ ê³„ì‚°ëœ ì„ê³„ê°’ í†µê³„ ë¡œë“œ
        self.threshold_stats = checkpoint.get('threshold_stats', None)
        if self.threshold_stats is not None:
            print(f"ğŸ“Š í•™ìŠµ ì‹œ ê³„ì‚°ëœ ì„ê³„ê°’:")
            print(f"   - 95 ë°±ë¶„ìœ„ìˆ˜: {self.threshold_stats['threshold_95']:.4f}")
            print(f"   - 99 ë°±ë¶„ìœ„ìˆ˜: {self.threshold_stats['threshold_99']:.4f} (ê¶Œì¥)")
            print(f"   - 99.9 ë°±ë¶„ìœ„ìˆ˜: {self.threshold_stats['threshold_99_9']:.4f}")
            print(f"   - 3-sigma: {self.threshold_stats['threshold_3sigma']:.4f}")
        else:
            print("âš ï¸  ê²½ê³ : ëª¨ë¸ì— ì„ê³„ê°’ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ì¶”ë¡  ë°ì´í„° ê¸°ë°˜ ì„ê³„ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    def detect_anomalies(self, window_counts_path: str | Path,
                        threshold: Optional[float] = None,
                        threshold_method: str = '99percentile') -> pd.DataFrame:  # ì´ìƒ íƒì§€ ì‹¤í–‰
        """ì´ìƒ íƒì§€ ìˆ˜í–‰

        Args:
            window_counts_path: window_counts.parquet íŒŒì¼ ê²½ë¡œ
            threshold: ìˆ˜ë™ ì„ê³„ê°’ (ì§€ì • ì‹œ ì´ ê°’ ì‚¬ìš©, Noneì´ë©´ ìë™)
            threshold_method: ìë™ ì„ê³„ê°’ ë°©ë²•
                - '99percentile': í•™ìŠµ ì‹œ 99 ë°±ë¶„ìœ„ìˆ˜ (ê¶Œì¥, ê¸°ë³¸ê°’)
                - '95percentile': í•™ìŠµ ì‹œ 95 ë°±ë¶„ìœ„ìˆ˜
                - '99.9percentile': í•™ìŠµ ì‹œ 99.9 ë°±ë¶„ìœ„ìˆ˜
                - '3sigma': í•™ìŠµ ì‹œ í‰ê·  + 3*í‘œì¤€í¸ì°¨
                - 'mad': í•™ìŠµ ì‹œ ì¤‘ì•™ê°’ + 3*1.4826*MAD
                - 'inference_adaptive': ì¶”ë¡  ë°ì´í„° ê¸°ë°˜ 95 ë°±ë¶„ìœ„ìˆ˜ (êµ¬ ë°©ì‹, ê¶Œì¥ ì•ˆí•¨)

        Returns:
            ê²°ê³¼ DataFrame (window_idx, start_index, reconstruction_error, is_anomaly, threshold)
        """

        # ë°ì´í„° ì¤€ë¹„  # í•™ìŠµ ì‹œ í…œí”Œë¦¿ ìˆ˜ì— ë§ì¶° ë³€í™˜
        trainer = MSCREDTrainer(self.model, self.device)  # íŠ¸ë ˆì´ë„ˆ ìƒì„± (ë°ì´í„° ì¤€ë¹„ ì¬ì‚¬ìš©)
        df = pd.read_parquet(window_counts_path)  # ì…ë ¥ ë°ì´í„° ë¡œë“œ
        data_tensor, actual_num_templates = trainer.prepare_data(df, target_num_templates=self.num_templates)  # ì •í•© ë³€í™˜
        data_tensor = data_tensor.to(self.device)  # ë””ë°”ì´ìŠ¤ ì´ë™

        if self.num_templates is not None and actual_num_templates != self.num_templates:  # ì°¨ì´ ì¡´ì¬ ì‹œ
            print(f"âš ï¸  í…œí”Œë¦¿ ê°œìˆ˜ê°€ í•™ìŠµ ì‹œì™€ ë‹¤ë¦…ë‹ˆë‹¤. ìë™ìœ¼ë¡œ ì¡°ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")  # ê²½ê³  ì¶œë ¥

        print(f"ğŸ“Š ì¶”ë¡  ë°ì´í„° í˜•íƒœ: {data_tensor.shape}")  # ì…ë ¥ í…ì„œ í˜•íƒœ ë¡œê·¸

        # ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°  # ë°°ì¹˜ë³„ë¡œ ê³„ì‚°
        reconstruction_errors = []  # ì˜¤ì°¨ ëˆ„ì  ë¦¬ìŠ¤íŠ¸

        with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ë¹„í™œì„±í™” (ì¶”ë¡ )
            for i in range(0, len(data_tensor), 32):  # ë°°ì¹˜ ë°˜ë³µ
                batch = data_tensor[i:i+32]  # ë°°ì¹˜ ìŠ¬ë¼ì´ìŠ¤
                reconstructed = self.model(batch)  # ì¬êµ¬ì„± ìˆ˜í–‰
                errors = self.model.compute_reconstruction_error(batch, reconstructed)  # ì˜¤ì°¨ ê³„ì‚°
                reconstruction_errors.extend(errors.cpu().numpy())  # CPUë¡œ ì´ë™ í›„ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€

        errors_array = np.array(reconstruction_errors)  # ë¦¬ìŠ¤íŠ¸ë¥¼ ë°°ì—´ë¡œ ë³€í™˜

        # ì„ê³„ê°’ ê²°ì •
        if threshold is not None:
            # ì‚¬ìš©ì ì§€ì • ì„ê³„ê°’ ì‚¬ìš©
            final_threshold = threshold
            print(f"ğŸ“Œ ì‚¬ìš©ì ì§€ì • ì„ê³„ê°’ ì‚¬ìš©: {final_threshold:.4f}")
        elif self.threshold_stats is not None:
            # í•™ìŠµ ì‹œ ê³„ì‚°ëœ ì„ê³„ê°’ ì‚¬ìš© (ê¶Œì¥)
            if threshold_method == '99percentile':
                final_threshold = self.threshold_stats['threshold_99']
                print(f"âœ… í•™ìŠµ ì‹œ 99 ë°±ë¶„ìœ„ìˆ˜ ì„ê³„ê°’ ì‚¬ìš©: {final_threshold:.4f} (ê¶Œì¥)")
            elif threshold_method == '95percentile':
                final_threshold = self.threshold_stats['threshold_95']
                print(f"âœ… í•™ìŠµ ì‹œ 95 ë°±ë¶„ìœ„ìˆ˜ ì„ê³„ê°’ ì‚¬ìš©: {final_threshold:.4f}")
            elif threshold_method == '99.9percentile':
                final_threshold = self.threshold_stats['threshold_99_9']
                print(f"âœ… í•™ìŠµ ì‹œ 99.9 ë°±ë¶„ìœ„ìˆ˜ ì„ê³„ê°’ ì‚¬ìš©: {final_threshold:.4f}")
            elif threshold_method == '3sigma':
                final_threshold = self.threshold_stats['threshold_3sigma']
                print(f"âœ… í•™ìŠµ ì‹œ 3-sigma ì„ê³„ê°’ ì‚¬ìš©: {final_threshold:.4f}")
            elif threshold_method == 'mad':
                final_threshold = self.threshold_stats['threshold_mad']
                print(f"âœ… í•™ìŠµ ì‹œ MAD ì„ê³„ê°’ ì‚¬ìš©: {final_threshold:.4f}")
            elif threshold_method == 'inference_adaptive':
                final_threshold = np.percentile(errors_array, 95.0)
                print(f"âš ï¸  ì¶”ë¡  ë°ì´í„° ê¸°ë°˜ 95 ë°±ë¶„ìœ„ìˆ˜ ì‚¬ìš©: {final_threshold:.4f} (ê¶Œì¥í•˜ì§€ ì•ŠìŒ)")
            else:
                # ì˜ëª»ëœ ë°©ë²•ëª…, ê¸°ë³¸ê°’ ì‚¬ìš©
                final_threshold = self.threshold_stats['threshold_99']
                print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ë°©ë²• '{threshold_method}', 99 ë°±ë¶„ìœ„ìˆ˜ ì‚¬ìš©: {final_threshold:.4f}")
        else:
            # í´ë°±: ì¶”ë¡  ë°ì´í„° ê¸°ë°˜ (êµ¬ ë°©ì‹)
            final_threshold = np.percentile(errors_array, 95.0)
            print(f"âš ï¸  í•™ìŠµ ì‹œ ì„ê³„ê°’ ì •ë³´ ì—†ìŒ. ì¶”ë¡  ë°ì´í„° ê¸°ë°˜ 95 ë°±ë¶„ìœ„ìˆ˜ ì‚¬ìš©: {final_threshold:.4f}")
            print(f"   (ìˆœí™˜ ë…¼ë¦¬ ë¬¸ì œ ê°€ëŠ¥ì„± ìˆìŒ - ëª¨ë¸ ì¬í•™ìŠµ ê¶Œì¥)")

        # ì¶”ë¡  ë°ì´í„° í†µê³„ ì¶œë ¥ (ì°¸ê³ ìš©)
        print(f"ğŸ“Š ì¶”ë¡  ë°ì´í„° ì¬êµ¬ì„± ì˜¤ì°¨ í†µê³„:")
        print(f"   - í‰ê· : {np.mean(errors_array):.4f}")
        print(f"   - ì¤‘ì•™ê°’: {np.median(errors_array):.4f}")
        print(f"   - í‘œì¤€í¸ì°¨: {np.std(errors_array):.4f}")
        print(f"   - ìµœì†Œ: {np.min(errors_array):.4f}")
        print(f"   - ìµœëŒ€: {np.max(errors_array):.4f}")

        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±  # ê° ìœˆë„ìš°ë³„ ê²°ê³¼ êµ¬ì„±
        results = []  # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ëª©ë¡
        for i, error in enumerate(reconstruction_errors):  # ê° ì˜¤ì°¨ì— ëŒ€í•´ ë°˜ë³µ
            is_anomaly = error > final_threshold  # ì„ê³„ê°’ ì´ˆê³¼ ì—¬ë¶€

            # ì›ë³¸ ìœˆë„ìš° ì •ë³´ ë§¤í•‘  # ì‹œì‘ ì¸ë±ìŠ¤ ë§¤í•‘
            if i < len(df):  # ë°ì´í„°í”„ë ˆì„ ë²”ìœ„ ë‚´ì´ë©´
                start_index = df.iloc[i].get('start_index', i)  # ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ i
            else:  # ë²”ìœ„ë¥¼ ë„˜ìœ¼ë©´
                start_index = i  # ì¸ë±ìŠ¤ ì‚¬ìš©

            results.append({  # ê²°ê³¼ ë ˆì½”ë“œ ì¶”ê°€
                'window_idx': i,  # ìœˆë„ìš° ì¸ë±ìŠ¤
                'start_index': start_index,  # ì‹œì‘ ì¸ë±ìŠ¤
                'reconstruction_error': float(error),  # ì¬êµ¬ì„± ì˜¤ì°¨
                'is_anomaly': bool(is_anomaly),  # ì´ìƒ ì—¬ë¶€
                'threshold': float(final_threshold)  # ì‚¬ìš© ì„ê³„ê°’
            })  # ë ˆì½”ë“œ ì™„ë£Œ

        results_df = pd.DataFrame(results)  # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜

        # í†µê³„ ì¶œë ¥  # ìš”ì•½ ì •ë³´ í‘œì‹œ
        anomaly_rate = results_df['is_anomaly'].mean()  # ì´ìƒ ë¹„ìœ¨
        print(f"ğŸ“ˆ ìµœì¢… ì„ê³„ê°’: {final_threshold:.4f}")  # ì„ê³„ê°’ ë¡œê·¸
        print(f"ğŸš¨ ì´ìƒ íƒì§€ìœ¨: {anomaly_rate:.3f} ({results_df['is_anomaly'].sum()}/{len(results_df)})")  # íƒì§€ìœ¨ ë¡œê·¸

        return results_df  # ê²°ê³¼ ë°˜í™˜


def train_mscred(window_counts_path: str | Path, model_output_path: str | Path,
                epochs: int = 50) -> Dict:  # ë‹¨ì¼ í˜¸ì¶œ í•™ìŠµ í•¨ìˆ˜
    """MS-CRED ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜"""  # í•¨ìˆ˜ ì„¤ëª…
    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # CUDA ê°€ëŠ¥ ì‹œ GPU ì‚¬ìš©
    print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")  # ë””ë°”ì´ìŠ¤ ë¡œê·¸

    model = MSCREDModel()  # ëª¨ë¸ ìƒì„±
    trainer = MSCREDTrainer(model, device)  # íŠ¸ë ˆì´ë„ˆ ìƒì„±

    # í•™ìŠµ ì‹¤í–‰  # ì§€ì • ì—í­ë§Œí¼ í•™ìŠµ
    training_stats = trainer.train(window_counts_path, epochs)  # í•™ìŠµ í†µê³„ íšë“

    # ëª¨ë¸ ì €ì¥ (í…œí”Œë¦¿ ê°œìˆ˜ ë° ì„ê³„ê°’ ë©”íƒ€ë°ì´í„° í¬í•¨)  # ì¶”í›„ ì¶”ë¡  ì •í•©ì„± ë³´ì¥
    num_templates = training_stats['num_templates']  # í…œí”Œë¦¿ ìˆ˜ ì¶”ì¶œ
    threshold_stats = training_stats.get('threshold_stats')  # ì„ê³„ê°’ í†µê³„ ì¶”ì¶œ
    trainer.save_model(model_output_path, num_templates, threshold_stats)  # ì²´í¬í¬ì¸íŠ¸ ì €ì¥

    return training_stats  # í•™ìŠµ ê²°ê³¼ ë°˜í™˜


def infer_mscred(window_counts_path: str | Path, model_path: str | Path,
                output_path: str | Path,
                threshold: Optional[float] = None,
                threshold_method: str = '99percentile') -> pd.DataFrame:  # ë‹¨ì¼ í˜¸ì¶œ ì¶”ë¡  í•¨ìˆ˜
    """MS-CRED ì´ìƒ íƒì§€ ì¶”ë¡  í•¨ìˆ˜

    Args:
        window_counts_path: window_counts.parquet íŒŒì¼ ê²½ë¡œ
        model_path: í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        threshold: ìˆ˜ë™ ì„ê³„ê°’ (Noneì´ë©´ ìë™)
        threshold_method: ìë™ ì„ê³„ê°’ ë°©ë²• (ê¸°ë³¸: '99percentile')
            - '99percentile': í•™ìŠµ ì‹œ 99 ë°±ë¶„ìœ„ìˆ˜ (ê¶Œì¥)
            - '95percentile': í•™ìŠµ ì‹œ 95 ë°±ë¶„ìœ„ìˆ˜
            - '99.9percentile': í•™ìŠµ ì‹œ 99.9 ë°±ë¶„ìœ„ìˆ˜
            - '3sigma': í•™ìŠµ ì‹œ í‰ê·  + 3*í‘œì¤€í¸ì°¨
            - 'mad': í•™ìŠµ ì‹œ ì¤‘ì•™ê°’ + 3*1.4826*MAD

    Returns:
        ê²°ê³¼ DataFrame
    """
    device = 'cuda' if torch.cuda.is_available() else 'cpu'  # ë””ë°”ì´ìŠ¤ ì„ íƒ
    print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")  # ë””ë°”ì´ìŠ¤ ë¡œê·¸

    # ì¶”ë¡  ì‹¤í–‰  # ëª¨ë¸ ë¡œë“œ ë° ì´ìƒ íƒì§€
    inference = MSCREDInference(model_path, device)  # ì¶”ë¡  ê°ì²´ ìƒì„±
    results_df = inference.detect_anomalies(window_counts_path, threshold, threshold_method)  # ì´ìƒ íƒì§€ ì‹¤í–‰

    # ê²°ê³¼ ì €ì¥  # íŒŒì¼€ í¬ë§·ìœ¼ë¡œ ì¶œë ¥
    results_df.to_parquet(output_path, index=False)  # íŒŒì¼ ì €ì¥
    print(f"âœ… MS-CRED ì¶”ë¡  ê²°ê³¼ ì €ì¥: {output_path}")  # ì™„ë£Œ ë¡œê·¸

    return results_df  # ê²°ê³¼ ë°˜í™˜
