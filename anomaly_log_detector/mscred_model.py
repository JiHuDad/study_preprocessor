"""
MS-CRED (Multi-Scale Convolutional Recurrent Encoder-Decoder) ëª¨ë¸ êµ¬í˜„

MS-CREDëŠ” ì‹œê³„ì—´ ì´ìƒíƒì§€ë¥¼ ìœ„í•œ ë©€í‹°ìŠ¤ì¼€ì¼ ì»¨ë³¼ë£¨ì…˜ ì˜¤í† ì¸ì½”ë”ì…ë‹ˆë‹¤.
ë¡œê·¸ í…œí”Œë¦¿ ì¹´ìš´íŠ¸ ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì¬êµ¬ì„± ì˜¤ì°¨ë¥¼ í†µí•´ ì´ìƒì„ íƒì§€í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
import pandas as pd
import numpy as np
from typing import Tuple, List, Dict, Optional
import json
from tqdm import tqdm


class MultiScaleConvBlock(nn.Module):
    """ë©€í‹°ìŠ¤ì¼€ì¼ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡"""
    
    def __init__(self, in_channels: int, out_channels: int, kernel_sizes: List[int] = [3, 5, 7]):
        super().__init__()
        self.kernel_sizes = kernel_sizes
        
        # ê° ì»¤ë„ì˜ ì±„ë„ ìˆ˜ë¥¼ ê· ë“±í•˜ê²Œ ë¶„ë°°í•˜ë˜ ë‚˜ë¨¸ì§€ëŠ” ì²« ë²ˆì§¸ ì»¤ë„ì— í• ë‹¹
        channels_per_kernel = out_channels // len(kernel_sizes)
        remainder = out_channels % len(kernel_sizes)
        
        # ê° ì»¤ë„ í¬ê¸°ë³„ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´
        self.convs = nn.ModuleList()
        for i, k in enumerate(kernel_sizes):
            # ì²« ë²ˆì§¸ ì»¤ë„ì— ë‚˜ë¨¸ì§€ ì±„ë„ ì¶”ê°€
            current_channels = channels_per_kernel + (remainder if i == 0 else 0)
            self.convs.append(
                nn.Conv2d(in_channels, current_channels, kernel_size=k, padding=k//2)
            )
        
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # ê° ì»¤ë„ í¬ê¸°ë³„ë¡œ ì»¨ë³¼ë£¨ì…˜ ì ìš© í›„ ì±„ë„ ì°¨ì›ì—ì„œ ê²°í•©
        conv_outputs = [conv(x) for conv in self.convs]
        out = torch.cat(conv_outputs, dim=1)
        out = self.bn(out)
        out = self.relu(out)
        return out


class AttentionModule(nn.Module):
    """ì–´í…ì…˜ ëª¨ë“ˆ"""
    
    def __init__(self, channels: int):
        super().__init__()
        self.conv_att = nn.Conv2d(channels, 1, kernel_size=1)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # ì±„ë„ë³„ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°
        att_weights = torch.sigmoid(self.conv_att(x))
        return x * att_weights


class MSCREDEncoder(nn.Module):
    """MS-CRED ì¸ì½”ë”"""
    
    def __init__(self, input_channels: int = 1, base_channels: int = 32):
        super().__init__()
        
        # ë©€í‹°ìŠ¤ì¼€ì¼ ì»¨ë³¼ë£¨ì…˜ ë ˆì´ì–´ë“¤
        self.conv1 = MultiScaleConvBlock(input_channels, base_channels)
        self.conv2 = MultiScaleConvBlock(base_channels, base_channels * 2)
        self.conv3 = MultiScaleConvBlock(base_channels * 2, base_channels * 4)
        
        # ì–´í…ì…˜ ëª¨ë“ˆë“¤
        self.att1 = AttentionModule(base_channels)
        self.att2 = AttentionModule(base_channels * 2)
        self.att3 = AttentionModule(base_channels * 4)
        
        # ë‹¤ìš´ìƒ˜í”Œë§
        self.pool = nn.MaxPool2d(2, 2)
        
    def forward(self, x: torch.Tensor) -> List[torch.Tensor]:
        # x: (batch, 1, height, width) - height: time_steps, width: num_templates
        
        # ì²« ë²ˆì§¸ ìŠ¤ì¼€ì¼
        x1 = self.conv1(x)
        x1_att = self.att1(x1)
        
        # ë‘ ë²ˆì§¸ ìŠ¤ì¼€ì¼ 
        x2 = self.pool(x1_att)
        x2 = self.conv2(x2)
        x2_att = self.att2(x2)
        
        # ì„¸ ë²ˆì§¸ ìŠ¤ì¼€ì¼
        x3 = self.pool(x2_att)
        x3 = self.conv3(x3)
        x3_att = self.att3(x3)
        
        return [x1_att, x2_att, x3_att]


class MSCREDDecoder(nn.Module):
    """MS-CRED ë””ì½”ë” (ê°„ì†Œí™” ë²„ì „)"""
    
    def __init__(self, base_channels: int = 32, output_channels: int = 1):
        super().__init__()
        
        # ê°„ë‹¨í•œ ì—…ìƒ˜í”Œë§ ë””ì½”ë”
        self.deconv3 = nn.ConvTranspose2d(base_channels * 4, base_channels * 2, 
                                         kernel_size=4, stride=2, padding=1)
        self.deconv2 = nn.ConvTranspose2d(base_channels * 2, base_channels, 
                                         kernel_size=4, stride=2, padding=1)
        self.deconv1 = nn.Conv2d(base_channels, output_channels, kernel_size=3, padding=1)
        
        self.relu = nn.ReLU(inplace=True)
        
    def forward(self, encoder_outputs: List[torch.Tensor]) -> torch.Tensor:
        # ê°€ì¥ ì‘ì€ í”¼ì²˜ë§µ(ê°€ì¥ ê¹Šì€ ì¸ì½”ë”©)ë§Œ ì‚¬ìš©
        _, _, x3_att = encoder_outputs
        
        # ì—…ìƒ˜í”Œë§ìœ¼ë¡œ ì›ë˜ í¬ê¸°ë¡œ ë³µì›
        x = self.relu(self.deconv3(x3_att))
        x = self.relu(self.deconv2(x))
        x = self.deconv1(x)
        
        return x


class MSCREDModel(nn.Module):
    """MS-CRED ì „ì²´ ëª¨ë¸"""
    
    def __init__(self, input_channels: int = 1, base_channels: int = 32):
        super().__init__()
        self.encoder = MSCREDEncoder(input_channels, base_channels)
        self.decoder = MSCREDDecoder(base_channels, input_channels)
        
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # ì…ë ¥ í¬ê¸° ì €ì¥
        input_shape = x.shape

        encoded = self.encoder(x)
        reconstructed = self.decoder(encoded)

        # ì¶œë ¥ í¬ê¸°ë¥¼ ì…ë ¥ í¬ê¸°ì™€ ì •í™•íˆ ë§ì¶¤
        # ONNX ì¶”ì  í˜¸í™˜ì„±: shape ë¹„êµ ëŒ€ì‹  í•­ìƒ interpolate ìˆ˜í–‰
        # (ì…ë ¥ê³¼ ì¶œë ¥ì´ ê°™ìœ¼ë©´ interpolateëŠ” no-op)
        reconstructed = F.interpolate(
            reconstructed,
            size=(input_shape[2], input_shape[3]),
            mode='bilinear',
            align_corners=False
        )

        return reconstructed
    
    def compute_reconstruction_error(self, x: torch.Tensor, reconstructed: torch.Tensor) -> torch.Tensor:
        """ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°"""
        return F.mse_loss(reconstructed, x, reduction='none').mean(dim=[1, 2, 3])


class MSCREDTrainer:
    """MS-CRED ëª¨ë¸ íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, model: MSCREDModel, device: str = 'cpu'):
        self.model = model.to(device)
        self.device = device
        self.optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5, patience=5
        )
        
    def prepare_data(self, window_counts_df: pd.DataFrame) -> torch.Tensor:
        """ìœˆë„ìš° ì¹´ìš´íŠ¸ ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜"""
        # start_index ì»¬ëŸ¼ ì œê±°í•˜ê³  í…œí”Œë¦¿ ì¹´ìš´íŠ¸ë§Œ ì¶”ì¶œ
        template_cols = [col for col in window_counts_df.columns if col.startswith('t')]
        data = window_counts_df[template_cols].fillna(0).values
        
        # ì •ê·œí™”
        data = (data - data.mean(axis=0)) / (data.std(axis=0) + 1e-8)
        
        # 2D ë§¤íŠ¸ë¦­ìŠ¤ë¥¼ ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³€í™˜ (time_steps, num_templates)
        # ì‹œí€€ìŠ¤ ê¸¸ì´ ì„¤ì • (ì˜ˆ: 20ê°œ ìœˆë„ìš°ì”©)
        seq_len = 20
        sequences = []
        
        for i in range(len(data) - seq_len + 1):
            seq = data[i:i+seq_len]  # (seq_len, num_templates)
            sequences.append(seq)
        
        if not sequences:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° íŒ¨ë”©
            padded_data = np.pad(data, ((0, seq_len - len(data)), (0, 0)), mode='constant')
            sequences = [padded_data]
        
        # (batch, 1, time_steps, num_templates) í˜•íƒœë¡œ ë³€í™˜
        sequences = np.array(sequences)
        return torch.FloatTensor(sequences).unsqueeze(1)
    
    def train(self, window_counts_path: str | Path, epochs: int = 50, 
              validation_split: float = 0.2) -> Dict:
        """ëª¨ë¸ í•™ìŠµ"""
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_parquet(window_counts_path)
        data_tensor = self.prepare_data(df).to(self.device)
        
        # í•™ìŠµ/ê²€ì¦ ë¶„í• 
        n_train = int(len(data_tensor) * (1 - validation_split))
        train_data = data_tensor[:n_train]
        val_data = data_tensor[n_train:]
        
        print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_data)}, ê²€ì¦ ë°ì´í„°: {len(val_data)}")
        print(f"ğŸ“ ë°ì´í„° í˜•íƒœ: {data_tensor.shape}")
        
        train_losses = []
        val_losses = []
        
        self.model.train()
        
        for epoch in tqdm(range(epochs), desc="MS-CRED í•™ìŠµ"):
            # í•™ìŠµ
            epoch_train_loss = 0
            for i in range(0, len(train_data), 32):  # ë°°ì¹˜ í¬ê¸° 32
                batch = train_data[i:i+32]
                
                self.optimizer.zero_grad()
                reconstructed = self.model(batch)
                loss = F.mse_loss(reconstructed, batch)
                loss.backward()
                self.optimizer.step()
                
                epoch_train_loss += loss.item()
            
            # ê²€ì¦
            self.model.eval()
            epoch_val_loss = 0
            with torch.no_grad():
                for i in range(0, len(val_data), 32):
                    batch = val_data[i:i+32]
                    reconstructed = self.model(batch)
                    loss = F.mse_loss(reconstructed, batch)
                    epoch_val_loss += loss.item()
            
            self.model.train()
            
            avg_train_loss = epoch_train_loss / (len(train_data) // 32 + 1)
            avg_val_loss = epoch_val_loss / (len(val_data) // 32 + 1) if len(val_data) > 0 else 0
            
            train_losses.append(avg_train_loss)
            val_losses.append(avg_val_loss)
            
            self.scheduler.step(avg_val_loss)
            
            if epoch % 10 == 0:
                print(f"Epoch {epoch}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}")
        
        return {
            'train_losses': train_losses,
            'val_losses': val_losses,
            'final_train_loss': train_losses[-1],
            'final_val_loss': val_losses[-1]
        }
    
    def save_model(self, path: str | Path):
        """ëª¨ë¸ ì €ì¥"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
        }, path)
        print(f"âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {path}")
    
    def load_model(self, path: str | Path):
        """ëª¨ë¸ ë¡œë“œ"""
        checkpoint = torch.load(path, map_location=self.device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")


class MSCREDInference:
    """MS-CRED ì¶”ë¡ """
    
    def __init__(self, model_path: str | Path, device: str = 'cpu'):
        self.device = device
        self.model = MSCREDModel().to(device)
        
        # ëª¨ë¸ ë¡œë“œ
        checkpoint = torch.load(model_path, map_location=device)
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.model.eval()
        
    def detect_anomalies(self, window_counts_path: str | Path, 
                        threshold_percentile: float = 95.0) -> pd.DataFrame:
        """ì´ìƒ íƒì§€ ìˆ˜í–‰"""
        
        # ë°ì´í„° ì¤€ë¹„
        trainer = MSCREDTrainer(self.model, self.device)
        df = pd.read_parquet(window_counts_path)
        data_tensor = trainer.prepare_data(df).to(self.device)
        
        print(f"ğŸ“Š ì¶”ë¡  ë°ì´í„° í˜•íƒœ: {data_tensor.shape}")
        
        # ì¬êµ¬ì„± ì˜¤ì°¨ ê³„ì‚°
        reconstruction_errors = []
        
        with torch.no_grad():
            for i in range(0, len(data_tensor), 32):
                batch = data_tensor[i:i+32]
                reconstructed = self.model(batch)
                errors = self.model.compute_reconstruction_error(batch, reconstructed)
                reconstruction_errors.extend(errors.cpu().numpy())
        
        # ì„ê³„ê°’ ê³„ì‚°
        errors_array = np.array(reconstruction_errors)
        threshold = np.percentile(errors_array, threshold_percentile)
        
        # ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
        results = []
        for i, error in enumerate(reconstruction_errors):
            is_anomaly = error > threshold
            
            # ì›ë³¸ ìœˆë„ìš° ì •ë³´ ë§¤í•‘
            if i < len(df):
                start_index = df.iloc[i].get('start_index', i)
            else:
                start_index = i
            
            results.append({
                'window_idx': i,
                'start_index': start_index,
                'reconstruction_error': float(error),
                'is_anomaly': bool(is_anomaly),
                'threshold': float(threshold)
            })
        
        results_df = pd.DataFrame(results)
        
        # í†µê³„ ì¶œë ¥
        anomaly_rate = results_df['is_anomaly'].mean()
        print(f"ğŸ“ˆ ì¬êµ¬ì„± ì˜¤ì°¨ ì„ê³„ê°’: {threshold:.4f} ({threshold_percentile}%)")
        print(f"ğŸš¨ ì´ìƒ íƒì§€ìœ¨: {anomaly_rate:.3f} ({results_df['is_anomaly'].sum()}/{len(results_df)})")
        
        return results_df


def train_mscred(window_counts_path: str | Path, model_output_path: str | Path, 
                epochs: int = 50) -> Dict:
    """MS-CRED ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    model = MSCREDModel()
    trainer = MSCREDTrainer(model, device)
    
    # í•™ìŠµ ì‹¤í–‰
    training_stats = trainer.train(window_counts_path, epochs)
    
    # ëª¨ë¸ ì €ì¥
    trainer.save_model(model_output_path)
    
    return training_stats


def infer_mscred(window_counts_path: str | Path, model_path: str | Path, 
                output_path: str | Path, threshold_percentile: float = 95.0) -> pd.DataFrame:
    """MS-CRED ì´ìƒ íƒì§€ ì¶”ë¡  í•¨ìˆ˜"""
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ì¶”ë¡  ì‹¤í–‰
    inference = MSCREDInference(model_path, device)
    results_df = inference.detect_anomalies(window_counts_path, threshold_percentile)
    
    # ê²°ê³¼ ì €ì¥
    results_df.to_parquet(output_path, index=False)
    print(f"âœ… MS-CRED ì¶”ë¡  ê²°ê³¼ ì €ì¥: {output_path}")
    
    return results_df
