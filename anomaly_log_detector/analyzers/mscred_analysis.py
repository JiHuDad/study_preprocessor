#!/usr/bin/env python3
"""
MS-CRED ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬

MS-CRED ì´ìƒíƒì§€ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ì—¬ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import pandas as pd
import numpy as np
from pathlib import Path
import json
from typing import Dict, List, Optional, Tuple
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import argparse


class MSCREDAnalyzer:
    """MS-CRED ê²°ê³¼ ë¶„ì„ê¸°"""
    
    def __init__(self, data_dir: str | Path):
        self.data_dir = Path(data_dir)
        self.results = {}
        self.load_results()
    
    def load_results(self):
        """MS-CRED ê´€ë ¨ íŒŒì¼ë“¤ ë¡œë“œ"""
        
        # MS-CRED ì¶”ë¡  ê²°ê³¼
        mscred_path = self.data_dir / "mscred_infer.parquet"
        if mscred_path.exists():
            self.results['mscred'] = pd.read_parquet(mscred_path)
            print(f"âœ… MS-CRED ê²°ê³¼ ë¡œë“œ: {len(self.results['mscred'])} ìœˆë„ìš°")
        
        # ìœˆë„ìš° ì¹´ìš´íŠ¸ ë°ì´í„°
        window_counts_path = self.data_dir / "window_counts.parquet"
        if window_counts_path.exists():
            self.results['window_counts'] = pd.read_parquet(window_counts_path)
            print(f"âœ… ìœˆë„ìš° ì¹´ìš´íŠ¸ ë¡œë“œ: {len(self.results['window_counts'])} ìœˆë„ìš°")
        
        # ì›ë³¸ íŒŒì‹± ë°ì´í„° (ë§¥ë½ ë¶„ì„ìš©)
        parsed_path = self.data_dir / "parsed.parquet"
        if parsed_path.exists():
            self.results['parsed'] = pd.read_parquet(parsed_path)
            print(f"âœ… íŒŒì‹± ë°ì´í„° ë¡œë“œ: {len(self.results['parsed'])} ë¡œê·¸")
        
        # ë‹¤ë¥¸ ì´ìƒíƒì§€ ê²°ê³¼ë“¤ê³¼ ë¹„êµìš©
        baseline_path = self.data_dir / "baseline_scores.parquet"
        if baseline_path.exists():
            self.results['baseline'] = pd.read_parquet(baseline_path)
        
        deeplog_path = self.data_dir / "deeplog_infer.parquet"
        if deeplog_path.exists():
            self.results['deeplog'] = pd.read_parquet(deeplog_path)
    
    def analyze_reconstruction_errors(self) -> Dict:
        """ì¬êµ¬ì„± ì˜¤ì°¨ í†µê³„ ë¶„ì„"""
        if 'mscred' not in self.results:
            return {}
        
        df = self.results['mscred']
        errors = df['reconstruction_error']
        
        stats = {
            'count': len(errors),
            'mean': float(errors.mean()),
            'std': float(errors.std()),
            'min': float(errors.min()),
            'max': float(errors.max()),
            'median': float(errors.median()),
            'q75': float(errors.quantile(0.75)),
            'q95': float(errors.quantile(0.95)),
            'q99': float(errors.quantile(0.99)),
            'anomaly_count': int(df['is_anomaly'].sum()),
            'anomaly_rate': float(df['is_anomaly'].mean()),
            'threshold': float(df['threshold'].iloc[0]) if len(df) > 0 else 0.0
        }
        
        return stats
    
    def find_anomaly_patterns(self) -> List[Dict]:
        """ì´ìƒ íŒ¨í„´ ë¶„ì„"""
        if 'mscred' not in self.results or 'window_counts' not in self.results:
            return []
        
        mscred_df = self.results['mscred']
        window_counts_df = self.results['window_counts']
        
        # ì´ìƒìœ¼ë¡œ íŒì •ëœ ìœˆë„ìš°ë“¤
        anomaly_windows = mscred_df[mscred_df['is_anomaly'] == True].copy()
        
        patterns = []
        for _, anomaly in anomaly_windows.head(20).iterrows():  # ìƒìœ„ 20ê°œ ì´ìƒ ìœˆë„ìš°
            window_idx = int(anomaly['window_idx'])
            
            # í•´ë‹¹ ìœˆë„ìš°ì˜ í…œí”Œë¦¿ ì¹´ìš´íŠ¸ íŒ¨í„´
            if window_idx < len(window_counts_df):
                window_data = window_counts_df.iloc[window_idx]
                template_cols = [col for col in window_data.index if col.startswith('t')]
                template_counts = {col: int(window_data[col]) for col in template_cols if pd.notna(window_data[col]) and window_data[col] > 0}
                
                # ê°€ì¥ ë¹ˆë²ˆí•œ í…œí”Œë¦¿ë“¤
                top_templates = sorted(template_counts.items(), key=lambda x: x[1], reverse=True)[:5]
                
                pattern = {
                    'window_idx': window_idx,
                    'start_index': int(anomaly.get('start_index', window_idx)),
                    'reconstruction_error': float(anomaly['reconstruction_error']),
                    'top_templates': top_templates,
                    'total_logs': sum(template_counts.values()),
                    'unique_templates': len(template_counts)
                }
                patterns.append(pattern)
        
        return patterns
    
    def compare_with_other_methods(self) -> Dict:
        """ë‹¤ë¥¸ ì´ìƒíƒì§€ ë°©ë²•ê³¼ ë¹„êµ"""
        comparison = {
            'mscred_anomalies': set(),
            'baseline_anomalies': set(),
            'deeplog_anomalies': set(),
            'overlap_stats': {}
        }
        
        # MS-CRED ì´ìƒ ìœˆë„ìš°ë“¤
        if 'mscred' in self.results:
            mscred_df = self.results['mscred']
            mscred_anomalies = mscred_df[mscred_df['is_anomaly'] == True]['window_idx'].tolist()
            comparison['mscred_anomalies'] = set(mscred_anomalies)
        
        # Baseline ì´ìƒ ìœˆë„ìš°ë“¤ (window_start_lineì„ ìœˆë„ìš° ì¸ë±ìŠ¤ë¡œ ë³€í™˜)
        if 'baseline' in self.results:
            baseline_df = self.results['baseline']
            baseline_anomalies = baseline_df[baseline_df['is_anomaly'] == True]
            if 'window_start_line' in baseline_anomalies.columns:
                # start_lineì„ window_idxë¡œ ë³€í™˜ (ëŒ€ëµì )
                baseline_window_idx = (baseline_anomalies['window_start_line'] // 25).astype(int).tolist()
                comparison['baseline_anomalies'] = set(baseline_window_idx)
        
        # DeepLogëŠ” ì‹œí€€ìŠ¤ ê¸°ë°˜ì´ë¯€ë¡œ ì§ì ‘ ë¹„êµ ì–´ë ¤ì›€
        if 'deeplog' in self.results:
            deeplog_df = self.results['deeplog']
            violations = deeplog_df[deeplog_df['in_topk'] == False]
            comparison['deeplog_violations'] = len(violations)
        
        # ê²¹ì¹˜ëŠ” ë¶€ë¶„ ê³„ì‚°
        mscred_set = comparison['mscred_anomalies']
        baseline_set = comparison['baseline_anomalies']
        
        if mscred_set and baseline_set:
            overlap = mscred_set.intersection(baseline_set)
            comparison['overlap_stats'] = {
                'mscred_only': len(mscred_set - baseline_set),
                'baseline_only': len(baseline_set - mscred_set),
                'both_methods': len(overlap),
                'overlap_ratio': len(overlap) / len(mscred_set.union(baseline_set)) if mscred_set.union(baseline_set) else 0.0
            }
        
        return comparison
    
    def extract_anomaly_logs(self) -> List[Dict]:
        """ì´ìƒ ìœˆë„ìš°ì˜ ì‹¤ì œ ë¡œê·¸ ë‚´ìš© ì¶”ì¶œ"""
        if 'mscred' not in self.results or 'parsed' not in self.results:
            return []
        
        mscred_df = self.results['mscred']
        parsed_df = self.results['parsed']
        
        anomaly_windows = mscred_df[mscred_df['is_anomaly'] == True].nlargest(10, 'reconstruction_error')
        
        anomaly_logs = []
        for _, anomaly in anomaly_windows.iterrows():
            start_index = int(anomaly.get('start_index', anomaly['window_idx'] * 25))
            
            # ìœˆë„ìš° ë²”ìœ„ì˜ ë¡œê·¸ë“¤ ì¶”ì¶œ (50ê°œ ë¡œê·¸)
            window_logs = parsed_df[
                (parsed_df['line_no'] >= start_index) & 
                (parsed_df['line_no'] < start_index + 50)
            ].copy()
            
            if len(window_logs) > 0:
                # ì—ëŸ¬ í‚¤ì›Œë“œ ê²€ì¶œ
                error_logs = window_logs[
                    window_logs['raw'].str.contains(
                        r'error|Error|ERROR|fail|Fail|FAIL|exception|Exception|EXCEPTION|warning|Warning|WARNING|critical|Critical|CRITICAL',
                        case=False, na=False, regex=True
                    )
                ]
                
                # ëŒ€í‘œ ë¡œê·¸ë“¤ ì„ íƒ
                sample_logs = window_logs.head(5)['raw'].tolist()
                error_samples = error_logs.head(3)['raw'].tolist() if len(error_logs) > 0 else []
                
                anomaly_info = {
                    'window_idx': int(anomaly['window_idx']),
                    'start_index': start_index,
                    'reconstruction_error': float(anomaly['reconstruction_error']),
                    'total_logs': len(window_logs),
                    'error_logs': len(error_logs),
                    'error_rate': len(error_logs) / len(window_logs) if len(window_logs) > 0 else 0.0,
                    'sample_logs': sample_logs,
                    'error_samples': error_samples,
                    'dominant_templates': window_logs['template'].value_counts().head(3).to_dict()
                }
                anomaly_logs.append(anomaly_info)
        
        return anomaly_logs
    
    def create_visualization(self, output_dir: str | Path):
        """ì‹œê°í™” ìƒì„±"""
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)
        
        if 'mscred' not in self.results:
            print("âŒ MS-CRED ê²°ê³¼ê°€ ì—†ì–´ ì‹œê°í™”ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        df = self.results['mscred']
        
        # 1. ì¬êµ¬ì„± ì˜¤ì°¨ ë¶„í¬
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        plt.hist(df['reconstruction_error'], bins=50, alpha=0.7, edgecolor='black')
        plt.axvline(df['threshold'].iloc[0], color='red', linestyle='--', label=f'Threshold: {df["threshold"].iloc[0]:.4f}')
        plt.xlabel('Reconstruction Error')
        plt.ylabel('Frequency')
        plt.title('MS-CRED Reconstruction Error Distribution')
        plt.legend()
        
        # 2. ì‹œê°„ ìˆœì„œë³„ ì¬êµ¬ì„± ì˜¤ì°¨
        plt.subplot(2, 2, 2)
        plt.plot(df['window_idx'], df['reconstruction_error'], alpha=0.6)
        anomalies = df[df['is_anomaly'] == True]
        if len(anomalies) > 0:
            plt.scatter(anomalies['window_idx'], anomalies['reconstruction_error'], 
                       color='red', s=30, alpha=0.8, label='Anomalies')
        plt.axhline(df['threshold'].iloc[0], color='red', linestyle='--', alpha=0.7)
        plt.xlabel('Window Index')
        plt.ylabel('Reconstruction Error')
        plt.title('MS-CRED Errors Over Time')
        plt.legend()
        
        # 3. ì´ìƒë¥  í†µê³„
        plt.subplot(2, 2, 3)
        anomaly_rate = df['is_anomaly'].mean()
        normal_rate = 1 - anomaly_rate
        plt.pie([normal_rate, anomaly_rate], labels=['Normal', 'Anomaly'], 
                autopct='%1.1f%%', colors=['lightblue', 'red'])
        plt.title('MS-CRED Anomaly Distribution')
        
        # 4. ìƒìœ„ ì´ìƒ ìœˆë„ìš°ë“¤
        plt.subplot(2, 2, 4)
        top_anomalies = df.nlargest(10, 'reconstruction_error')
        plt.barh(range(len(top_anomalies)), top_anomalies['reconstruction_error'])
        plt.yticks(range(len(top_anomalies)), [f"W{int(w)}" for w in top_anomalies['window_idx']])
        plt.xlabel('Reconstruction Error')
        plt.title('Top 10 Anomalous Windows')
        
        plt.tight_layout()
        plt.savefig(output_dir / 'mscred_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… MS-CRED ì‹œê°í™” ì €ì¥: {output_dir / 'mscred_analysis.png'}")
        
        # 5. ë°©ë²• ê°„ ë¹„êµ (ë‹¤ë¥¸ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°)
        comparison = self.compare_with_other_methods()
        if comparison['overlap_stats']:
            plt.figure(figsize=(10, 6))
            
            stats = comparison['overlap_stats']
            categories = ['MS-CRED Only', 'Baseline Only', 'Both Methods']
            values = [stats['mscred_only'], stats['baseline_only'], stats['both_methods']]
            
            plt.bar(categories, values, color=['blue', 'green', 'orange'])
            plt.ylabel('Number of Anomalous Windows')
            plt.title('Anomaly Detection Method Comparison')
            
            for i, v in enumerate(values):
                plt.text(i, v + 0.1, str(v), ha='center', va='bottom')
            
            plt.tight_layout()
            plt.savefig(output_dir / 'method_comparison.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            print(f"âœ… ë°©ë²• ë¹„êµ ì‹œê°í™” ì €ì¥: {output_dir / 'method_comparison.png'}")
    
    def generate_report(self, output_path: str | Path):
        """MS-CRED ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        output_path = Path(output_path)
        
        if 'mscred' not in self.results:
            print("âŒ MS-CRED ê²°ê³¼ê°€ ì—†ì–´ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë¶„ì„ ìˆ˜í–‰
        error_stats = self.analyze_reconstruction_errors()
        patterns = self.find_anomaly_patterns()
        comparison = self.compare_with_other_methods()
        anomaly_logs = self.extract_anomaly_logs()
        
        # ë¦¬í¬íŠ¸ ì‘ì„±
        report_lines = [
            "# MS-CRED ì´ìƒíƒì§€ ë¶„ì„ ë¦¬í¬íŠ¸",
            f"\n**ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"**ë¶„ì„ ë°ì´í„°**: {self.data_dir}",
            
            "\n## ğŸ“Š ì¬êµ¬ì„± ì˜¤ì°¨ í†µê³„",
            f"- **ì´ ìœˆë„ìš° ìˆ˜**: {error_stats['count']:,}",
            f"- **í‰ê·  ì¬êµ¬ì„± ì˜¤ì°¨**: {error_stats['mean']:.4f}",
            f"- **í‘œì¤€í¸ì°¨**: {error_stats['std']:.4f}",
            f"- **ìµœëŒ€ ì˜¤ì°¨**: {error_stats['max']:.4f}",
            f"- **95%ile**: {error_stats['q95']:.4f}",
            f"- **99%ile**: {error_stats['q99']:.4f}",
            f"- **ì„ê³„ê°’**: {error_stats['threshold']:.4f}",
            
            "\n## ğŸš¨ ì´ìƒíƒì§€ ê²°ê³¼",
            f"- **ì´ìƒ ìœˆë„ìš° ìˆ˜**: {error_stats['anomaly_count']:,}",
            f"- **ì´ìƒíƒì§€ìœ¨**: {error_stats['anomaly_rate']:.1%}",
        ]
        
        # ë‹¤ë¥¸ ë°©ë²•ê³¼ì˜ ë¹„êµ
        if comparison['overlap_stats']:
            stats = comparison['overlap_stats']
            report_lines.extend([
                "\n## ğŸ” ë‹¤ë¥¸ ì´ìƒíƒì§€ ë°©ë²•ê³¼ì˜ ë¹„êµ",
                f"- **MS-CRED ë‹¨ë… íƒì§€**: {stats['mscred_only']} ìœˆë„ìš°",
                f"- **Baseline ë‹¨ë… íƒì§€**: {stats['baseline_only']} ìœˆë„ìš°", 
                f"- **ë‘ ë°©ë²• ëª¨ë‘ íƒì§€**: {stats['both_methods']} ìœˆë„ìš°",
                f"- **ê²¹ì¹¨ ë¹„ìœ¨**: {stats['overlap_ratio']:.1%}",
            ])
        
        # ìƒìœ„ ì´ìƒ íŒ¨í„´ë“¤
        if patterns:
            report_lines.extend([
                "\n## ğŸ¯ ì£¼ìš” ì´ìƒ íŒ¨í„´ (ìƒìœ„ 10ê°œ)",
                ""
            ])
            
            for i, pattern in enumerate(patterns[:10], 1):
                report_lines.extend([
                    f"### {i}. ìœˆë„ìš° {pattern['window_idx']} (ì‹œì‘: {pattern['start_index']})",
                    f"- **ì¬êµ¬ì„± ì˜¤ì°¨**: {pattern['reconstruction_error']:.4f}",
                    f"- **ì´ ë¡œê·¸ ìˆ˜**: {pattern['total_logs']}",
                    f"- **ê³ ìœ  í…œí”Œë¦¿ ìˆ˜**: {pattern['unique_templates']}",
                    f"- **ì£¼ìš” í…œí”Œë¦¿**: {', '.join([f'{t}({c})' for t, c in pattern['top_templates'][:3]])}",
                    ""
                ])
        
        # ì‹¤ì œ ì´ìƒ ë¡œê·¸ ìƒ˜í”Œë“¤
        if anomaly_logs:
            report_lines.extend([
                "\n## ğŸ“‹ ì‹¤ì œ ì´ìƒ ë¡œê·¸ ìƒ˜í”Œë“¤",
                ""
            ])
            
            for i, log_info in enumerate(anomaly_logs[:5], 1):
                report_lines.extend([
                    f"### {i}. ìœˆë„ìš° {log_info['window_idx']} (ì—ëŸ¬ìœ¨: {log_info['error_rate']:.1%})",
                    f"**ì¬êµ¬ì„± ì˜¤ì°¨**: {log_info['reconstruction_error']:.4f}",
                    f"**ë¡œê·¸ ìˆ˜**: {log_info['total_logs']} (ì—ëŸ¬: {log_info['error_logs']})",
                    ""
                ])
                
                if log_info['error_samples']:
                    report_lines.extend([
                        "**ğŸš¨ ì—ëŸ¬ ë¡œê·¸ ìƒ˜í”Œë“¤**:",
                        ""
                    ])
                    for error_log in log_info['error_samples']:
                        report_lines.append(f"```\n{error_log[:200]}...\n```")
                    report_lines.append("")
                
                if log_info['sample_logs']:
                    report_lines.extend([
                        "**ğŸ“„ ì¼ë°˜ ë¡œê·¸ ìƒ˜í”Œë“¤**:",
                        ""
                    ])
                    for sample_log in log_info['sample_logs'][:3]:
                        report_lines.append(f"```\n{sample_log[:150]}...\n```")
                    report_lines.append("")
        
        # ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­
        report_lines.extend([
            "\n## ğŸ’¡ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­",
            "",
            f"- MS-CREDëŠ” ì´ {error_stats['count']:,}ê°œ ìœˆë„ìš° ì¤‘ {error_stats['anomaly_count']:,}ê°œë¥¼ ì´ìƒìœ¼ë¡œ íƒì§€í–ˆìŠµë‹ˆë‹¤.",
            f"- ì´ìƒíƒì§€ìœ¨ {error_stats['anomaly_rate']:.1%}ëŠ” "
            + ("ì •ìƒ ë²”ìœ„" if error_stats['anomaly_rate'] < 0.1 else "ë†’ì€ í¸") + "ì…ë‹ˆë‹¤.",
        ])
        
        if comparison['overlap_stats']:
            overlap_ratio = comparison['overlap_stats']['overlap_ratio']
            if overlap_ratio > 0.5:
                report_lines.append("- ë‹¤ë¥¸ ì´ìƒíƒì§€ ë°©ë²•ê³¼ ë†’ì€ ì¼ì¹˜ìœ¨ì„ ë³´ì—¬ ì‹ ë¢°ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
            else:
                report_lines.append("- ë‹¤ë¥¸ ë°©ë²•ê³¼ ë‹¤ë¥¸ íŒ¨í„´ì„ íƒì§€í•˜ë¯€ë¡œ ìƒí˜¸ ë³´ì™„ì ìœ¼ë¡œ í™œìš©í•˜ì„¸ìš”.")
        
        report_lines.extend([
            "- ë†’ì€ ì¬êµ¬ì„± ì˜¤ì°¨ë¥¼ ë³´ì´ëŠ” ìœˆë„ìš°ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ ê²€í† í•˜ì„¸ìš”.",
            "- ì—ëŸ¬ ë¡œê·¸ê°€ ì§‘ì¤‘ëœ êµ¬ê°„ì€ ì‹œìŠ¤í…œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.",
            ""
        ])
        
        # íŒŒì¼ ì €ì¥
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"âœ… MS-CRED ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")


def main():
    parser = argparse.ArgumentParser(description="MS-CRED ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±")
    parser.add_argument("--data-dir", type=str, required=True, 
                       help="MS-CRED ê²°ê³¼ê°€ í¬í•¨ëœ ë°ì´í„° ë””ë ‰í† ë¦¬")
    parser.add_argument("--output-dir", type=str, 
                       help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: ë°ì´í„° ë””ë ‰í† ë¦¬)")
    
    args = parser.parse_args()
    
    data_dir = Path(args.data_dir)
    output_dir = Path(args.output_dir) if args.output_dir else data_dir
    
    if not data_dir.exists():
        print(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
        return
    
    print(f"ğŸ” MS-CRED ê²°ê³¼ ë¶„ì„ ì‹œì‘: {data_dir}")
    
    # ë¶„ì„ê¸° ìƒì„± ë° ì‹¤í–‰
    analyzer = MSCREDAnalyzer(data_dir)
    
    # ì‹œê°í™” ìƒì„±
    analyzer.create_visualization(output_dir)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report_path = output_dir / "mscred_analysis_report.md"
    analyzer.generate_report(report_path)
    
    print(f"âœ… MS-CRED ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ëŠ” {output_dir}ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
