#!/usr/bin/env python3
"""
ìë™ ëª¨ë¸ ë³€í™˜ ë° ë°°í¬ ìŠ¤í¬ë¦½íŠ¸
í•™ìŠµ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ONNX ë³€í™˜ ë° C ì—”ì§„ ë°°í¬ ì¤€ë¹„
"""

import os
import json
import time
import shutil
from pathlib import Path
from typing import Dict, Any, Optional
import logging
from datetime import datetime
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

from .model_converter import ModelConverter
from .batch_trainer import BatchTrainer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModelWatcher(FileSystemEventHandler):
    """ëª¨ë¸ íŒŒì¼ ë³€ê²½ ê°ì§€ ë° ìë™ ë³€í™˜"""
    
    def __init__(self, converter: ModelConverter, watch_patterns: Dict[str, str]):
        self.converter = converter
        self.watch_patterns = watch_patterns  # {íŒŒì¼íŒ¨í„´: ëª¨ë¸íƒ€ì…}
        self.last_processed = {}  # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
    
    def on_created(self, event):
        """ìƒˆ íŒŒì¼ ìƒì„± ì‹œ ì²˜ë¦¬"""
        if not event.is_directory:
            self._process_file(event.src_path)
    
    def on_modified(self, event):
        """íŒŒì¼ ìˆ˜ì • ì‹œ ì²˜ë¦¬"""
        if not event.is_directory:
            self._process_file(event.src_path)
    
    def _process_file(self, file_path: str):
        """íŒŒì¼ ì²˜ë¦¬ (ëª¨ë¸ ë³€í™˜)"""
        file_path = Path(file_path)
        
        # ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€ (1ë¶„ ë‚´ ê°™ì€ íŒŒì¼)
        now = time.time()
        if file_path.name in self.last_processed:
            if now - self.last_processed[file_path.name] < 60:
                return
        
        self.last_processed[file_path.name] = now
        
        # íŒ¨í„´ ë§¤ì¹­
        for pattern, model_type in self.watch_patterns.items():
            if pattern in file_path.name and file_path.suffix == '.pth':
                logger.info(f"ğŸ” ìƒˆ {model_type} ëª¨ë¸ ê°ì§€: {file_path}")
                self._convert_model(file_path, model_type)
                break
    
    def _convert_model(self, model_path: Path, model_type: str):
        """ëª¨ë¸ ë³€í™˜ ì‹¤í–‰"""
        try:
            if model_type == 'deeplog':
                # vocab.json ì°¾ê¸°
                vocab_path = self._find_vocab_file(model_path)
                if vocab_path:
                    result = self.converter.convert_deeplog_to_onnx(
                        str(model_path), str(vocab_path)
                    )
                    logger.info(f"âœ… DeepLog ìë™ ë³€í™˜ ì™„ë£Œ: {result['onnx_path']}")
                else:
                    logger.warning("vocab.jsonì„ ì°¾ì„ ìˆ˜ ì—†ì–´ DeepLog ë³€í™˜ ê±´ë„ˆëœ€")
            
            elif model_type == 'mscred':
                result = self.converter.convert_mscred_to_onnx(str(model_path))
                logger.info(f"âœ… MS-CRED ìë™ ë³€í™˜ ì™„ë£Œ: {result['onnx_path']}")
            
        except Exception as e:
            logger.error(f"âŒ {model_type} ìë™ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def _find_vocab_file(self, model_path: Path) -> Optional[Path]:
        """DeepLogìš© vocab.json íŒŒì¼ ì°¾ê¸°"""
        # ê°™ì€ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
        vocab_path = model_path.parent / "vocab.json"
        if vocab_path.exists():
            return vocab_path
        
        # ìƒìœ„ ë””ë ‰í† ë¦¬ë“¤ì—ì„œ ì°¾ê¸°
        for parent in model_path.parents:
            vocab_path = parent / "vocab.json"
            if vocab_path.exists():
                return vocab_path
        
        # data/processed ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
        data_dirs = ["data/processed", "../data/processed", "../../data/processed"]
        for data_dir in data_dirs:
            vocab_path = Path(data_dir) / "vocab.json"
            if vocab_path.exists():
                return vocab_path
        
        return None


class AutoConverter:
    """ìë™ ë³€í™˜ ë° ë°°í¬ ê´€ë¦¬ì"""
    
    def __init__(self, 
                 models_dir: str = "models",
                 onnx_dir: str = "models/onnx",
                 deployment_dir: str = "models/deployment"):
        self.models_dir = Path(models_dir)
        self.onnx_dir = Path(onnx_dir)
        self.deployment_dir = Path(deployment_dir)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.models_dir.mkdir(parents=True, exist_ok=True)
        self.onnx_dir.mkdir(parents=True, exist_ok=True)
        self.deployment_dir.mkdir(parents=True, exist_ok=True)
        
        self.converter = ModelConverter(str(self.onnx_dir))
        self.observer = None
    
    def start_watching(self):
        """ëª¨ë¸ ë””ë ‰í† ë¦¬ ê°ì‹œ ì‹œì‘"""
        watch_patterns = {
            'deeplog': 'deeplog',
            'mscred': 'mscred'
        }
        
        event_handler = ModelWatcher(self.converter, watch_patterns)
        self.observer = Observer()
        self.observer.schedule(event_handler, str(self.models_dir), recursive=True)
        self.observer.start()
        
        logger.info(f"ğŸ” ëª¨ë¸ ë””ë ‰í† ë¦¬ ê°ì‹œ ì‹œì‘: {self.models_dir}")
        logger.info("ìƒˆë¡œìš´ ëª¨ë¸ì´ ìƒì„±ë˜ë©´ ìë™ìœ¼ë¡œ ONNX ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    
    def stop_watching(self):
        """ëª¨ë¸ ë””ë ‰í† ë¦¬ ê°ì‹œ ì¤‘ë‹¨"""
        if self.observer:
            self.observer.stop()
            self.observer.join()
            logger.info("ğŸ›‘ ëª¨ë¸ ê°ì‹œ ì¤‘ë‹¨")
    
    def convert_existing_models(self) -> Dict[str, Any]:
        """ê¸°ì¡´ ëª¨ë¸ë“¤ì„ ì¼ê´„ ë³€í™˜"""
        logger.info("ğŸ”„ ê¸°ì¡´ ëª¨ë¸ ì¼ê´„ ë³€í™˜ ì‹œì‘")
        
        results = {}
        
        # DeepLog ëª¨ë¸ ì°¾ê¸°
        deeplog_models = list(self.models_dir.glob("*deeplog*.pth"))
        for model_path in deeplog_models:
            try:
                vocab_path = self._find_vocab_for_model(model_path)
                if vocab_path:
                    result = self.converter.convert_deeplog_to_onnx(
                        str(model_path), str(vocab_path)
                    )
                    results[f"deeplog_{model_path.stem}"] = result
                    logger.info(f"âœ… DeepLog ë³€í™˜: {model_path.name}")
                else:
                    logger.warning(f"âš ï¸ vocab.json ì—†ìŒ: {model_path.name}")
            except Exception as e:
                logger.error(f"âŒ DeepLog ë³€í™˜ ì‹¤íŒ¨ {model_path.name}: {e}")
        
        # MS-CRED ëª¨ë¸ ì°¾ê¸°
        mscred_models = list(self.models_dir.glob("*mscred*.pth"))
        for model_path in mscred_models:
            try:
                result = self.converter.convert_mscred_to_onnx(str(model_path))
                results[f"mscred_{model_path.stem}"] = result
                logger.info(f"âœ… MS-CRED ë³€í™˜: {model_path.name}")
            except Exception as e:
                logger.error(f"âŒ MS-CRED ë³€í™˜ ì‹¤íŒ¨ {model_path.name}: {e}")
        
        logger.info(f"ğŸ‰ ì¼ê´„ ë³€í™˜ ì™„ë£Œ: {len(results)}ê°œ ëª¨ë¸")
        return results
    
    def _find_vocab_for_model(self, model_path: Path) -> Optional[Path]:
        """ëª¨ë¸ì— í•´ë‹¹í•˜ëŠ” vocab.json ì°¾ê¸°"""
        # ëª¨ë¸ê³¼ ê°™ì€ ë””ë ‰í† ë¦¬
        vocab_path = model_path.parent / "vocab.json"
        if vocab_path.exists():
            return vocab_path
        
        # ì¼ë°˜ì ì¸ ìœ„ì¹˜ë“¤ ê²€ìƒ‰
        search_paths = [
            "data/processed/vocab.json",
            "../data/processed/vocab.json",
            "../../data/processed/vocab.json",
            self.models_dir / "vocab.json"
        ]
        
        for search_path in search_paths:
            vocab_path = Path(search_path)
            if vocab_path.exists():
                return vocab_path
        
        return None
    
    def prepare_deployment_package(self, model_name: Optional[str] = None) -> Dict[str, Any]:
        """C ì—”ì§„ ë°°í¬ìš© íŒ¨í‚¤ì§€ ì¤€ë¹„"""
        logger.info("ğŸ“¦ ë°°í¬ íŒ¨í‚¤ì§€ ì¤€ë¹„ ì¤‘...")
        
        deployment_info = {
            'timestamp': datetime.now().isoformat(),
            'models': {},
            'files': []
        }
        
        # ONNX ëª¨ë¸ë“¤ ë³µì‚¬
        onnx_files = list(self.onnx_dir.glob("*.onnx"))
        for onnx_file in onnx_files:
            if model_name and model_name not in onnx_file.name:
                continue
            
            # ë°°í¬ ë””ë ‰í† ë¦¬ë¡œ ë³µì‚¬
            dest_path = self.deployment_dir / onnx_file.name
            shutil.copy2(onnx_file, dest_path)
            
            # ë©”íƒ€ë°ì´í„°ë„ ë³µì‚¬
            meta_file = onnx_file.with_suffix('.onnx.meta.json')
            if meta_file.exists():
                meta_dest = self.deployment_dir / meta_file.name
                shutil.copy2(meta_file, meta_dest)
                deployment_info['files'].append(str(meta_dest))
            
            deployment_info['models'][onnx_file.stem] = {
                'onnx_path': str(dest_path),
                'size_mb': dest_path.stat().st_size / (1024 * 1024)
            }
            deployment_info['files'].append(str(dest_path))
        
        # vocab.json ë³µì‚¬
        vocab_file = self.onnx_dir / "vocab.json"
        if vocab_file.exists():
            vocab_dest = self.deployment_dir / "vocab.json"
            shutil.copy2(vocab_file, vocab_dest)
            deployment_info['files'].append(str(vocab_dest))
        
        # ë°°í¬ ì •ë³´ ì €ì¥
        info_file = self.deployment_dir / "deployment_info.json"
        with open(info_file, 'w') as f:
            json.dump(deployment_info, f, indent=2, default=str)
        
        logger.info(f"âœ… ë°°í¬ íŒ¨í‚¤ì§€ ì¤€ë¹„ ì™„ë£Œ: {self.deployment_dir}")
        logger.info(f"ğŸ“Š í¬í•¨ëœ ëª¨ë¸: {list(deployment_info['models'].keys())}")
        
        return deployment_info
    
    def run_full_pipeline(self, log_file: str, auto_deploy: bool = True) -> Dict[str, Any]:
        """ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (í•™ìŠµ â†’ ë³€í™˜ â†’ ë°°í¬)"""
        logger.info("ğŸš€ ì „ì²´ í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        pipeline_results = {
            'start_time': datetime.now().isoformat(),
            'log_file': log_file,
            'stages': {}
        }
        
        try:
            # 1ë‹¨ê³„: ë°°ì¹˜ í•™ìŠµ
            logger.info("1ï¸âƒ£ ë°°ì¹˜ í•™ìŠµ ë‹¨ê³„")
            trainer = BatchTrainer(models_dir=str(self.models_dir))
            training_results = trainer.train_full_pipeline(log_file)
            pipeline_results['stages']['training'] = training_results
            
            # 2ë‹¨ê³„: ONNX ë³€í™˜
            logger.info("2ï¸âƒ£ ONNX ë³€í™˜ ë‹¨ê³„")
            conversion_results = {}
            
            for model_name, model_info in training_results.get('models', {}).items():
                try:
                    model_path = model_info['path']
                    
                    if model_name == 'deeplog':
                        vocab_path = training_results['files']['vocab']
                        result = self.converter.convert_deeplog_to_onnx(
                            model_path, vocab_path
                        )
                    elif model_name == 'mscred':
                        result = self.converter.convert_mscred_to_onnx(model_path)
                    
                    conversion_results[model_name] = result
                    logger.info(f"âœ… {model_name} ë³€í™˜ ì™„ë£Œ")
                    
                except Exception as e:
                    logger.error(f"âŒ {model_name} ë³€í™˜ ì‹¤íŒ¨: {e}")
                    conversion_results[model_name] = {'error': str(e)}
            
            pipeline_results['stages']['conversion'] = conversion_results
            
            # 3ë‹¨ê³„: ë°°í¬ ì¤€ë¹„
            if auto_deploy and conversion_results:
                logger.info("3ï¸âƒ£ ë°°í¬ ì¤€ë¹„ ë‹¨ê³„")
                deployment_info = self.prepare_deployment_package()
                pipeline_results['stages']['deployment'] = deployment_info
            
            pipeline_results['status'] = 'success'
            pipeline_results['end_time'] = datetime.now().isoformat()
            
            logger.info("ğŸ‰ ì „ì²´ í•˜ì´ë¸Œë¦¬ë“œ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            
        except Exception as e:
            pipeline_results['status'] = 'failed'
            pipeline_results['error'] = str(e)
            pipeline_results['end_time'] = datetime.now().isoformat()
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            raise
        
        # ê²°ê³¼ ì €ì¥
        results_file = self.deployment_dir / "pipeline_results.json"
        with open(results_file, 'w') as f:
            json.dump(pipeline_results, f, indent=2, default=str)
        
        return pipeline_results


def main():
    """CLI ì¸í„°í˜ì´ìŠ¤"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ìë™ ëª¨ë¸ ë³€í™˜ ë° ë°°í¬")
    parser.add_argument("--mode", choices=['watch', 'convert', 'pipeline'], 
                       default='convert', help="ì‹¤í–‰ ëª¨ë“œ")
    parser.add_argument("--log-file", help="í•™ìŠµìš© ë¡œê·¸ íŒŒì¼ (pipeline ëª¨ë“œ)")
    parser.add_argument("--models-dir", default="models", help="ëª¨ë¸ ë””ë ‰í† ë¦¬")
    parser.add_argument("--onnx-dir", default="models/onnx", help="ONNX ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--deployment-dir", default="models/deployment", help="ë°°í¬ ë””ë ‰í† ë¦¬")
    
    args = parser.parse_args()
    
    converter = AutoConverter(args.models_dir, args.onnx_dir, args.deployment_dir)
    
    if args.mode == 'watch':
        # ê°ì‹œ ëª¨ë“œ
        converter.start_watching()
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            converter.stop_watching()
            logger.info("ğŸ‘‹ ê°ì‹œ ëª¨ë“œ ì¢…ë£Œ")
    
    elif args.mode == 'convert':
        # ë³€í™˜ ëª¨ë“œ
        results = converter.convert_existing_models()
        if results:
            converter.prepare_deployment_package()
        print(f"âœ… ë³€í™˜ ì™„ë£Œ: {len(results)}ê°œ ëª¨ë¸")
    
    elif args.mode == 'pipeline':
        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ëª¨ë“œ
        if not args.log_file:
            print("âŒ pipeline ëª¨ë“œëŠ” --log-fileì´ í•„ìš”í•©ë‹ˆë‹¤")
            return
        
        results = converter.run_full_pipeline(args.log_file)
        print(f"âœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {results['status']}")


if __name__ == "__main__":
    main()
