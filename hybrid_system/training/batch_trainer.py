#!/usr/bin/env python3
"""
ê¸°ì¡´ Python í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ë˜í•‘í•˜ê³  ìµœì í™”í•˜ëŠ” ëª¨ë“ˆ
í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œì˜ í•™ìŠµ ì»´í¬ë„ŒíŠ¸
"""

import os
import json
import subprocess
import sys
from pathlib import Path
from typing import Dict, Any, List, Optional
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BatchTrainer:
    """ë°°ì¹˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ê´€ë¦¬ì"""
    
    def __init__(self, 
                 cache_dir: str = ".cache",
                 models_dir: str = "models",
                 use_venv: bool = True):
        self.cache_dir = Path(cache_dir)
        self.models_dir = Path(models_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        self.use_venv = use_venv
        
        # Python ëª…ë ¹ì–´ ì„¤ì •
        self.python_cmd = self._setup_python_command()
    
    def _setup_python_command(self) -> str:
        """Python ëª…ë ¹ì–´ ì„¤ì • (ê°€ìƒí™˜ê²½ ê³ ë ¤)"""
        if self.use_venv and os.environ.get('VIRTUAL_ENV'):
            return "python"
        elif self.use_venv and Path(".venv/bin/python").exists():
            return ".venv/bin/python"
        else:
            return "python3"
    
    def train_full_pipeline(self, 
                          log_file: str, 
                          output_dir: Optional[str] = None,
                          config: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            log_file: ì…ë ¥ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (Noneì´ë©´ ìë™ ìƒì„±)
            config: í•™ìŠµ ì„¤ì •
            
        Returns:
            í•™ìŠµ ê²°ê³¼ ì •ë³´
        """
        if output_dir is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = f"data/processed/batch_{timestamp}"
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ë³¸ ì„¤ì •
        default_config = {
            'seq_len': 50,
            'deeplog_epochs': 3,
            'mscred_epochs': 30,
            'window_size': 50,
            'stride': 25,
            'ewm_alpha': 0.3,
            'anomaly_q': 0.95
        }
        
        if config:
            default_config.update(config)
        
        logger.info(f"ğŸš€ ë°°ì¹˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {log_file}")
        logger.info(f"ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        logger.info(f"âš™ï¸ ì„¤ì •: {default_config}")
        
        results = {
            'log_file': log_file,
            'output_dir': output_dir,
            'config': default_config,
            'steps': {},
            'models': {},
            'start_time': datetime.now().isoformat()
        }
        
        try:
            # 1ë‹¨ê³„: ë¡œê·¸ ì „ì²˜ë¦¬
            logger.info("1ï¸âƒ£ ë¡œê·¸ ì „ì²˜ë¦¬ ì¤‘...")
            self._run_preprocessing(log_file, output_dir, results)
            
            # 2ë‹¨ê³„: DeepLog ë°ì´í„° ì¤€ë¹„
            logger.info("2ï¸âƒ£ DeepLog ë°ì´í„° ì¤€ë¹„ ì¤‘...")
            self._prepare_deeplog_data(output_dir, results)
            
            # 3ë‹¨ê³„: MS-CRED ë°ì´í„° ì¤€ë¹„
            logger.info("3ï¸âƒ£ MS-CRED ë°ì´í„° ì¤€ë¹„ ì¤‘...")
            self._prepare_mscred_data(output_dir, default_config, results)
            
            # 4ë‹¨ê³„: ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€
            logger.info("4ï¸âƒ£ ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ ì¤‘...")
            self._run_baseline_detection(output_dir, default_config, results)
            
            # 5ë‹¨ê³„: DeepLog í•™ìŠµ
            logger.info("5ï¸âƒ£ DeepLog ëª¨ë¸ í•™ìŠµ ì¤‘...")
            self._train_deeplog(output_dir, default_config, results)
            
            # 6ë‹¨ê³„: MS-CRED í•™ìŠµ
            logger.info("6ï¸âƒ£ MS-CRED ëª¨ë¸ í•™ìŠµ ì¤‘...")
            self._train_mscred(output_dir, default_config, results)
            
            # 7ë‹¨ê³„: ë¦¬í¬íŠ¸ ìƒì„±
            logger.info("7ï¸âƒ£ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
            self._generate_report(output_dir, results)
            
            results['status'] = 'success'
            results['end_time'] = datetime.now().isoformat()
            
            logger.info("âœ… ë°°ì¹˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            
        except Exception as e:
            results['status'] = 'failed'
            results['error'] = str(e)
            results['end_time'] = datetime.now().isoformat()
            logger.error(f"âŒ ë°°ì¹˜ í•™ìŠµ ì‹¤íŒ¨: {e}")
            raise
        
        # ê²°ê³¼ ì €ì¥
        results_path = Path(output_dir) / "training_results.json"
        with open(results_path, 'w') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        return results
    
    def _run_command(self, cmd: List[str], step_name: str) -> Dict[str, Any]:
        """ëª…ë ¹ì–´ ì‹¤í–‰ ë° ê²°ê³¼ ê¸°ë¡"""
        logger.info(f"ì‹¤í–‰ ì¤‘: {' '.join(cmd)}")
        
        start_time = datetime.now()
        result = subprocess.run(cmd, capture_output=True, text=True)
        end_time = datetime.now()
        
        step_result = {
            'command': ' '.join(cmd),
            'start_time': start_time.isoformat(),
            'end_time': end_time.isoformat(),
            'duration_seconds': (end_time - start_time).total_seconds(),
            'return_code': result.returncode,
            'stdout': result.stdout,
            'stderr': result.stderr
        }
        
        if result.returncode != 0:
            logger.error(f"âŒ {step_name} ì‹¤íŒ¨: {result.stderr}")
            raise subprocess.CalledProcessError(result.returncode, cmd, result.stderr)
        
        logger.info(f"âœ… {step_name} ì™„ë£Œ ({step_result['duration_seconds']:.1f}ì´ˆ)")
        return step_result
    
    def _run_preprocessing(self, log_file: str, output_dir: str, results: Dict[str, Any]):
        """ë¡œê·¸ ì „ì²˜ë¦¬ ì‹¤í–‰"""
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "parse",
            "--input", log_file,
            "--out-dir", output_dir,
            "--drain-state", str(self.cache_dir / "drain3_state.json")
        ]
        
        step_result = self._run_command(cmd, "ë¡œê·¸ ì „ì²˜ë¦¬")
        results['steps']['preprocessing'] = step_result
        
        # ê²°ê³¼ íŒŒì¼ í™•ì¸
        parsed_file = Path(output_dir) / "parsed.parquet"
        if not parsed_file.exists():
            raise FileNotFoundError(f"ì „ì²˜ë¦¬ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ: {parsed_file}")
        
        results['files'] = results.get('files', {})
        results['files']['parsed'] = str(parsed_file)
    
    def _prepare_deeplog_data(self, output_dir: str, results: Dict[str, Any]):
        """DeepLog ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "build-deeplog",
            "--parsed", str(Path(output_dir) / "parsed.parquet"),
            "--out-dir", output_dir
        ]
        
        step_result = self._run_command(cmd, "DeepLog ë°ì´í„° ì¤€ë¹„")
        results['steps']['deeplog_data'] = step_result
        
        # ê²°ê³¼ íŒŒì¼ í™•ì¸
        vocab_file = Path(output_dir) / "vocab.json"
        sequences_file = Path(output_dir) / "sequences.parquet"
        
        if not vocab_file.exists() or not sequences_file.exists():
            raise FileNotFoundError("DeepLog ì…ë ¥ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        
        results['files']['vocab'] = str(vocab_file)
        results['files']['sequences'] = str(sequences_file)
    
    def _prepare_mscred_data(self, output_dir: str, config: Dict[str, Any], results: Dict[str, Any]):
        """MS-CRED ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "build-mscred",
            "--parsed", str(Path(output_dir) / "parsed.parquet"),
            "--out-dir", output_dir,
            "--window-size", str(config['window_size']),
            "--stride", str(config['stride'])
        ]
        
        step_result = self._run_command(cmd, "MS-CRED ë°ì´í„° ì¤€ë¹„")
        results['steps']['mscred_data'] = step_result
        
        # ê²°ê³¼ íŒŒì¼ í™•ì¸
        window_counts_file = Path(output_dir) / "window_counts.parquet"
        if not window_counts_file.exists():
            raise FileNotFoundError("MS-CRED ì…ë ¥ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        
        results['files']['window_counts'] = str(window_counts_file)
    
    def _run_baseline_detection(self, output_dir: str, config: Dict[str, Any], results: Dict[str, Any]):
        """ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€ ì‹¤í–‰"""
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "detect",
            "--parsed", str(Path(output_dir) / "parsed.parquet"),
            "--out-dir", output_dir,
            "--window-size", str(config['window_size']),
            "--stride", str(config['stride']),
            "--ewm-alpha", str(config['ewm_alpha']),
            "--q", str(config['anomaly_q'])
        ]
        
        step_result = self._run_command(cmd, "ë² ì´ìŠ¤ë¼ì¸ ì´ìƒíƒì§€")
        results['steps']['baseline_detection'] = step_result
        
        # ê²°ê³¼ íŒŒì¼ í™•ì¸
        baseline_file = Path(output_dir) / "baseline_scores.parquet"
        if not baseline_file.exists():
            raise FileNotFoundError("ë² ì´ìŠ¤ë¼ì¸ ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        
        results['files']['baseline_scores'] = str(baseline_file)
    
    def _train_deeplog(self, output_dir: str, config: Dict[str, Any], results: Dict[str, Any]):
        """DeepLog ëª¨ë¸ í•™ìŠµ"""
        model_name = f"deeplog_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
        model_path = self.models_dir / model_name
        
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "deeplog-train",
            "--seq", str(Path(output_dir) / "sequences.parquet"),
            "--vocab", str(Path(output_dir) / "vocab.json"),
            "--out", str(model_path),
            "--seq-len", str(config['seq_len']),
            "--epochs", str(config['deeplog_epochs'])
        ]
        
        step_result = self._run_command(cmd, "DeepLog í•™ìŠµ")
        results['steps']['deeplog_training'] = step_result
        
        # ëª¨ë¸ íŒŒì¼ í™•ì¸
        if not model_path.exists():
            raise FileNotFoundError(f"DeepLog ëª¨ë¸ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ: {model_path}")
        
        results['models']['deeplog'] = {
            'path': str(model_path),
            'type': 'pytorch',
            'config': {
                'seq_len': config['seq_len'],
                'epochs': config['deeplog_epochs']
            }
        }
        
        # DeepLog ì¶”ë¡ ë„ ì‹¤í–‰
        self._run_deeplog_inference(output_dir, model_path, results)
    
    def _run_deeplog_inference(self, output_dir: str, model_path: Path, results: Dict[str, Any]):
        """DeepLog ì¶”ë¡  ì‹¤í–‰"""
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "deeplog-infer",
            "--seq", str(Path(output_dir) / "sequences.parquet"),
            "--model", str(model_path),
            "--k", "3"
        ]
        
        step_result = self._run_command(cmd, "DeepLog ì¶”ë¡ ")
        results['steps']['deeplog_inference'] = step_result
        
        # ê²°ê³¼ íŒŒì¼ í™•ì¸
        inference_file = Path(output_dir) / "deeplog_infer.parquet"
        if not inference_file.exists():
            raise FileNotFoundError("DeepLog ì¶”ë¡  ê²°ê³¼ê°€ ìƒì„±ë˜ì§€ ì•ŠìŒ")
        
        results['files']['deeplog_inference'] = str(inference_file)
    
    def _train_mscred(self, output_dir: str, config: Dict[str, Any], results: Dict[str, Any]):
        """MS-CRED ëª¨ë¸ í•™ìŠµ"""
        model_name = f"mscred_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth"
        model_path = self.models_dir / model_name
        
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "mscred-train",
            "--window-counts", str(Path(output_dir) / "window_counts.parquet"),
            "--out", str(model_path),
            "--epochs", str(config['mscred_epochs'])
        ]
        
        try:
            step_result = self._run_command(cmd, "MS-CRED í•™ìŠµ")
            results['steps']['mscred_training'] = step_result
            
            # ëª¨ë¸ íŒŒì¼ í™•ì¸
            if model_path.exists():
                results['models']['mscred'] = {
                    'path': str(model_path),
                    'type': 'pytorch',
                    'config': {
                        'epochs': config['mscred_epochs']
                    }
                }
                
                # MS-CRED ì¶”ë¡ ë„ ì‹¤í–‰
                self._run_mscred_inference(output_dir, model_path, results)
            else:
                logger.warning("MS-CRED ëª¨ë¸ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")
                
        except subprocess.CalledProcessError as e:
            logger.warning(f"MS-CRED í•™ìŠµ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
            results['steps']['mscred_training'] = {
                'status': 'failed',
                'error': str(e)
            }
    
    def _run_mscred_inference(self, output_dir: str, model_path: Path, results: Dict[str, Any]):
        """MS-CRED ì¶”ë¡  ì‹¤í–‰"""
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "mscred-infer",
            "--window-counts", str(Path(output_dir) / "window_counts.parquet"),
            "--model", str(model_path),
            "--threshold", "95.0"
        ]
        
        try:
            step_result = self._run_command(cmd, "MS-CRED ì¶”ë¡ ")
            results['steps']['mscred_inference'] = step_result
            
            # ê²°ê³¼ íŒŒì¼ í™•ì¸
            inference_file = Path(output_dir) / "mscred_infer.parquet"
            if inference_file.exists():
                results['files']['mscred_inference'] = str(inference_file)
                
        except subprocess.CalledProcessError as e:
            logger.warning(f"MS-CRED ì¶”ë¡  ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
            results['steps']['mscred_inference'] = {
                'status': 'failed',
                'error': str(e)
            }
    
    def _generate_report(self, output_dir: str, results: Dict[str, Any]):
        """ë¦¬í¬íŠ¸ ìƒì„±"""
        cmd = [
            self.python_cmd, "-m", "anomaly_log_detector.cli", "report",
            "--processed-dir", output_dir
        ]
        
        step_result = self._run_command(cmd, "ë¦¬í¬íŠ¸ ìƒì„±")
        results['steps']['report'] = step_result
        
        # ë¦¬í¬íŠ¸ íŒŒì¼ í™•ì¸
        report_file = Path(output_dir) / "report.md"
        if report_file.exists():
            results['files']['report'] = str(report_file)


def main():
    """CLI ì¸í„°í˜ì´ìŠ¤"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ë°°ì¹˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰")
    parser.add_argument("log_file", help="ì…ë ¥ ë¡œê·¸ íŒŒì¼")
    parser.add_argument("--output-dir", help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--config", help="ì„¤ì • JSON íŒŒì¼")
    parser.add_argument("--seq-len", type=int, default=50, help="ì‹œí€€ìŠ¤ ê¸¸ì´")
    parser.add_argument("--deeplog-epochs", type=int, default=3, help="DeepLog ì—í¬í¬")
    parser.add_argument("--mscred-epochs", type=int, default=30, help="MS-CRED ì—í¬í¬")
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = {}
    if args.config and Path(args.config).exists():
        with open(args.config, 'r') as f:
            config = json.load(f)
    
    # CLI ì¸ìˆ˜ë¡œ ì„¤ì • ì—…ë°ì´íŠ¸
    config.update({
        'seq_len': args.seq_len,
        'deeplog_epochs': args.deeplog_epochs,
        'mscred_epochs': args.mscred_epochs
    })
    
    # í•™ìŠµ ì‹¤í–‰
    trainer = BatchTrainer()
    results = trainer.train_full_pipeline(
        args.log_file,
        args.output_dir,
        config
    )
    
    print(f"\nğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print(f"ğŸ“‚ ê²°ê³¼ ë””ë ‰í† ë¦¬: {results['output_dir']}")
    print(f"ğŸ“Š í•™ìŠµëœ ëª¨ë¸:")
    for model_name, model_info in results.get('models', {}).items():
        print(f"  - {model_name}: {model_info['path']}")


if __name__ == "__main__":
    main()
